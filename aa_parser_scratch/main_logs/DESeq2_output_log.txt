
###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_2_12 deseq2_release_2_13

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_2_12 deseq2_release_2_13",
    "desc_release_old": "1.0.19",
    "desc_release_new": "1.2.10",
    "old_release_number": 0,
    "new_release_number": 1,
    "function_removals": 0,
    "function_additions": 1,
    "parameter_removals": 2,
    "parameter_additions": 6,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 10,
    "total_count": 10
}

##########
Functions Removed
##########



##########
Functions Added
##########

replaceOutliersWithTrimmedMean


##########
Removed Non Default Parameters
##########

0.
{
  "old_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , pAdjustMethod = \"BH\" , priorSigmaSq , cooksCutoff , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df )",
    "body": "{   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim )   H -   fit $ hat_diagonals }  if (  betaPrior )  { # we need the MLE betas to fit the prior variance # and for the hat matrix diagonals in order to # calculate Cook's distance   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit )   H -   fit $ hat_diagonals  if (   missing (  priorSigmaSq ) )  { # estimate the width of the prior on betas # excluding those rows with coefficients going to infinity. # if all betas are large, use a very large prior   priorSigmaSq -   apply (   fit $ betaMatrix ,  2 ,  function ( x )  {   useSmall -    abs (  x ) undefined  8  if (    sum (  useSmall ) ==  0 )  {   return (  1e6 ) } else  {   mean (    x [  useSmall ] ^  2 ) } } ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%   fit $ modelMatrixNames )  {    priorSigmaSq [   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] -  1e6 } } else  { # we are provided the prior variance: # check if the lambda is the correct length # given the design formula   p -   ncol (   fit $ modelMatrix )  if (    length (  priorSigmaSq ) !=  p )  {   stop (   paste0 (  \"priorSigmaSq should have length\" ,  p ) ) } }   lambda -   1 /  priorSigmaSq   fit -   fitNbinomGLMs (  objectNZ , lambda =  lambda , maxit =  maxit , useOptim =  useOptim ) }   m -   nrow (   fit $ modelMatrix )   p -   ncol (   fit $ modelMatrix ) # calculate Cook's distance  if (   missing (  cooksCutoff ) )  {   cooksCutoff -   qf (  .75 ,  p ,   m -  p ) }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -   qf (  .75 ,  p ,   m -  p ) }   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p )   looFullRank -   leaveOneOutFullRank (   fit $ modelMatrix )  if (   m undefined  p )  {   maxCooks -   apply (   cooks [ ,  looFullRank , drop =  FALSE ] ,  1 ,  max )   cooksOutlier -   maxCooks undefined  cooksCutoff } else  {   maxCooks -   rep (  NA ,   nrow (  objectNZ ) )   cooksOutlier -   rep (  FALSE ,   nrow (  objectNZ ) ) } # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )   modelMatrixNames -   fit $ modelMatrixNames # add betas, standard errors and Wald p-values to the object   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   priorVar -   attr (   dispersionFunction (  object ) ,  \"priorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames ) # Set to NA the p-values for genes that have one or more # samples with Cook's distance beyond the cutof  if (    is.numeric (  cooksCutoff ) |  cooksCutoff )  {    WaldPvalue [  cooksOutlier , ] -  NA } # if more than 1 row, we adjust p-values  if (    nrow (  WaldPvalue ) undefined  1 )  {   WaldAdjPvalue -   apply (  WaldPvalue ,  2 ,  p.adjust , method =  pAdjustMethod ) } else  {   WaldAdjPvalue -  WaldPvalue }    colnames (  WaldAdjPvalue ) -   paste0 (  \"WaldAdjPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   matrixToList (  WaldAdjPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks , cooksOutlier =  cooksOutlier ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )  if (  betaPrior )  {   coefInfo -   paste (  \"log2 fold change (MAP):\" ,  modelMatrixNamesSpaces ) } else  {   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces ) }   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"Wald test:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test:\" ,  modelMatrixNamesSpaces )   adjInfo -   paste (   paste (  \"Wald test,\" ,  pAdjustMethod ,  \"adj.:\" ) ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  adjInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ,  \"whether maxCooks ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{   stopifnot (    length (  maxit ) ==  1 )  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   H -   fit $ hat_diagonals # record the wide prior which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } # calculate the prior variance (on the log2 scale)  if (  betaPrior )  { # we need the MLE betas to fit the prior variance # and for the hat matrix diagonals in order to # calculate Cook's distance   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useQR =  useQR )   H -   fit $ hat_diagonals  if (   missing (  betaPriorVar ) )  { # estimate the variance of the prior on betas  if (    nrow (   fit $ betaMatrix ) undefined  1 )  {   betaPriorVar -   apply (   fit $ betaMatrix ,  2 ,  function ( x )  { # infinite betas are halted when |beta| # so this test removes them   useSmall -    abs (  x ) undefined  8 # if no more betas pass test, return wide prior  if (    sum (  useSmall ) ==  0 )  {   return (  1e6 ) } else  {   mean (    x [  useSmall ] ^  2 ) } } ) } else  {   betaPriorVar -   (   fit $ betaMatrix ) ^  2 } # except for intercept which we set to wide prior  if (   \"Intercept\" %in%   fit $ modelMatrixNames )  {    betaPriorVar [   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] -  1e6 } } else  { # else we are provided the prior variance: # check if the lambda is the correct length # given the design formula   p -   ncol (   fit $ modelMatrix )  if (    length (  betaPriorVar ) !=  p )  {   stop (   paste (  \"betaPriorVar should have length\" ,  p ) ) } }   lambda -   1 /  betaPriorVar   fit -   fitNbinomGLMs (  objectNZ , lambda =  lambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) } # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -   fit $ modelMatrix   m -   nrow (   fit $ modelMatrix )   p -   ncol (   fit $ modelMatrix ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,   fit $ modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )   modelMatrixNames -   fit $ modelMatrixNames # add betas, standard errors and Wald p-values to the object   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )  if (  betaPrior )  {   coefInfo -   paste (  \"log2 fold change (MAP):\" ,  modelMatrixNamesSpaces ) } else  {   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces ) }   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , pAdjustMethod = \"BH\" , cooksCutoff , maxit = 100 , useOptim = TRUE , quiet = FALSE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"please provide a reduced formula for the likelihood ratio test, e.g. nbinomLRT(object, reduced = ~ 1)\" ) }  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) } # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix )  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim )   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim )   p -   ncol (  fullModelMatrix )   m -   nrow (  fullModelMatrix )   H -   fullModel $ hat_diagonals # calculate Cook's distance  if (   missing (  cooksCutoff ) )  {   cooksCutoff -   qf (  .75 ,  p ,   m -  p ) }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -   qf (  .75 ,  p ,   m -  p ) }   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p )   looFullRank -   leaveOneOutFullRank (  fullModelMatrix )  if (   m undefined  p )  {   maxCooks -   apply (   cooks [ ,  looFullRank , drop =  FALSE ] ,  1 ,  max )   cooksOutlier -   maxCooks undefined  cooksCutoff } else  {   maxCooks -   rep (  NA ,   nrow (  objectNZ ) )   cooksOutlier -   rep (  FALSE ,   nrow (  objectNZ ) ) } # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # Set to NA the p-values for genes that have one or more # samples with Cook's distance beyond the cutoff  if (    is.numeric (  cooksCutoff ) |  cooksCutoff )  {    LRTPvalue [  cooksOutlier ] -  NA } # continue storing LRT results   LRTAdjPvalue -   p.adjust (  LRTPvalue , method =  pAdjustMethod )   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , LRTAdjPvalue =  LRTAdjPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks , cooksOutlier =  cooksOutlier ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" )   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )   adjInfo -   paste (  \"LRT p-value,\" ,  pAdjustMethod ,  \"adj.\" )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  adjInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ,  \"whether maxCooks ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"please provide a reduced formula for the likelihood ratio test, e.g. nbinomLRT(object, reduced = ~ 1)\" ) }  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) } # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix )  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )    attr (  object ,  \"modelMatrix\" ) -  fullModelMatrix   p -   ncol (  fullModelMatrix )   m -   nrow (  fullModelMatrix )   H -   fullModel $ hat_diagonals # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  fullModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" )   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}



##########
Added Non Default Parameters
##########

0.
{
  "old_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , betaPrior = TRUE , pAdjustMethod = \"BH\" , quiet = FALSE )",
    "body": "{  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object )  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"fitting generalized linear model\" )   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , pAdjustMethod =  pAdjustMethod , quiet =  quiet )  object } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , test = c ( \"Wald\" , \"LRT\" ) , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , betaPrior = TRUE , full = design ( object ) , reduced , quiet = FALSE )",
    "body": "{  if (   missing (  test ) )  {   test -   test [  1 ] }   stopifnot (     length (  test ) ==  1 undefined   test %in%   c (  \"Wald\" ,  \"LRT\" ) )  if (   !   is.null (   sizeFactors (  object ) ) ||  !   is.null (   normalizationFactors (  object ) ) )  {  if (  !  quiet )  {  if (  !   is.null (   normalizationFactors (  object ) ) )  {   message (  \"using pre-existing normalization factors\" ) } else  {   message (  \"using pre-existing size factors\" ) } } } else  {  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object ) }  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"fitting model and testing\" )  if (   test ==  \"Wald\" )  {   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , quiet =  quiet ) } else  if (   test ==  \"LRT\" )  {   object -   nbinomLRT (  object , full =  full , reduced =  reduced , quiet =  quiet ) }  object } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "estimateSizeFactorsForMatrix",
    "representation": "estimateSizeFactorsForMatrix",
    "parameters": "function ( counts , locfunc = median )",
    "body": "{   loggeomeans -   rowMeans (   log (  counts ) )  if (   all (   is.infinite (  loggeomeans ) ) )  {   stop (  \"every gene contains at least one zero, cannot compute log geometric means\" ) }   apply (  counts ,  2 ,  function ( cnts )   exp (   locfunc (   (    log (  cnts ) -  loggeomeans ) [   is.finite (  loggeomeans ) ] ) ) ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateSizeFactorsForMatrix",
    "representation": "estimateSizeFactorsForMatrix",
    "parameters": "function ( counts , locfunc = median , geoMeans )",
    "body": "{  if (   missing (  geoMeans ) )  {   loggeomeans -   rowMeans (   log (  counts ) ) } else  {  if (    length (  geoMeans ) !=   nrow (  counts ) )  {   stop (  \"geoMeans should be as long as the number of rows of counts\" ) }   loggeomeans -   log (  geoMeans ) }  if (   all (   is.infinite (  loggeomeans ) ) )  {   stop (  \"every gene contains at least one zero, cannot compute log geometric means\" ) }   apply (  counts ,  2 ,  function ( cnts )   exp (   locfunc (   (    log (  cnts ) -  loggeomeans ) [    is.finite (  loggeomeans ) undefined  (   cnts undefined  0 ) ] ) ) ) } ",
    "filename": "core.txt"
  }
}

2.
{
  "old_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , name )",
    "body": "{  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) }  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }  if (    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) ) )  {   test -  \"Wald\" } else  if (   \"LRTPvalue\" %in%   names (   mcols (  object ) ) )  {   test -  \"LRT\" } else  {   stop (  \"cannot find appropriate results, for available names call 'resultsNames(object)'\" ) }   log2FoldChange -   coef (  object ,  name )   lfcSE -   coefSE (  object ,  name )   pvalue -   pvalues (  object ,  test ,  name )   padj -   padj (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  pvalue ,  padj )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"pvalue\" ,  \"padj\" )    rownames (  res ) -   rownames (  object )  res } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , name , contrast , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta = seq ( 0 , 0.95 , by = 0.05 ) , pAdjustMethod = \"BH\" )",
    "body": "{  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  theta ) undefined  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } # determine test type from the names of mcols(object)  if (    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) ) )  {   test -  \"Wald\" } else  if (   \"LRTPvalue\" %in%   names (   mcols (  object ) ) )  {   test -  \"LRT\" } else  {   stop (  \"cannot find appropriate results, for available names call 'resultsNames(object)'\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  { # must have performed the Wald test steps  if (   test !=  \"Wald\" )  {   stop (  \"using contrasts requires that the Wald test was performed\" ) }   res -   cleanContrast (  object ,  contrast ) } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"modelMatrix\" ) )   p -   ncol (   attr (  object ,  \"modelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # perform independent filtering  if (  independentFiltering )  {  if (   missing (  filter ) )  {   filter -   res $ baseMean }   stopifnot (    length (  filter ) ==   nrow (  object ) )   filtPadj -   filtered_p ( filter =  filter , test =   res $ pvalue , theta =  theta , method =  pAdjustMethod )   numRej -   colSums (   filtPadj undefined  alpha , na.rm =  TRUE )   j -   which.max (  numRej )    res $ padj -   filtPadj [ ,  j , drop =  TRUE ]   cutoffs -   quantile (  filter ,  theta )    attr (  res ,  \"filterThreshold\" ) -   cutoffs [  j ]    attr (  res ,  \"filterNumRej\" ) -   data.frame ( theta =  theta , numRej =  numRej ) } else  { # regular p-value adjustment # which does not include those rows which were removed # by maximum Cook's distance    res $ padj -   p.adjust (   res $ pvalue , method =  pAdjustMethod ) }      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" )  res } ",
    "filename": "core.txt"
  }
}

3.
{
  "old_function": {
    "name": "rlogTransformation",
    "representation": "rlogTransformation",
    "parameters": "function ( object , blind = TRUE , samplesVector , priorSigmasq , rowVarQuantile = .9 )",
    "body": "{  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   object -   estimateSizeFactors (  object ) }  if (  blind )  {    design (  object ) -  ~  1   object -   estimateDispersions (  object ) }  if (   is.null (   dispersions (  object ) ) )  {   object -   estimateDispersions (  object ) }   SummarizedExperiment ( assays =   rlogData (  object ,  samplesVector ,  priorSigmasq ,  rowVarQuantile ) , colData =   colData (  object ) , rowData =   rowData (  object ) , exptData =   exptData (  object ) ) } ",
    "filename": "rlogTransformation.txt"
  },
  "new_function": {
    "name": "rlogTransformation",
    "representation": "rlogTransformation",
    "parameters": "function ( object , blind = TRUE , samplesVector , betaPriorVar , intercept )",
    "body": "{  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   object -   estimateSizeFactors (  object ) }  if (  blind )  {    design (  object ) -  ~  1   object -   estimateDispersionsGeneEst (  object )   object -   estimateDispersionsFit (  object ) }  if (   is.null (    mcols (  object ) $ dispFit ) )  {   object -   estimateDispersionsGeneEst (  object )   object -   estimateDispersionsFit (  object ) }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }   rld -   rlogData (  object ,  samplesVector ,  betaPriorVar ,  intercept )   se -   SummarizedExperiment ( assays =  rld , colData =   colData (  object ) , rowData =   rowData (  object ) , exptData =   exptData (  object ) )    attr (  se ,  \"betaPriorVar\" ) -   attr (  rld ,  \"betaPriorVar\" )  if (  !   is.null (   attr (  rld ,  \"intercept\" ) ) )  {     mcols (  se ) $ rlogIntercept -   attr (  rld ,  \"intercept\" ) }  se } ",
    "filename": "rlogTransformation.txt"
  }
}

4.
{
  "old_function": {
    "name": "rlogData",
    "representation": "rlogData",
    "parameters": "function ( object , samplesVector , priorSigmasq , rowVarQuantile = .9 )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"first estimate dispersion with a design of formula(~ 1)\" ) }  if (   missing (  samplesVector ) )  {   samplesVector -   as.character (   seq_len (   ncol (  object ) ) ) }   stopifnot (    length (  rowVarQuantile ) ==  1 ) # make a design matrix with a term for every sample # this would typically produce unidentifiable solution # for the GLM, but we add priors for all terms except # the intercept   samplesVector -   factor (  samplesVector , levels =   unique (  samplesVector ) )   samples -   factor (   c (  \"null_level\" ,   as.character (  samplesVector ) ) , levels =   c (  \"null_level\" ,   levels (  samplesVector ) ) )   modelMatrix -    model.matrix (  ~  samples ) [  -  1 , ]   modelMatrixNames -   colnames (  modelMatrix ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # if a prior sigma squared not provided, calculate it # from betas calculated with a wide prior  if (   missing (  priorSigmasq ) )  {   lambda -   rep (  1e-4 ,   ncol (  modelMatrix ) )  if (   \"(Intercept)\" %in%  modelMatrixNames )  {    lambda [   which (   modelMatrixNames ==  \"(Intercept)\" ) ] -  1e-6 }   fit -   fitNbinomGLMs (  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE ) # use rows which have no zeros   useNoZeros -   apply (   counts (  objectNZ ) ,  1 ,  function ( x )   all (   x undefined  0 ) )  if (    sum (  useNoZeros ) ==  0 )  {   stop (  \"no rows found without zeros\" ) } # calculate priors on sample betas # take row means of squares of sample betas   betaRowMeanSquared -   rowMeans (     fit $ betaMatrix [ ,  -   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] ^  2 )   priorSigmasq -   quantile (   betaRowMeanSquared [  useNoZeros ] ,  rowVarQuantile ) }   stopifnot (    length (  priorSigmasq ) ==  1 )   lambda -   1 /   rep (  priorSigmasq ,   ncol (  modelMatrix ) ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%   fit $ modelMatrixNames )  {    lambda [   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] -  1e-6 }   fit -   fitNbinomGLMs (  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE )   normalizedDataNZ -   t (   modelMatrix %*%   t (   fit $ betaMatrix ) )   normalizedData -   buildMatrixWithNARows (  normalizedDataNZ ,    mcols (  object ) $ allZero )    colnames (  normalizedData ) -   colnames (  object )   return (  normalizedData ) } ",
    "filename": "rlogTransformation.txt"
  },
  "new_function": {
    "name": "rlogData",
    "representation": "rlogData",
    "parameters": "function ( object , samplesVector , betaPriorVar , intercept )",
    "body": "{  if (   is.null (    mcols (  object ) $ dispFit ) )  {   stop (  \"first estimate dispersion with a design of formula(~ 1)\" ) }  if (   missing (  samplesVector ) )  {   samplesVector -   as.character (   seq_len (   ncol (  object ) ) ) }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {     mcols (  object ) $ allZero -    rowSums (   counts (  object ) ) ==  0 } # make a design matrix with a term for every sample # this would typically produce unidentifiable solution # for the GLM, but we add priors for all terms except # the intercept   samplesVector -   factor (  samplesVector , levels =   unique (  samplesVector ) )  if (   missing (  intercept ) )  {   samples -   factor (   c (  \"null_level\" ,   as.character (  samplesVector ) ) , levels =   c (  \"null_level\" ,   levels (  samplesVector ) ) )   modelMatrix -    model.matrix (  ~  samples ) [  -  1 , ]   modelMatrixNames -   colnames (  modelMatrix )    modelMatrixNames [   modelMatrixNames ==  \"(Intercept)\" ] -  \"Intercept\" } else  { # or we want to set the intercept using the # provided intercept instead   samples -   factor (  samplesVector )  if (    length (  samples ) undefined  1 )  {   modelMatrix -   model.matrix (  ~   0 +  samples ) } else  {   modelMatrix -   matrix (  1 , ncol =  1 )   modelMatrixNames -  \"samples1\" }   modelMatrixNames -   colnames (  modelMatrix )  if (  !   is.null (   normalizationFactors (  object ) ) )  {   nf -   normalizationFactors (  object ) } else  {   sf -   sizeFactors (  object )   nf -   matrix (   rep (  sf , each =   nrow (  object ) ) , ncol =   ncol (  object ) ) } # if the intercept is not finite, these rows # were all zero. here we put a small value instead   intercept -   as.numeric (  intercept )   infiniteIntercept -  !   is.finite (  intercept )    intercept [  infiniteIntercept ] -  -  10    normalizationFactors (  object ) -   nf *   2 ^  intercept # we set the intercept, so replace the all zero # column with the rows which were all zero # in the previous dataset     mcols (  object ) $ allZero -  infiniteIntercept } # only continue on the rows with non-zero row sums   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # if a prior sigma squared not provided, estimate this # by the variance of log2 counts plus a pseudocount  if (   missing (  betaPriorVar ) )  {   logCounts -   log2 (    counts (  objectNZ , normalized =  TRUE ) +  0.5 )   logFoldChangeMatrix -   logCounts -   rowMeans (  logCounts )   betaPriorVar -   var (   as.numeric (  logFoldChangeMatrix ) ) }   stopifnot (    length (  betaPriorVar ) ==  1 )   lambda -   1 /   rep (  betaPriorVar ,   ncol (  modelMatrix ) ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%  modelMatrixNames )  {    lambda [   which (   modelMatrixNames ==  \"Intercept\" ) ] -  1e-6 }   fit -   fitNbinomGLMs ( object =  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE , alpha_hat =    mcols (  objectNZ ) $ dispFit , betaTol =  1e-4 , useOptim =  FALSE , useQR =  TRUE )   normalizedDataNZ -   t (   modelMatrix %*%   t (   fit $ betaMatrix ) )   normalizedData -   buildMatrixWithZeroRows (  normalizedDataNZ ,    mcols (  object ) $ allZero ) # add back in the intercept, if finite  if (  !   missing (  intercept ) )  {   normalizedData -   normalizedData +   ifelse (  infiniteIntercept ,  0 ,  intercept ) }    colnames (  normalizedData ) -   colnames (  object )    attr (  normalizedData ,  \"betaPriorVar\" ) -  betaPriorVar  if (   \"Intercept\" %in%  modelMatrixNames )  {   fittedInterceptNZ -    fit $ betaMatrix [ ,   which (   modelMatrixNames ==  \"Intercept\" ) , drop =  FALSE ]   fittedIntercept -   buildMatrixWithNARows (  fittedInterceptNZ ,    mcols (  object ) $ allZero )    fittedIntercept [   is.na (  fittedIntercept ) ] -  -  Inf    attr (  normalizedData ,  \"intercept\" ) -  fittedIntercept }  normalizedData } ",
    "filename": "rlogTransformation.txt"
  }
}

5.
{
  "old_function": {
    "name": "estimateSizeFactors",
    "representation": "estimateSizeFactors",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , locfunc = median )",
    "body": "{    sizeFactors (  object ) -   estimateSizeFactorsForMatrix (   counts (  object ) ,  locfunc )  object } ",
    "replacementFunction": "estimateSizeFactors.DESeqDataSet",
    "filename": "methods.txt"
  },
  "new_function": {
    "name": "estimateSizeFactors",
    "representation": "estimateSizeFactors",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , locfunc = median , geoMeans )",
    "body": "{    sizeFactors (  object ) -   estimateSizeFactorsForMatrix (   counts (  object ) ,  locfunc , geoMeans =  geoMeans )  object } ",
    "replacementFunction": "estimateSizeFactors.DESeqDataSet",
    "filename": "methods.txt"
  }
}



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , betaPrior = TRUE , pAdjustMethod = \"BH\" , quiet = FALSE )",
    "body": "{  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object )  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"fitting generalized linear model\" )   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , pAdjustMethod =  pAdjustMethod , quiet =  quiet )  object } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , test = c ( \"Wald\" , \"LRT\" ) , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , betaPrior = TRUE , full = design ( object ) , reduced , quiet = FALSE )",
    "body": "{  if (   missing (  test ) )  {   test -   test [  1 ] }   stopifnot (     length (  test ) ==  1 undefined   test %in%   c (  \"Wald\" ,  \"LRT\" ) )  if (   !   is.null (   sizeFactors (  object ) ) ||  !   is.null (   normalizationFactors (  object ) ) )  {  if (  !  quiet )  {  if (  !   is.null (   normalizationFactors (  object ) ) )  {   message (  \"using pre-existing normalization factors\" ) } else  {   message (  \"using pre-existing size factors\" ) } } } else  {  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object ) }  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"fitting model and testing\" )  if (   test ==  \"Wald\" )  {   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , quiet =  quiet ) } else  if (   test ==  \"LRT\" )  {   object -   nbinomLRT (  object , full =  full , reduced =  reduced , quiet =  quiet ) }  object } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "makeExampleDESeqDataSet",
    "representation": "makeExampleDESeqDataSet",
    "parameters": "function ( n = 1000 , m = 10 , betaSd = 0 , interceptMean = 4 , interceptSd = 2 , dispMeanRel = function ( x ) 4 / x + .1 , sizeFactors = rep ( 1 , m ) )",
    "body": "{   beta -   cbind (   rnorm (  n ,  interceptMean ,  interceptSd ) ,   rnorm (  n ,  0 ,  betaSd ) )   dispersion -   dispMeanRel (   2 ^  (   beta [ ,  1 ] ) )   colData -   DataFrame ( sample =   paste (  \"sample\" ,   1 :  m , sep =  \"\" ) , condition =   factor (   rep (   c (  \"A\" ,  \"B\" ) , times =   c (   ceiling (   m /  2 ) ,   floor (   m /  2 ) ) ) ) )   x -   model.matrix (  ~   colData $ condition )   mu -    2 ^  (   t (   x %*%   t (  beta ) ) ) *   rep (  sizeFactors , each =  n )   countData -   matrix (   rnbinom (   m *  n , mu =  mu , size =   1 /  dispersion ) , ncol =  m )    rownames (  colData ) -   colData $ sample   rowData -   GRanges (  \"1\" ,   IRanges ( start =    (    1 :  n -  1 ) *  100 +  1 , width =  100 ) )    names (  rowData ) -   paste0 (  \"feature\" ,   1 :  n )   object -   DESeqDataSetFromMatrix ( countData =  countData , colData =  colData , design =   formula (  ~  condition ) , rowData =  rowData )   trueVals -   DataFrame ( trueIntercept =   beta [ ,  1 ] , trueBeta =   beta [ ,  2 ] , trueDisp =  dispersion )    mcols (  trueVals ) -   DataFrame ( type =   rep (  \"input\" ,   ncol (  trueVals ) ) , description =   c (  \"simulated intercept values\" ,  \"simulated beta values\" ,  \"simulated dispersion values\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  trueVals )  object } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "makeExampleDESeqDataSet",
    "representation": "makeExampleDESeqDataSet",
    "parameters": "function ( n = 1000 , m = 12 , betaSD = 0 , interceptMean = 4 , interceptSD = 2 , dispMeanRel = function ( x ) 4 / x + .1 , sizeFactors = rep ( 1 , m ) )",
    "body": "{   beta -   cbind (   rnorm (  n ,  interceptMean ,  interceptSD ) ,   rnorm (  n ,  0 ,  betaSD ) )   dispersion -   dispMeanRel (   2 ^  (   beta [ ,  1 ] ) )   colData -   DataFrame ( sample =   paste (  \"sample\" ,   1 :  m , sep =  \"\" ) , condition =   factor (   rep (   c (  \"A\" ,  \"B\" ) , times =   c (   ceiling (   m /  2 ) ,   floor (   m /  2 ) ) ) ) )  if (   m undefined  1 )  {   x -   model.matrix (  ~   colData $ condition ) } else  {   x -   cbind (   rep (  1 ,  m ) ,   rep (  0 ,  m ) ) }   mu -    2 ^  (   t (   x %*%   t (  beta ) ) ) *   rep (  sizeFactors , each =  n )   countData -   matrix (   rnbinom (   m *  n , mu =  mu , size =   1 /  dispersion ) , ncol =  m )    rownames (  colData ) -   colData $ sample   rowData -   GRanges (  \"1\" ,   IRanges ( start =    (    1 :  n -  1 ) *  100 +  1 , width =  100 ) )    names (  rowData ) -   paste0 (  \"feature\" ,   1 :  n )  if (   m undefined  1 )  {   designFormula -   formula (  ~  condition ) } else  {   designFormula -   formula (  ~  1 ) }   object -   DESeqDataSetFromMatrix ( countData =  countData , colData =  colData , design =  designFormula , rowData =  rowData )   trueVals -   DataFrame ( trueIntercept =   beta [ ,  1 ] , trueBeta =   beta [ ,  2 ] , trueDisp =  dispersion )    mcols (  trueVals ) -   DataFrame ( type =   rep (  \"input\" ,   ncol (  trueVals ) ) , description =   c (  \"simulated intercept values\" ,  \"simulated beta values\" ,  \"simulated dispersion values\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  trueVals ) # cleaning up environment from formula above   objNames -   ls ( )   objNames -   objNames [   objNames !=  \"object\" ]   rm ( list =  objNames )   rm (  \"objNames\" )  object } ",
    "filename": "core.txt"
  }
}

2.
{
  "old_function": {
    "name": "estimateSizeFactorsForMatrix",
    "representation": "estimateSizeFactorsForMatrix",
    "parameters": "function ( counts , locfunc = median )",
    "body": "{   loggeomeans -   rowMeans (   log (  counts ) )  if (   all (   is.infinite (  loggeomeans ) ) )  {   stop (  \"every gene contains at least one zero, cannot compute log geometric means\" ) }   apply (  counts ,  2 ,  function ( cnts )   exp (   locfunc (   (    log (  cnts ) -  loggeomeans ) [   is.finite (  loggeomeans ) ] ) ) ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateSizeFactorsForMatrix",
    "representation": "estimateSizeFactorsForMatrix",
    "parameters": "function ( counts , locfunc = median , geoMeans )",
    "body": "{  if (   missing (  geoMeans ) )  {   loggeomeans -   rowMeans (   log (  counts ) ) } else  {  if (    length (  geoMeans ) !=   nrow (  counts ) )  {   stop (  \"geoMeans should be as long as the number of rows of counts\" ) }   loggeomeans -   log (  geoMeans ) }  if (   all (   is.infinite (  loggeomeans ) ) )  {   stop (  \"every gene contains at least one zero, cannot compute log geometric means\" ) }   apply (  counts ,  2 ,  function ( cnts )   exp (   locfunc (   (    log (  cnts ) -  loggeomeans ) [    is.finite (  loggeomeans ) undefined  (   cnts undefined  0 ) ] ) ) ) } ",
    "filename": "core.txt"
  }
}

3.
{
  "old_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , priorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   \"dispersion\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated dispersions, removing these\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%   c (  \"dispersion\" ,  \"dispIter\" ,  \"dispIterAccept\" ,  \"dispConv\" ) ] }   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) )   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   useNotMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  10  if (    sum (  useNotMinDisp , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   minDisp *  10 )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } # estimate the variance of the distribution of the # log dispersion estimates around the fitted value   dispResiduals -    log (    mcols (  objectNZ ) $ dispGeneEst ) -   log (    mcols (  objectNZ ) $ dispFit )   useForPrior -  useNotMinDisp  if (    sum (  useForPrior , na.rm =  TRUE ) ==  0 )  {   stop (  \"no data found which is greater than minDisp, within quants, and converged in gene-wise estimates\" ) }   varLogDispEsts -   varLogDispEstsAll -    mad (   dispResiduals [  useForPrior ] , na.rm =  TRUE ) ^  2   m -   nrow (  modelMatrix )   p -   ncol (  modelMatrix ) # if the residual degrees of freedom is between 1 and 3, the distribution # of log dispersions is especially asymmetric and poorly estimated # by the MAD. we then use an alternate estimator, a monte carlo # approach to match the distribution  if (   (   (   m -  p ) =  3 ) undefined  (   m undefined  p ) )  { # in order to produce identical results we set the seed, # and so we need to save and restore the .Random.seed value first  if (   exists (  \".Random.seed\" ) )  {   oldRandomSeed -  .Random.seed }   set.seed (  2 ) # The residuals are the observed distribution we try to match   obsDist -   dispResiduals [  useForPrior ]   brks -    -  20 :  20 /  2   obsDist -   obsDist [    obsDist undefined   min (  brks ) undefined   obsDist undefined   max (  brks ) ]   obsVarGrid -   seq ( from =  0 , to =  8 , length =  200 )   obsDistHist -   hist (  obsDist , breaks =  brks , plot =  FALSE )   klDivs -   sapply (  obsVarGrid ,  function ( x )  {   randDist -     log (   rchisq (  1e4 , df =  (   m -  p ) ) ) +   rnorm (  1e4 ,  0 ,   sqrt (  x ) ) -   log (   m -  p )   randDist -   randDist [    randDist undefined   min (  brks ) undefined   randDist undefined   max (  brks ) ]   randDistHist -   hist (  randDist , breaks =  brks , plot =  FALSE )   z -   c (   obsDistHist $ density ,   randDistHist $ density )   small -   min (   z [   z undefined  0 ] )   kl -   sum (    obsDistHist $ density *  (    log (    obsDistHist $ density +  small ) -   log (    randDistHist $ density +  small ) ) )  kl } )   lofit -   loess (   klDivs ~  obsVarGrid , span =  .2 )   obsVarFineGrid -   seq ( from =  0 , to =  8 , length =  1000 )   lofitFitted -   predict (  lofit ,  obsVarFineGrid )   argminKL -   obsVarFineGrid [   which.min (  lofitFitted ) ]   expVarLogDisp -   trigamma (   (   m -  p ) /  2 )   varLogDispEsts -   argminKL +  expVarLogDisp # finally, restore the .Random.seed if it existed beforehand  if (   exists (  \"oldRandomSeed\" ) )  {   .Random.seed -  oldRandomSeed } }    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts # estimate the expected sampling variance of the log estimates # Var(log(cX)) = Var(log(X)) # X ~ chi-squared with m - p degrees of freedom  if (   m undefined  p )  {   expVarLogDisp -   trigamma (   (   m -  p ) /  2 )    attr (   dispersionFunction (  object ) ,  \"expVarLogDisp\" ) -  expVarLogDisp # set the variance of the prior using these two estimates # with a minimum of .25   priorVarCalc -   pmax (  (   varLogDispEsts -  expVarLogDisp ) ,  .25 ) } else  { # we have m = p, so do not try to substract sampling variance   priorVarCalc -  varLogDispEsts } # fill in the calculated dispersion prior variance  if (   missing (  priorVar ) )  {   priorVar -  priorVarCalc }   stopifnot (    length (  priorVar ) ==  1 )    attr (   dispersionFunction (  object ) ,  \"priorVar\" ) -  priorVar # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  priorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one decade # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDisp ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  TRUE ) # prepare dispersions for storage in mcols(object)   dispersionFinal -   dispMAP -   exp (   dispResMAP $ log_alpha ) # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEstsAll )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispConv =  (    dispResMAP $ iter undefined  maxit ) , dispOutlier =  dispOutlier , dispMAP =  dispMAP )  if (   any (  !   resultsList $ dispConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   resultsList $ dispConv ) ,  \"rows did not converge in dispersion, labelled in mcols(object)$dispConv. Use larger maxit argument with estimateDispersions\" ) ) }   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"convergence of final estimate\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   \"dispersion\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated dispersions, removing these\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%   c (  \"dispersion\" ,  \"dispIter\" ,  \"dispIterAccept\" ,  \"dispConv\" ) ] }   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) )   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   useNotMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  10  if (    sum (  useNotMinDisp , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   minDisp *  10 )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } # estimate the variance of the distribution of the # log dispersion estimates around the fitted value   dispResiduals -    log (    mcols (  objectNZ ) $ dispGeneEst ) -   log (    mcols (  objectNZ ) $ dispFit )   useForPrior -  useNotMinDisp  if (    sum (  useForPrior , na.rm =  TRUE ) ==  0 )  {   stop (  \"no data found which is greater than minDisp, within quants, and converged in gene-wise estimates\" ) }   varLogDispEsts -   varLogDispEstsAll -    mad (   dispResiduals [  useForPrior ] , na.rm =  TRUE ) ^  2   m -   nrow (  modelMatrix )   p -   ncol (  modelMatrix ) # if the residual degrees of freedom is between 1 and 3, the distribution # of log dispersions is especially asymmetric and poorly estimated # by the MAD. we then use an alternate estimator, a monte carlo # approach to match the distribution  if (   (   (   m -  p ) =  3 ) undefined  (   m undefined  p ) )  { # in order to produce identical results we set the seed, # and so we need to save and restore the .Random.seed value first  if (   exists (  \".Random.seed\" ) )  {   oldRandomSeed -  .Random.seed }   set.seed (  2 ) # The residuals are the observed distribution we try to match   obsDist -   dispResiduals [  useForPrior ]   brks -    -  20 :  20 /  2   obsDist -   obsDist [    obsDist undefined   min (  brks ) undefined   obsDist undefined   max (  brks ) ]   obsVarGrid -   seq ( from =  0 , to =  8 , length =  200 )   obsDistHist -   hist (  obsDist , breaks =  brks , plot =  FALSE )   klDivs -   sapply (  obsVarGrid ,  function ( x )  {   randDist -     log (   rchisq (  1e4 , df =  (   m -  p ) ) ) +   rnorm (  1e4 ,  0 ,   sqrt (  x ) ) -   log (   m -  p )   randDist -   randDist [    randDist undefined   min (  brks ) undefined   randDist undefined   max (  brks ) ]   randDistHist -   hist (  randDist , breaks =  brks , plot =  FALSE )   z -   c (   obsDistHist $ density ,   randDistHist $ density )   small -   min (   z [   z undefined  0 ] )   kl -   sum (    obsDistHist $ density *  (    log (    obsDistHist $ density +  small ) -   log (    randDistHist $ density +  small ) ) )  kl } )   lofit -   loess (   klDivs ~  obsVarGrid , span =  .2 )   obsVarFineGrid -   seq ( from =  0 , to =  8 , length =  1000 )   lofitFitted -   predict (  lofit ,  obsVarFineGrid )   argminKL -   obsVarFineGrid [   which.min (  lofitFitted ) ]   expVarLogDisp -   trigamma (   (   m -  p ) /  2 )   varLogDispEsts -   argminKL +  expVarLogDisp # finally, restore the .Random.seed if it existed beforehand  if (   exists (  \"oldRandomSeed\" ) )  {   .Random.seed -  oldRandomSeed } }    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts # estimate the expected sampling variance of the log estimates # Var(log(cX)) = Var(log(X)) # X ~ chi-squared with m - p degrees of freedom  if (   m undefined  p )  {   expVarLogDisp -   trigamma (   (   m -  p ) /  2 )    attr (   dispersionFunction (  object ) ,  \"expVarLogDisp\" ) -  expVarLogDisp # set the variance of the prior using these two estimates # with a minimum of .25   dispPriorVarCalc -   pmax (  (   varLogDispEsts -  expVarLogDisp ) ,  .25 ) } else  { # we have m = p, so do not try to substract sampling variance   dispPriorVarCalc -  varLogDispEsts } # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  {   dispPriorVar -  dispPriorVarCalc }   stopifnot (    length (  dispPriorVar ) ==  1 )    attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" ) -  dispPriorVar # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one decade # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDisp ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  TRUE ) # prepare dispersions for storage in mcols(object)   dispersionFinal -   dispMAP -   exp (   dispResMAP $ log_alpha ) # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEstsAll )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispConv =  (    dispResMAP $ iter undefined  maxit ) , dispOutlier =  dispOutlier , dispMAP =  dispMAP )  if (   any (  !   resultsList $ dispConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   resultsList $ dispConv ) ,  \"rows did not converge in dispersion, labelled in mcols(object)$dispConv. Use larger maxit argument with estimateDispersions\" ) ) }   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"convergence of final estimate\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  }
}

4.
{
  "old_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , pAdjustMethod = \"BH\" , priorSigmaSq , cooksCutoff , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df )",
    "body": "{   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim )   H -   fit $ hat_diagonals }  if (  betaPrior )  { # we need the MLE betas to fit the prior variance # and for the hat matrix diagonals in order to # calculate Cook's distance   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit )   H -   fit $ hat_diagonals  if (   missing (  priorSigmaSq ) )  { # estimate the width of the prior on betas # excluding those rows with coefficients going to infinity. # if all betas are large, use a very large prior   priorSigmaSq -   apply (   fit $ betaMatrix ,  2 ,  function ( x )  {   useSmall -    abs (  x ) undefined  8  if (    sum (  useSmall ) ==  0 )  {   return (  1e6 ) } else  {   mean (    x [  useSmall ] ^  2 ) } } ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%   fit $ modelMatrixNames )  {    priorSigmaSq [   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] -  1e6 } } else  { # we are provided the prior variance: # check if the lambda is the correct length # given the design formula   p -   ncol (   fit $ modelMatrix )  if (    length (  priorSigmaSq ) !=  p )  {   stop (   paste0 (  \"priorSigmaSq should have length\" ,  p ) ) } }   lambda -   1 /  priorSigmaSq   fit -   fitNbinomGLMs (  objectNZ , lambda =  lambda , maxit =  maxit , useOptim =  useOptim ) }   m -   nrow (   fit $ modelMatrix )   p -   ncol (   fit $ modelMatrix ) # calculate Cook's distance  if (   missing (  cooksCutoff ) )  {   cooksCutoff -   qf (  .75 ,  p ,   m -  p ) }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -   qf (  .75 ,  p ,   m -  p ) }   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p )   looFullRank -   leaveOneOutFullRank (   fit $ modelMatrix )  if (   m undefined  p )  {   maxCooks -   apply (   cooks [ ,  looFullRank , drop =  FALSE ] ,  1 ,  max )   cooksOutlier -   maxCooks undefined  cooksCutoff } else  {   maxCooks -   rep (  NA ,   nrow (  objectNZ ) )   cooksOutlier -   rep (  FALSE ,   nrow (  objectNZ ) ) } # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )   modelMatrixNames -   fit $ modelMatrixNames # add betas, standard errors and Wald p-values to the object   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   priorVar -   attr (   dispersionFunction (  object ) ,  \"priorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames ) # Set to NA the p-values for genes that have one or more # samples with Cook's distance beyond the cutof  if (    is.numeric (  cooksCutoff ) |  cooksCutoff )  {    WaldPvalue [  cooksOutlier , ] -  NA } # if more than 1 row, we adjust p-values  if (    nrow (  WaldPvalue ) undefined  1 )  {   WaldAdjPvalue -   apply (  WaldPvalue ,  2 ,  p.adjust , method =  pAdjustMethod ) } else  {   WaldAdjPvalue -  WaldPvalue }    colnames (  WaldAdjPvalue ) -   paste0 (  \"WaldAdjPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   matrixToList (  WaldAdjPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks , cooksOutlier =  cooksOutlier ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )  if (  betaPrior )  {   coefInfo -   paste (  \"log2 fold change (MAP):\" ,  modelMatrixNamesSpaces ) } else  {   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces ) }   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"Wald test:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test:\" ,  modelMatrixNamesSpaces )   adjInfo -   paste (   paste (  \"Wald test,\" ,  pAdjustMethod ,  \"adj.:\" ) ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  adjInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ,  \"whether maxCooks ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{   stopifnot (    length (  maxit ) ==  1 )  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   H -   fit $ hat_diagonals # record the wide prior which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } # calculate the prior variance (on the log2 scale)  if (  betaPrior )  { # we need the MLE betas to fit the prior variance # and for the hat matrix diagonals in order to # calculate Cook's distance   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useQR =  useQR )   H -   fit $ hat_diagonals  if (   missing (  betaPriorVar ) )  { # estimate the variance of the prior on betas  if (    nrow (   fit $ betaMatrix ) undefined  1 )  {   betaPriorVar -   apply (   fit $ betaMatrix ,  2 ,  function ( x )  { # infinite betas are halted when |beta| # so this test removes them   useSmall -    abs (  x ) undefined  8 # if no more betas pass test, return wide prior  if (    sum (  useSmall ) ==  0 )  {   return (  1e6 ) } else  {   mean (    x [  useSmall ] ^  2 ) } } ) } else  {   betaPriorVar -   (   fit $ betaMatrix ) ^  2 } # except for intercept which we set to wide prior  if (   \"Intercept\" %in%   fit $ modelMatrixNames )  {    betaPriorVar [   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] -  1e6 } } else  { # else we are provided the prior variance: # check if the lambda is the correct length # given the design formula   p -   ncol (   fit $ modelMatrix )  if (    length (  betaPriorVar ) !=  p )  {   stop (   paste (  \"betaPriorVar should have length\" ,  p ) ) } }   lambda -   1 /  betaPriorVar   fit -   fitNbinomGLMs (  objectNZ , lambda =  lambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) } # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -   fit $ modelMatrix   m -   nrow (   fit $ modelMatrix )   p -   ncol (   fit $ modelMatrix ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,   fit $ modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )   modelMatrixNames -   fit $ modelMatrixNames # add betas, standard errors and Wald p-values to the object   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )  if (  betaPrior )  {   coefInfo -   paste (  \"log2 fold change (MAP):\" ,  modelMatrixNamesSpaces ) } else  {   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces ) }   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

5.
{
  "old_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , pAdjustMethod = \"BH\" , cooksCutoff , maxit = 100 , useOptim = TRUE , quiet = FALSE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"please provide a reduced formula for the likelihood ratio test, e.g. nbinomLRT(object, reduced = ~ 1)\" ) }  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) } # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix )  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim )   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim )   p -   ncol (  fullModelMatrix )   m -   nrow (  fullModelMatrix )   H -   fullModel $ hat_diagonals # calculate Cook's distance  if (   missing (  cooksCutoff ) )  {   cooksCutoff -   qf (  .75 ,  p ,   m -  p ) }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -   qf (  .75 ,  p ,   m -  p ) }   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p )   looFullRank -   leaveOneOutFullRank (  fullModelMatrix )  if (   m undefined  p )  {   maxCooks -   apply (   cooks [ ,  looFullRank , drop =  FALSE ] ,  1 ,  max )   cooksOutlier -   maxCooks undefined  cooksCutoff } else  {   maxCooks -   rep (  NA ,   nrow (  objectNZ ) )   cooksOutlier -   rep (  FALSE ,   nrow (  objectNZ ) ) } # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # Set to NA the p-values for genes that have one or more # samples with Cook's distance beyond the cutoff  if (    is.numeric (  cooksCutoff ) |  cooksCutoff )  {    LRTPvalue [  cooksOutlier ] -  NA } # continue storing LRT results   LRTAdjPvalue -   p.adjust (  LRTPvalue , method =  pAdjustMethod )   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , LRTAdjPvalue =  LRTAdjPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks , cooksOutlier =  cooksOutlier ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" )   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )   adjInfo -   paste (  \"LRT p-value,\" ,  pAdjustMethod ,  \"adj.\" )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  adjInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ,  \"whether maxCooks ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"please provide a reduced formula for the likelihood ratio test, e.g. nbinomLRT(object, reduced = ~ 1)\" ) }  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) } # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix )  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )    attr (  object ,  \"modelMatrix\" ) -  fullModelMatrix   p -   ncol (  fullModelMatrix )   m -   nrow (  fullModelMatrix )   H -   fullModel $ hat_diagonals # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  fullModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" )   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

6.
{
  "old_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , name )",
    "body": "{  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) }  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }  if (    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) ) )  {   test -  \"Wald\" } else  if (   \"LRTPvalue\" %in%   names (   mcols (  object ) ) )  {   test -  \"LRT\" } else  {   stop (  \"cannot find appropriate results, for available names call 'resultsNames(object)'\" ) }   log2FoldChange -   coef (  object ,  name )   lfcSE -   coefSE (  object ,  name )   pvalue -   pvalues (  object ,  test ,  name )   padj -   padj (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  pvalue ,  padj )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"pvalue\" ,  \"padj\" )    rownames (  res ) -   rownames (  object )  res } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , name , contrast , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta = seq ( 0 , 0.95 , by = 0.05 ) , pAdjustMethod = \"BH\" )",
    "body": "{  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  theta ) undefined  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } # determine test type from the names of mcols(object)  if (    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) ) )  {   test -  \"Wald\" } else  if (   \"LRTPvalue\" %in%   names (   mcols (  object ) ) )  {   test -  \"LRT\" } else  {   stop (  \"cannot find appropriate results, for available names call 'resultsNames(object)'\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  { # must have performed the Wald test steps  if (   test !=  \"Wald\" )  {   stop (  \"using contrasts requires that the Wald test was performed\" ) }   res -   cleanContrast (  object ,  contrast ) } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"modelMatrix\" ) )   p -   ncol (   attr (  object ,  \"modelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # perform independent filtering  if (  independentFiltering )  {  if (   missing (  filter ) )  {   filter -   res $ baseMean }   stopifnot (    length (  filter ) ==   nrow (  object ) )   filtPadj -   filtered_p ( filter =  filter , test =   res $ pvalue , theta =  theta , method =  pAdjustMethod )   numRej -   colSums (   filtPadj undefined  alpha , na.rm =  TRUE )   j -   which.max (  numRej )    res $ padj -   filtPadj [ ,  j , drop =  TRUE ]   cutoffs -   quantile (  filter ,  theta )    attr (  res ,  \"filterThreshold\" ) -   cutoffs [  j ]    attr (  res ,  \"filterNumRej\" ) -   data.frame ( theta =  theta , numRej =  numRej ) } else  { # regular p-value adjustment # which does not include those rows which were removed # by maximum Cook's distance    res $ padj -   p.adjust (   res $ pvalue , method =  pAdjustMethod ) }      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" )  res } ",
    "filename": "core.txt"
  }
}

7.
{
  "old_function": {
    "name": "rlogTransformation",
    "representation": "rlogTransformation",
    "parameters": "function ( object , blind = TRUE , samplesVector , priorSigmasq , rowVarQuantile = .9 )",
    "body": "{  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   object -   estimateSizeFactors (  object ) }  if (  blind )  {    design (  object ) -  ~  1   object -   estimateDispersions (  object ) }  if (   is.null (   dispersions (  object ) ) )  {   object -   estimateDispersions (  object ) }   SummarizedExperiment ( assays =   rlogData (  object ,  samplesVector ,  priorSigmasq ,  rowVarQuantile ) , colData =   colData (  object ) , rowData =   rowData (  object ) , exptData =   exptData (  object ) ) } ",
    "filename": "rlogTransformation.txt"
  },
  "new_function": {
    "name": "rlogTransformation",
    "representation": "rlogTransformation",
    "parameters": "function ( object , blind = TRUE , samplesVector , betaPriorVar , intercept )",
    "body": "{  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   object -   estimateSizeFactors (  object ) }  if (  blind )  {    design (  object ) -  ~  1   object -   estimateDispersionsGeneEst (  object )   object -   estimateDispersionsFit (  object ) }  if (   is.null (    mcols (  object ) $ dispFit ) )  {   object -   estimateDispersionsGeneEst (  object )   object -   estimateDispersionsFit (  object ) }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }   rld -   rlogData (  object ,  samplesVector ,  betaPriorVar ,  intercept )   se -   SummarizedExperiment ( assays =  rld , colData =   colData (  object ) , rowData =   rowData (  object ) , exptData =   exptData (  object ) )    attr (  se ,  \"betaPriorVar\" ) -   attr (  rld ,  \"betaPriorVar\" )  if (  !   is.null (   attr (  rld ,  \"intercept\" ) ) )  {     mcols (  se ) $ rlogIntercept -   attr (  rld ,  \"intercept\" ) }  se } ",
    "filename": "rlogTransformation.txt"
  }
}

8.
{
  "old_function": {
    "name": "rlogData",
    "representation": "rlogData",
    "parameters": "function ( object , samplesVector , priorSigmasq , rowVarQuantile = .9 )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"first estimate dispersion with a design of formula(~ 1)\" ) }  if (   missing (  samplesVector ) )  {   samplesVector -   as.character (   seq_len (   ncol (  object ) ) ) }   stopifnot (    length (  rowVarQuantile ) ==  1 ) # make a design matrix with a term for every sample # this would typically produce unidentifiable solution # for the GLM, but we add priors for all terms except # the intercept   samplesVector -   factor (  samplesVector , levels =   unique (  samplesVector ) )   samples -   factor (   c (  \"null_level\" ,   as.character (  samplesVector ) ) , levels =   c (  \"null_level\" ,   levels (  samplesVector ) ) )   modelMatrix -    model.matrix (  ~  samples ) [  -  1 , ]   modelMatrixNames -   colnames (  modelMatrix ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # if a prior sigma squared not provided, calculate it # from betas calculated with a wide prior  if (   missing (  priorSigmasq ) )  {   lambda -   rep (  1e-4 ,   ncol (  modelMatrix ) )  if (   \"(Intercept)\" %in%  modelMatrixNames )  {    lambda [   which (   modelMatrixNames ==  \"(Intercept)\" ) ] -  1e-6 }   fit -   fitNbinomGLMs (  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE ) # use rows which have no zeros   useNoZeros -   apply (   counts (  objectNZ ) ,  1 ,  function ( x )   all (   x undefined  0 ) )  if (    sum (  useNoZeros ) ==  0 )  {   stop (  \"no rows found without zeros\" ) } # calculate priors on sample betas # take row means of squares of sample betas   betaRowMeanSquared -   rowMeans (     fit $ betaMatrix [ ,  -   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] ^  2 )   priorSigmasq -   quantile (   betaRowMeanSquared [  useNoZeros ] ,  rowVarQuantile ) }   stopifnot (    length (  priorSigmasq ) ==  1 )   lambda -   1 /   rep (  priorSigmasq ,   ncol (  modelMatrix ) ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%   fit $ modelMatrixNames )  {    lambda [   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] -  1e-6 }   fit -   fitNbinomGLMs (  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE )   normalizedDataNZ -   t (   modelMatrix %*%   t (   fit $ betaMatrix ) )   normalizedData -   buildMatrixWithNARows (  normalizedDataNZ ,    mcols (  object ) $ allZero )    colnames (  normalizedData ) -   colnames (  object )   return (  normalizedData ) } ",
    "filename": "rlogTransformation.txt"
  },
  "new_function": {
    "name": "rlogData",
    "representation": "rlogData",
    "parameters": "function ( object , samplesVector , betaPriorVar , intercept )",
    "body": "{  if (   is.null (    mcols (  object ) $ dispFit ) )  {   stop (  \"first estimate dispersion with a design of formula(~ 1)\" ) }  if (   missing (  samplesVector ) )  {   samplesVector -   as.character (   seq_len (   ncol (  object ) ) ) }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {     mcols (  object ) $ allZero -    rowSums (   counts (  object ) ) ==  0 } # make a design matrix with a term for every sample # this would typically produce unidentifiable solution # for the GLM, but we add priors for all terms except # the intercept   samplesVector -   factor (  samplesVector , levels =   unique (  samplesVector ) )  if (   missing (  intercept ) )  {   samples -   factor (   c (  \"null_level\" ,   as.character (  samplesVector ) ) , levels =   c (  \"null_level\" ,   levels (  samplesVector ) ) )   modelMatrix -    model.matrix (  ~  samples ) [  -  1 , ]   modelMatrixNames -   colnames (  modelMatrix )    modelMatrixNames [   modelMatrixNames ==  \"(Intercept)\" ] -  \"Intercept\" } else  { # or we want to set the intercept using the # provided intercept instead   samples -   factor (  samplesVector )  if (    length (  samples ) undefined  1 )  {   modelMatrix -   model.matrix (  ~   0 +  samples ) } else  {   modelMatrix -   matrix (  1 , ncol =  1 )   modelMatrixNames -  \"samples1\" }   modelMatrixNames -   colnames (  modelMatrix )  if (  !   is.null (   normalizationFactors (  object ) ) )  {   nf -   normalizationFactors (  object ) } else  {   sf -   sizeFactors (  object )   nf -   matrix (   rep (  sf , each =   nrow (  object ) ) , ncol =   ncol (  object ) ) } # if the intercept is not finite, these rows # were all zero. here we put a small value instead   intercept -   as.numeric (  intercept )   infiniteIntercept -  !   is.finite (  intercept )    intercept [  infiniteIntercept ] -  -  10    normalizationFactors (  object ) -   nf *   2 ^  intercept # we set the intercept, so replace the all zero # column with the rows which were all zero # in the previous dataset     mcols (  object ) $ allZero -  infiniteIntercept } # only continue on the rows with non-zero row sums   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # if a prior sigma squared not provided, estimate this # by the variance of log2 counts plus a pseudocount  if (   missing (  betaPriorVar ) )  {   logCounts -   log2 (    counts (  objectNZ , normalized =  TRUE ) +  0.5 )   logFoldChangeMatrix -   logCounts -   rowMeans (  logCounts )   betaPriorVar -   var (   as.numeric (  logFoldChangeMatrix ) ) }   stopifnot (    length (  betaPriorVar ) ==  1 )   lambda -   1 /   rep (  betaPriorVar ,   ncol (  modelMatrix ) ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%  modelMatrixNames )  {    lambda [   which (   modelMatrixNames ==  \"Intercept\" ) ] -  1e-6 }   fit -   fitNbinomGLMs ( object =  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE , alpha_hat =    mcols (  objectNZ ) $ dispFit , betaTol =  1e-4 , useOptim =  FALSE , useQR =  TRUE )   normalizedDataNZ -   t (   modelMatrix %*%   t (   fit $ betaMatrix ) )   normalizedData -   buildMatrixWithZeroRows (  normalizedDataNZ ,    mcols (  object ) $ allZero ) # add back in the intercept, if finite  if (  !   missing (  intercept ) )  {   normalizedData -   normalizedData +   ifelse (  infiniteIntercept ,  0 ,  intercept ) }    colnames (  normalizedData ) -   colnames (  object )    attr (  normalizedData ,  \"betaPriorVar\" ) -  betaPriorVar  if (   \"Intercept\" %in%  modelMatrixNames )  {   fittedInterceptNZ -    fit $ betaMatrix [ ,   which (   modelMatrixNames ==  \"Intercept\" ) , drop =  FALSE ]   fittedIntercept -   buildMatrixWithNARows (  fittedInterceptNZ ,    mcols (  object ) $ allZero )    fittedIntercept [   is.na (  fittedIntercept ) ] -  -  Inf    attr (  normalizedData ,  \"intercept\" ) -  fittedIntercept }  normalizedData } ",
    "filename": "rlogTransformation.txt"
  }
}

9.
{
  "old_function": {
    "name": "estimateSizeFactors",
    "representation": "estimateSizeFactors",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , locfunc = median )",
    "body": "{    sizeFactors (  object ) -   estimateSizeFactorsForMatrix (   counts (  object ) ,  locfunc )  object } ",
    "replacementFunction": "estimateSizeFactors.DESeqDataSet",
    "filename": "methods.txt"
  },
  "new_function": {
    "name": "estimateSizeFactors",
    "representation": "estimateSizeFactors",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , locfunc = median , geoMeans )",
    "body": "{    sizeFactors (  object ) -   estimateSizeFactorsForMatrix (   counts (  object ) ,  locfunc , geoMeans =  geoMeans )  object } ",
    "replacementFunction": "estimateSizeFactors.DESeqDataSet",
    "filename": "methods.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_2_13 deseq2_release_2_14

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_2_13 deseq2_release_2_14",
    "desc_release_old": "1.2.10",
    "desc_release_new": "1.4.5",
    "old_release_number": 1,
    "new_release_number": 2,
    "function_removals": 0,
    "function_additions": 9,
    "parameter_removals": 1,
    "parameter_additions": 6,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 7,
    "total_count": 7
}

##########
Functions Removed
##########



##########
Functions Added
##########

DESeqResults
collapseReplicates
fpkm
fpm
replaceOutliers
rlog
rlogDataFast
show
coef.DESeqDataSet


##########
Removed Non Default Parameters
##########

0.
{
  "old_function": {
    "name": "rlogData",
    "representation": "rlogData",
    "parameters": "function ( object , samplesVector , betaPriorVar , intercept )",
    "body": "{  if (   is.null (    mcols (  object ) $ dispFit ) )  {   stop (  \"first estimate dispersion with a design of formula(~ 1)\" ) }  if (   missing (  samplesVector ) )  {   samplesVector -   as.character (   seq_len (   ncol (  object ) ) ) }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {     mcols (  object ) $ allZero -    rowSums (   counts (  object ) ) ==  0 } # make a design matrix with a term for every sample # this would typically produce unidentifiable solution # for the GLM, but we add priors for all terms except # the intercept   samplesVector -   factor (  samplesVector , levels =   unique (  samplesVector ) )  if (   missing (  intercept ) )  {   samples -   factor (   c (  \"null_level\" ,   as.character (  samplesVector ) ) , levels =   c (  \"null_level\" ,   levels (  samplesVector ) ) )   modelMatrix -    model.matrix (  ~  samples ) [  -  1 , ]   modelMatrixNames -   colnames (  modelMatrix )    modelMatrixNames [   modelMatrixNames ==  \"(Intercept)\" ] -  \"Intercept\" } else  { # or we want to set the intercept using the # provided intercept instead   samples -   factor (  samplesVector )  if (    length (  samples ) undefined  1 )  {   modelMatrix -   model.matrix (  ~   0 +  samples ) } else  {   modelMatrix -   matrix (  1 , ncol =  1 )   modelMatrixNames -  \"samples1\" }   modelMatrixNames -   colnames (  modelMatrix )  if (  !   is.null (   normalizationFactors (  object ) ) )  {   nf -   normalizationFactors (  object ) } else  {   sf -   sizeFactors (  object )   nf -   matrix (   rep (  sf , each =   nrow (  object ) ) , ncol =   ncol (  object ) ) } # if the intercept is not finite, these rows # were all zero. here we put a small value instead   intercept -   as.numeric (  intercept )   infiniteIntercept -  !   is.finite (  intercept )    intercept [  infiniteIntercept ] -  -  10    normalizationFactors (  object ) -   nf *   2 ^  intercept # we set the intercept, so replace the all zero # column with the rows which were all zero # in the previous dataset     mcols (  object ) $ allZero -  infiniteIntercept } # only continue on the rows with non-zero row sums   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # if a prior sigma squared not provided, estimate this # by the variance of log2 counts plus a pseudocount  if (   missing (  betaPriorVar ) )  {   logCounts -   log2 (    counts (  objectNZ , normalized =  TRUE ) +  0.5 )   logFoldChangeMatrix -   logCounts -   rowMeans (  logCounts )   betaPriorVar -   var (   as.numeric (  logFoldChangeMatrix ) ) }   stopifnot (    length (  betaPriorVar ) ==  1 )   lambda -   1 /   rep (  betaPriorVar ,   ncol (  modelMatrix ) ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%  modelMatrixNames )  {    lambda [   which (   modelMatrixNames ==  \"Intercept\" ) ] -  1e-6 }   fit -   fitNbinomGLMs ( object =  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE , alpha_hat =    mcols (  objectNZ ) $ dispFit , betaTol =  1e-4 , useOptim =  FALSE , useQR =  TRUE )   normalizedDataNZ -   t (   modelMatrix %*%   t (   fit $ betaMatrix ) )   normalizedData -   buildMatrixWithZeroRows (  normalizedDataNZ ,    mcols (  object ) $ allZero ) # add back in the intercept, if finite  if (  !   missing (  intercept ) )  {   normalizedData -   normalizedData +   ifelse (  infiniteIntercept ,  0 ,  intercept ) }    colnames (  normalizedData ) -   colnames (  object )    attr (  normalizedData ,  \"betaPriorVar\" ) -  betaPriorVar  if (   \"Intercept\" %in%  modelMatrixNames )  {   fittedInterceptNZ -    fit $ betaMatrix [ ,   which (   modelMatrixNames ==  \"Intercept\" ) , drop =  FALSE ]   fittedIntercept -   buildMatrixWithNARows (  fittedInterceptNZ ,    mcols (  object ) $ allZero )    fittedIntercept [   is.na (  fittedIntercept ) ] -  -  Inf    attr (  normalizedData ,  \"intercept\" ) -  fittedIntercept }  normalizedData } ",
    "filename": "rlogTransformation.txt"
  },
  "new_function": {
    "name": "rlogData",
    "representation": "rlogData",
    "parameters": "function ( object , intercept , betaPriorVar )",
    "body": "{  if (   is.null (    mcols (  object ) $ dispFit ) )  {   stop (  \"first estimate dispersion with a design of formula(~ 1)\" ) }   samplesVector -   as.character (   seq_len (   ncol (  object ) ) )  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {     mcols (  object ) $ allZero -    rowSums (   counts (  object ) ) ==  0 }  if (  !   \"baseMean\" %in%   names (   mcols (  object ) ) )  {     mcols (  object ) $ baseMean -   rowMeans (   counts (  object , normalized =  TRUE ) ) } # make a design matrix with a term for every sample # this would typically produce unidentifiable solution # for the GLM, but we add priors for all terms except # the intercept   samplesVector -   factor (  samplesVector , levels =   unique (  samplesVector ) )  if (   missing (  intercept ) )  {   samples -   factor (   c (  \"null_level\" ,   as.character (  samplesVector ) ) , levels =   c (  \"null_level\" ,   levels (  samplesVector ) ) )   modelMatrix -    model.matrix (  ~  samples ) [  -  1 , ]   modelMatrixNames -   colnames (  modelMatrix )    modelMatrixNames [   modelMatrixNames ==  \"(Intercept)\" ] -  \"Intercept\" } else  { # or we want to set the intercept using the # provided intercept instead   samples -   factor (  samplesVector )  if (    length (  samples ) undefined  1 )  {   modelMatrix -   model.matrix (  ~   0 +  samples ) } else  {   modelMatrix -   matrix (  1 , ncol =  1 )   modelMatrixNames -  \"samples1\" }   modelMatrixNames -   colnames (  modelMatrix )  if (  !   is.null (   normalizationFactors (  object ) ) )  {   nf -   normalizationFactors (  object ) } else  {   sf -   sizeFactors (  object )   nf -   matrix (   rep (  sf , each =   nrow (  object ) ) , ncol =   ncol (  object ) ) } # if the intercept is not finite, these rows # were all zero. here we put a small value instead   intercept -   as.numeric (  intercept )   infiniteIntercept -  !   is.finite (  intercept )    intercept [  infiniteIntercept ] -  -  10    normalizationFactors (  object ) -   nf *   2 ^  intercept # we set the intercept, so replace the all zero # column with the rows which were all zero # in the previous dataset     mcols (  object ) $ allZero -  infiniteIntercept } # only continue on the rows with non-zero row sums   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   stopifnot (   all (  !   is.na (    mcols (  objectNZ ) $ dispFit ) ) ) # if a prior sigma squared not provided, estimate this # by the matching upper quantiles of the # log2 counts plus a pseudocount  if (   missing (  betaPriorVar ) )  {   logCounts -   log2 (    counts (  objectNZ , normalized =  TRUE ) +  0.5 )   baseMean -   rowMeans (   counts (  objectNZ , normalized =  TRUE ) )   logFoldChangeMatrix -   logCounts -   log2 (   baseMean +  0.5 )   logFoldChangeVector -   as.numeric (  logFoldChangeMatrix )   betaPriorVar -   matchUpperQuantileForVariance (  logFoldChangeVector ) }   stopifnot (    length (  betaPriorVar ) ==  1 )   lambda -   1 /   rep (  betaPriorVar ,   ncol (  modelMatrix ) ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%  modelMatrixNames )  {    lambda [   which (   modelMatrixNames ==  \"Intercept\" ) ] -  1e-6 }   fit -   fitNbinomGLMs ( object =  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE , alpha_hat =    mcols (  objectNZ ) $ dispFit , betaTol =  1e-4 , useOptim =  FALSE , useQR =  TRUE )   normalizedDataNZ -   t (   modelMatrix %*%   t (   fit $ betaMatrix ) )   normalizedData -   buildMatrixWithZeroRows (  normalizedDataNZ ,    mcols (  object ) $ allZero ) # add back in the intercept, if finite  if (  !   missing (  intercept ) )  {   normalizedData -   normalizedData +   ifelse (  infiniteIntercept ,  0 ,  intercept ) }    colnames (  normalizedData ) -   colnames (  object )    attr (  normalizedData ,  \"betaPriorVar\" ) -  betaPriorVar  if (   \"Intercept\" %in%  modelMatrixNames )  {   fittedInterceptNZ -    fit $ betaMatrix [ ,   which (   modelMatrixNames ==  \"Intercept\" ) , drop =  FALSE ]   fittedIntercept -   buildMatrixWithNARows (  fittedInterceptNZ ,    mcols (  object ) $ allZero )    fittedIntercept [   is.na (  fittedIntercept ) ] -  -  Inf    attr (  normalizedData ,  \"intercept\" ) -  fittedIntercept }  normalizedData } ",
    "filename": "rlogTransformation.txt"
  }
}



##########
Added Non Default Parameters
##########

0.
{
  "old_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , test = c ( \"Wald\" , \"LRT\" ) , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , betaPrior = TRUE , full = design ( object ) , reduced , quiet = FALSE )",
    "body": "{  if (   missing (  test ) )  {   test -   test [  1 ] }   stopifnot (     length (  test ) ==  1 undefined   test %in%   c (  \"Wald\" ,  \"LRT\" ) )  if (   !   is.null (   sizeFactors (  object ) ) ||  !   is.null (   normalizationFactors (  object ) ) )  {  if (  !  quiet )  {  if (  !   is.null (   normalizationFactors (  object ) ) )  {   message (  \"using pre-existing normalization factors\" ) } else  {   message (  \"using pre-existing size factors\" ) } } } else  {  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object ) }  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"fitting model and testing\" )  if (   test ==  \"Wald\" )  {   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , quiet =  quiet ) } else  if (   test ==  \"LRT\" )  {   object -   nbinomLRT (  object , full =  full , reduced =  reduced , quiet =  quiet ) }  object } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , test = c ( \"Wald\" , \"LRT\" ) , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , betaPrior , full = design ( object ) , reduced , quiet = FALSE , minReplicatesForReplace = 7 , modelMatrixType )",
    "body": "{  if (   missing (  test ) )  {   test -   match.arg (  test , choices =   c (  \"Wald\" ,  \"LRT\" ) ) }  if (   missing (  betaPrior ) )  {   betaPrior -   test ==  \"Wald\" }  if (   test ==  \"LRT\" )  {   checkLRT (  full ,  reduced ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior  if (   !   is.null (   sizeFactors (  object ) ) ||  !   is.null (   normalizationFactors (  object ) ) )  {  if (  !  quiet )  {  if (  !   is.null (   normalizationFactors (  object ) ) )  {   message (  \"using pre-existing normalization factors\" ) } else  {   message (  \"using pre-existing size factors\" ) } } } else  {  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object ) }  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"fitting model and testing\" )  if (   test ==  \"Wald\" )  {   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , quiet =  quiet , modelMatrixType =  modelMatrixType ) } else  if (   test ==  \"LRT\" )  {   object -   nbinomLRT (  object , full =  full , reduced =  reduced , betaPrior =  betaPrior , quiet =  quiet , modelMatrixType =  modelMatrixType ) } # if there are sufficient replicates, then pass through to refitting function  if (   any (   nOrMoreInCell (   attr (  object ,  \"modelMatrix\" ) ,  minReplicatesForReplace ) ) )  {   object -   refitWithoutOutliers (  object ,  test ,  betaPrior ,  full ,  reduced ,  quiet ,  minReplicatesForReplace ,  modelMatrixType ) }  object } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "estimateDispersionsGeneEst",
    "representation": "estimateDispersionsGeneEst",
    "parameters": "function ( object , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE )",
    "body": "{  if (   \"dispGeneEst\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated gene-wise dispersions, removing these\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) ==  \"dispGeneEst\" ] }   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (    log (   minDisp /  10 ) =  -  30 )  {   stop (  \"for computational stability, log(minDisp/10) should be above -30\" ) }   object -   getBaseMeansAndVariances (  object )  if (  !   is.null (   normalizationFactors (  object ) ) )  {   xim -   mean (   1 /   colMeans (   normalizationFactors (  object ) ) ) } else  {   xim -   mean (   1 /   sizeFactors (  object ) ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   bv -    mcols (  objectNZ ) $ baseVar   bm -    mcols (  objectNZ ) $ baseMean # this rough dispersion estimate (alpha_hat) # is for estimating beta and mu # and for the initial starting point for line search   alpha_hat -   pmax (  minDisp ,   (   bv -   xim *  bm ) /   bm ^  2 ) # fitNbinomGLMs returns mu and modelMatrix   fit -   fitNbinomGLMs (  objectNZ , alpha_hat =  alpha_hat ) # use of kappa_0 in backtracking search # initial proposal = log(alpha) + kappa_0 * deriv. of log lik. w.r.t. log(alpha) # use log(minDisp/10) to stop if dispersions going to -infinity   dispRes -   fitDisp ( ySEXP =   counts (  objectNZ ) , xSEXP =   fit $ modelMatrix , mu_hatSEXP =   fit $ mu , log_alphaSEXP =   log (  alpha_hat ) , log_alpha_prior_meanSEXP =   log (  alpha_hat ) , log_alpha_prior_sigmasqSEXP =  1 , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  FALSE )  if (    mean (    dispRes $ iter undefined  maxit ) undefined  .5 )  {   warning (  \"in calling estimateDispersionsGeneEst, less than 50% of gene-wise estimates converged. Use larger maxit argument with estimateDispersions\" ) } # dont accept moves if the log posterior did not # increase by more than one millionth, # and set the small estimates to the minimum dispersion   dispGeneEst -   exp (   dispRes $ log_alpha )   noIncrease -    dispRes $ last_lp undefined    dispRes $ initial_lp +    abs (   dispRes $ initial_lp ) /  1e6    dispGeneEst [   which (  noIncrease ) ] -   alpha_hat [   which (  noIncrease ) ]   dispGeneEst -   pmax (  dispGeneEst ,  minDisp )   dispGeneEstConv -    dispRes $ iter undefined  maxit   dispDataFrame -   buildDataFrameWithNARows (   list ( dispGeneEst =  dispGeneEst , dispGeneEstConv =  dispGeneEstConv ) ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"gene-wise estimates of dispersion\" ,  \"gene-wise dispersion estimate convergence\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsGeneEst",
    "representation": "estimateDispersionsGeneEst",
    "parameters": "function ( object , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE , modelMatrix , niter = 1 )",
    "body": "{  if (   \"dispGeneEst\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated gene-wise dispersions, removing these\" )   removeCols -   c (  \"dispGeneEst\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols ] }   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (    log (   minDisp /  10 ) =  -  30 )  {   stop (  \"for computational stability, log(minDisp/10) should be above -30\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   missing (  modelMatrix ) )  {   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) ) } else  {   message (  \"using supplied model matrix\" ) }   object -   getBaseMeansAndVariances (  object ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # this rough dispersion estimate (alpha_hat) # is for estimating mu # and for the initial starting point for line search # first check if model matrix is full rank   fullRank -     qr (  modelMatrix ) $ rank ==   ncol (  modelMatrix )   alpha_hat -  if (  fullRank )  { # if full rank use this estimator which compares normalized counts to mu   roughDisp -   roughDispEstimate ( y =   counts (  objectNZ , normalized =  TRUE ) , x =  modelMatrix )   momentsDisp -   momentsDispEstimate (  objectNZ )   pmin (  roughDisp ,  momentsDisp ) } else  { # if not full rank use method of moments across all samples   momentsDispEstimate (  objectNZ ) } # bound the rough estimated alpha between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   alpha_hat -   alpha_hat_new -   alpha_init -   pmin (   pmax (  minDisp ,  alpha_hat ) ,  maxDisp )   stopifnot (     length (  niter ) ==  1 undefined   niter undefined  0 ) # iterate between mean and dispersion estimation (niter) times   fitidx -   rep (  TRUE ,   nrow (  objectNZ ) )   mu -   matrix (  0 , nrow =   nrow (  objectNZ ) , ncol =   ncol (  objectNZ ) )   dispIter -   numeric (   nrow (  objectNZ ) )  for  ( iter in   seq_len (  niter ) )  {   fit -   fitNbinomGLMs (   objectNZ [  fitidx , , drop =  FALSE ] , alpha_hat =   alpha_hat [  fitidx ] , modelMatrix =  modelMatrix )   fitMu -   fit $ mu    fitMu [   fitMu undefined  .01 ] -  .01    mu [  fitidx , ] -  fitMu # use of kappa_0 in backtracking search # initial proposal = log(alpha) + kappa_0 * deriv. of log lik. w.r.t. log(alpha) # use log(minDisp/10) to stop if dispersions going to -infinity   dispRes -   fitDisp ( ySEXP =    counts (  objectNZ ) [  fitidx , , drop =  FALSE ] , xSEXP =   fit $ modelMatrix , mu_hatSEXP =  fitMu , log_alphaSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_meanSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_sigmasqSEXP =  1 , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  FALSE )    dispIter [  fitidx ] -   dispRes $ iter    alpha_hat_new [  fitidx ] -   pmin (   exp (   dispRes $ log_alpha ) ,  maxDisp ) # only rerun those rows which moved   fitidx -    abs (    log (  alpha_hat_new ) -   log (  alpha_hat ) ) undefined  .05   alpha_hat -  alpha_hat_new  if (    sum (  fitidx ) ==  0 )  break } # dont accept moves if the log posterior did not # increase by more than one millionth, # and set the small estimates to the minimum dispersion   dispGeneEst -  alpha_hat  if (   niter ==  1 )  {   noIncrease -    dispRes $ last_lp undefined    dispRes $ initial_lp +    abs (   dispRes $ initial_lp ) /  1e6    dispGeneEst [   which (  noIncrease ) ] -   alpha_init [   which (  noIncrease ) ] }   dispGeneEstConv -   dispIter undefined  maxit # when lacking convergence from the C++ routine # we use an R function to estimate dispersions. # This finds the maximum of a smooth curve along a # grid of posterior evaluations   refitDisp -   !  dispGeneEstConv undefined   dispGeneEst undefined   minDisp *  10  if (    sum (  refitDisp ) undefined  0 )  {   dispInR -   fitDispInR ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =   rep (  0 ,   sum (  refitDisp ) ) , logAlphaPriorSigmaSq =  1 , usePrior =  FALSE )    dispGeneEst [  refitDisp ] -  dispInR }   dispGeneEst -   pmin (   pmax (  dispGeneEst ,  minDisp ) ,  maxDisp )   dispDataFrame -   buildDataFrameWithNARows (   list ( dispGeneEst =  dispGeneEst ) ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"gene-wise estimates of dispersion\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (  mu ,    mcols (  object ) $ allZero )   return (  object ) } ",
    "filename": "core.txt"
  }
}

2.
{
  "old_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   \"dispersion\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated dispersions, removing these\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%   c (  \"dispersion\" ,  \"dispIter\" ,  \"dispIterAccept\" ,  \"dispConv\" ) ] }   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) )   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   useNotMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  10  if (    sum (  useNotMinDisp , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   minDisp *  10 )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } # estimate the variance of the distribution of the # log dispersion estimates around the fitted value   dispResiduals -    log (    mcols (  objectNZ ) $ dispGeneEst ) -   log (    mcols (  objectNZ ) $ dispFit )   useForPrior -  useNotMinDisp  if (    sum (  useForPrior , na.rm =  TRUE ) ==  0 )  {   stop (  \"no data found which is greater than minDisp, within quants, and converged in gene-wise estimates\" ) }   varLogDispEsts -   varLogDispEstsAll -    mad (   dispResiduals [  useForPrior ] , na.rm =  TRUE ) ^  2   m -   nrow (  modelMatrix )   p -   ncol (  modelMatrix ) # if the residual degrees of freedom is between 1 and 3, the distribution # of log dispersions is especially asymmetric and poorly estimated # by the MAD. we then use an alternate estimator, a monte carlo # approach to match the distribution  if (   (   (   m -  p ) =  3 ) undefined  (   m undefined  p ) )  { # in order to produce identical results we set the seed, # and so we need to save and restore the .Random.seed value first  if (   exists (  \".Random.seed\" ) )  {   oldRandomSeed -  .Random.seed }   set.seed (  2 ) # The residuals are the observed distribution we try to match   obsDist -   dispResiduals [  useForPrior ]   brks -    -  20 :  20 /  2   obsDist -   obsDist [    obsDist undefined   min (  brks ) undefined   obsDist undefined   max (  brks ) ]   obsVarGrid -   seq ( from =  0 , to =  8 , length =  200 )   obsDistHist -   hist (  obsDist , breaks =  brks , plot =  FALSE )   klDivs -   sapply (  obsVarGrid ,  function ( x )  {   randDist -     log (   rchisq (  1e4 , df =  (   m -  p ) ) ) +   rnorm (  1e4 ,  0 ,   sqrt (  x ) ) -   log (   m -  p )   randDist -   randDist [    randDist undefined   min (  brks ) undefined   randDist undefined   max (  brks ) ]   randDistHist -   hist (  randDist , breaks =  brks , plot =  FALSE )   z -   c (   obsDistHist $ density ,   randDistHist $ density )   small -   min (   z [   z undefined  0 ] )   kl -   sum (    obsDistHist $ density *  (    log (    obsDistHist $ density +  small ) -   log (    randDistHist $ density +  small ) ) )  kl } )   lofit -   loess (   klDivs ~  obsVarGrid , span =  .2 )   obsVarFineGrid -   seq ( from =  0 , to =  8 , length =  1000 )   lofitFitted -   predict (  lofit ,  obsVarFineGrid )   argminKL -   obsVarFineGrid [   which.min (  lofitFitted ) ]   expVarLogDisp -   trigamma (   (   m -  p ) /  2 )   varLogDispEsts -   argminKL +  expVarLogDisp # finally, restore the .Random.seed if it existed beforehand  if (   exists (  \"oldRandomSeed\" ) )  {   .Random.seed -  oldRandomSeed } }    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts # estimate the expected sampling variance of the log estimates # Var(log(cX)) = Var(log(X)) # X ~ chi-squared with m - p degrees of freedom  if (   m undefined  p )  {   expVarLogDisp -   trigamma (   (   m -  p ) /  2 )    attr (   dispersionFunction (  object ) ,  \"expVarLogDisp\" ) -  expVarLogDisp # set the variance of the prior using these two estimates # with a minimum of .25   dispPriorVarCalc -   pmax (  (   varLogDispEsts -  expVarLogDisp ) ,  .25 ) } else  { # we have m = p, so do not try to substract sampling variance   dispPriorVarCalc -  varLogDispEsts } # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  {   dispPriorVar -  dispPriorVarCalc }   stopifnot (    length (  dispPriorVar ) ==  1 )    attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" ) -  dispPriorVar # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one decade # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDisp ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  TRUE ) # prepare dispersions for storage in mcols(object)   dispersionFinal -   dispMAP -   exp (   dispResMAP $ log_alpha ) # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEstsAll )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispConv =  (    dispResMAP $ iter undefined  maxit ) , dispOutlier =  dispOutlier , dispMAP =  dispMAP )  if (   any (  !   resultsList $ dispConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   resultsList $ dispConv ) ,  \"rows did not converge in dispersion, labelled in mcols(object)$dispConv. Use larger maxit argument with estimateDispersions\" ) ) }   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"convergence of final estimate\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , modelMatrix , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   \"dispersion\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated dispersions, removing these\" )   removeCols -   c (  \"dispersion\" ,  \"dispOutlier\" ,  \"dispMAP\" ,  \"dispIter\" ,  \"dispConv\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols ] }  if (   missing (  modelMatrix ) )  {   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) ) } else  {   message (  \"using supplied model matrix\" ) }   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  {   aboveMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  100  if (    sum (  aboveMinDisp , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   minDisp *  10 )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )    attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" ) -  0.25   return (  object ) }   resList -   estimateDispersionPriorVar (  objectNZ ,  aboveMinDisp ,  modelMatrix )   dispPriorVar -   resList $ dispPriorVar   varLogDispEsts -   resList $ varLogDispEsts   expVarLogDisp -   resList $ expVarLogDisp    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts    attr (   dispersionFunction (  object ) ,  \"expVarLogDisp\" ) -  expVarLogDisp }   stopifnot (    length (  dispPriorVar ) ==  1 )    attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" ) -  dispPriorVar # could be coming from a previous run, and need to import varLogDispEsts # for the calculation of outliers  if (  !   is.null (   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) ) )  {   varLogDispEsts -   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) } else  { # provided dispPriorVar, so need to calculate observed varLogDispEsts # this code is copied from estimateDispPriorVar()   aboveMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  100   stopifnot (    sum (  aboveMinDisp , na.rm =  TRUE ) undefined  0 )   dispResiduals -    log (    mcols (  objectNZ ) $ dispGeneEst ) -   log (    mcols (  objectNZ ) $ dispFit )   varLogDispEsts -    mad (   dispResiduals [  aboveMinDisp ] , na.rm =  TRUE ) ^  2    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts } # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one order of magnitude # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDisp ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  TRUE ) # prepare dispersions for storage in mcols(object)   dispMAP -   exp (   dispResMAP $ log_alpha ) # when lacking convergence from the C++ routine # we use an R function to estimate dispersions. # This finds the maximum of a smooth curve along a # grid of posterior evaluations   dispConv -    dispResMAP $ iter undefined  maxit   refitDisp -  !  dispConv  if (    sum (  refitDisp ) undefined  0 )  {   dispInR -   fitDispInR ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =    log (    mcols (  objectNZ ) $ dispFit ) [  refitDisp ] , logAlphaPriorSigmaSq =  log_alpha_prior_sigmasq , usePrior =  TRUE )    dispMAP [  refitDisp ] -  dispInR }   dispersionFinal -  dispMAP # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEsts )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispOutlier =  dispOutlier , dispMAP =  dispMAP )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  }
}

3.
{
  "old_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{   stopifnot (    length (  maxit ) ==  1 )  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   H -   fit $ hat_diagonals # record the wide prior which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } # calculate the prior variance (on the log2 scale)  if (  betaPrior )  { # we need the MLE betas to fit the prior variance # and for the hat matrix diagonals in order to # calculate Cook's distance   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useQR =  useQR )   H -   fit $ hat_diagonals  if (   missing (  betaPriorVar ) )  { # estimate the variance of the prior on betas  if (    nrow (   fit $ betaMatrix ) undefined  1 )  {   betaPriorVar -   apply (   fit $ betaMatrix ,  2 ,  function ( x )  { # infinite betas are halted when |beta| # so this test removes them   useSmall -    abs (  x ) undefined  8 # if no more betas pass test, return wide prior  if (    sum (  useSmall ) ==  0 )  {   return (  1e6 ) } else  {   mean (    x [  useSmall ] ^  2 ) } } ) } else  {   betaPriorVar -   (   fit $ betaMatrix ) ^  2 } # except for intercept which we set to wide prior  if (   \"Intercept\" %in%   fit $ modelMatrixNames )  {    betaPriorVar [   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] -  1e6 } } else  { # else we are provided the prior variance: # check if the lambda is the correct length # given the design formula   p -   ncol (   fit $ modelMatrix )  if (    length (  betaPriorVar ) !=  p )  {   stop (   paste (  \"betaPriorVar should have length\" ,  p ) ) } }   lambda -   1 /  betaPriorVar   fit -   fitNbinomGLMs (  objectNZ , lambda =  lambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) } # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -   fit $ modelMatrix   m -   nrow (   fit $ modelMatrix )   p -   ncol (   fit $ modelMatrix ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,   fit $ modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )   modelMatrixNames -   fit $ modelMatrixNames # add betas, standard errors and Wald p-values to the object   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )  if (  betaPrior )  {   coefInfo -   paste (  \"log2 fold change (MAP):\" ,  modelMatrixNamesSpaces ) } else  {   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces ) }   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE , betaPriorUpperQuantile = .05 )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 )   stopifnot (      length (  betaPriorUpperQuantile ) ==  1 undefined   betaPriorUpperQuantile undefined  0 undefined   betaPriorUpperQuantile undefined  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  modelMatrixType ) )  {   blindDesign -    design (  object ) ==   formula (  ~  1 )   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # if there are interaction terms present in the design # then we should only use the prior on the interaction terms  if (    any (   termsOrder undefined  2 ) undefined   modelMatrixType ==  \"expanded\" )  {   stop (  \"interactions higher than 2nd order and usage of expanded model matrices\r\nhas not been implemented. we recommend instead using a likelihood\r\nratio test, i.e. DESeq with argument test='LRT' and betaPrior=FALSE.\" ) }   priorOnlyInteraction -    interactionPresent undefined  betaPrior undefined   missing (  betaPriorVar )  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) }  if (  betaPrior )  {   priorFitList -   fitGLMsWithPrior ( objectNZ =  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , modelMatrixType =  modelMatrixType , betaPriorVar =  betaPriorVar , priorOnlyInteraction =  priorOnlyInteraction , upperQuantile =  betaPriorUpperQuantile )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix } # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType    attr (  object ,  \"test\" ) -  \"Wald\"   m -   nrow (  modelMatrix )   p -   ncol (  modelMatrix ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,   fit $ modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -  if (  betaPrior )  {   paste (  \"log2 fold change (MAP):\" ,  modelMatrixNamesSpaces ) } else  {   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces ) }   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

4.
{
  "old_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"please provide a reduced formula for the likelihood ratio test, e.g. nbinomLRT(object, reduced = ~ 1)\" ) }  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) } # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix )  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )    attr (  object ,  \"modelMatrix\" ) -  fullModelMatrix   p -   ncol (  fullModelMatrix )   m -   nrow (  fullModelMatrix )   H -   fullModel $ hat_diagonals # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  fullModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" )   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE , betaPriorUpperQuantile = .05 )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (      length (  betaPriorUpperQuantile ) ==  1 undefined   betaPriorUpperQuantile undefined  0 undefined   betaPriorUpperQuantile undefined  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object ) # run check on the formula   modelsAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelsAsFormula )  {   checkLRT (  full ,  reduced ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  modelMatrixType ) )  {   blindDesign -    design (  object ) ==   formula (  ~  1 )   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # if there are interaction terms present in the design # then we should only use the prior on the interaction terms  if (    any (   termsOrder undefined  2 ) undefined   modelMatrixType ==  \"expanded\" )  {   stop (  \"interactions higher than 2nd order and usage of expanded model matrices\r\nhas not been implemented\" ) }   priorOnlyInteraction -    interactionPresent undefined  betaPrior undefined   missing (  betaPriorVar ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {  if (  modelsAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( objectNZ =  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , modelMatrixType =  modelMatrixType , betaPriorVar =  betaPriorVar , priorOnlyInteraction =  priorOnlyInteraction , upperQuantile =  betaPriorUpperQuantile )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType    attr (  object ,  \"test\" ) -  \"LRT\"   p -   ncol (  modelMatrix )   m -   nrow (  modelMatrix )   H -   fullModel $ hat_diagonals # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelsAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

5.
{
  "old_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , name , contrast , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta = seq ( 0 , 0.95 , by = 0.05 ) , pAdjustMethod = \"BH\" )",
    "body": "{  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  theta ) undefined  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } # determine test type from the names of mcols(object)  if (    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) ) )  {   test -  \"Wald\" } else  if (   \"LRTPvalue\" %in%   names (   mcols (  object ) ) )  {   test -  \"LRT\" } else  {   stop (  \"cannot find appropriate results, for available names call 'resultsNames(object)'\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  { # must have performed the Wald test steps  if (   test !=  \"Wald\" )  {   stop (  \"using contrasts requires that the Wald test was performed\" ) }   res -   cleanContrast (  object ,  contrast ) } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"modelMatrix\" ) )   p -   ncol (   attr (  object ,  \"modelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # perform independent filtering  if (  independentFiltering )  {  if (   missing (  filter ) )  {   filter -   res $ baseMean }   stopifnot (    length (  filter ) ==   nrow (  object ) )   filtPadj -   filtered_p ( filter =  filter , test =   res $ pvalue , theta =  theta , method =  pAdjustMethod )   numRej -   colSums (   filtPadj undefined  alpha , na.rm =  TRUE )   j -   which.max (  numRej )    res $ padj -   filtPadj [ ,  j , drop =  TRUE ]   cutoffs -   quantile (  filter ,  theta )    attr (  res ,  \"filterThreshold\" ) -   cutoffs [  j ]    attr (  res ,  \"filterNumRej\" ) -   data.frame ( theta =  theta , numRej =  numRej ) } else  { # regular p-value adjustment # which does not include those rows which were removed # by maximum Cook's distance    res $ padj -   p.adjust (   res $ pvalue , method =  pAdjustMethod ) }      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" )  res } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" )",
    "body": "{  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }   test -   attr (  object ,  \"test\" )   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # allows use of 'name' for expanded model matrices if there are interactions  if (     (   test ==  \"Wald\" ) undefined  isExpanded undefined   missing (  contrast ) undefined   all (   termsOrder undefined  2 ) )  {  if (   missing (  name ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) )   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  altHypothesis ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) } # check to see at least one of these are present   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) )  if (  !  (   WaldResults |  LRTResults ) )  {   stop (  \"cannot find appropriate results in the DESeqDataSet.\r\npossibly nbinomWaldTest or nbinomLRT has not yet been run.\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {  if (    is.character (  contrast ) undefined    length (  contrast ) !=  3 )  {   stop (  \"'contrast', as a character vector of length 3, should have the form:\r\ncontrast = c('factorName','numeratorLevel','denominatorLevel'),\r\nsee the manual page of ?results for more information\" ) }  if (    is.list (  contrast ) undefined    length (  contrast ) !=  2 )  {   stop (  \"'contrast', as a list, should have length 2,\r\nsee the manual page of ?results for more information\" ) }  if (    is.list (  contrast ) undefined  !  (    is.character (   contrast [[  1 ] ] ) undefined   is.character (   contrast [[  2 ] ] ) ) )  {   stop (  \"'contrast', as a list of length 2, should have character vectors as elements,\r\nsee the manual page of ?results for more information\" ) } # pass down whether the model matrix type was \"expanded\"   res -   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues ) } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   warning (  \"tests of log fold change above or below a theshold are Wald tests.\r\nLikelihood ratio test p-values are overwritten\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"modelMatrix\" ) )   p -   ncol (   attr (  object ,  \"modelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # perform independent filtering  if (  independentFiltering )  {  if (   missing (  filter ) )  {   filter -   res $ baseMean }  if (   missing (  theta ) )  {   lowerQuantile -   mean (   filter ==  0 )  if (   lowerQuantile undefined  .95 )   upperQuantile -  .95 else   upperQuantile -  1   theta -   seq (  lowerQuantile ,  upperQuantile , length =  20 ) }   stopifnot (    length (  theta ) undefined  1 )   stopifnot (    length (  filter ) ==   nrow (  object ) )   filtPadj -   filtered_p ( filter =  filter , test =   res $ pvalue , theta =  theta , method =  pAdjustMethod )   numRej -   colSums (   filtPadj undefined  alpha , na.rm =  TRUE )   j -   which.max (  numRej )    res $ padj -   filtPadj [ ,  j , drop =  TRUE ]   cutoffs -   quantile (  filter ,  theta )   filterThreshold -   cutoffs [  j ]   filterNumRej -   data.frame ( theta =  theta , numRej =  numRej ) } else  { # regular p-value adjustment # which does not include those rows which were removed # by maximum Cook's distance    res $ padj -   p.adjust (   res $ pvalue , method =  pAdjustMethod ) }      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" )   deseqRes -   DESeqResults (  res )  if (  independentFiltering )  {    attr (  deseqRes ,  \"filterThreshold\" ) -  filterThreshold    attr (  deseqRes ,  \"filterNumRej\" ) -  filterNumRej }  deseqRes } ",
    "filename": "results.txt"
  }
}



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , test = c ( \"Wald\" , \"LRT\" ) , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , betaPrior = TRUE , full = design ( object ) , reduced , quiet = FALSE )",
    "body": "{  if (   missing (  test ) )  {   test -   test [  1 ] }   stopifnot (     length (  test ) ==  1 undefined   test %in%   c (  \"Wald\" ,  \"LRT\" ) )  if (   !   is.null (   sizeFactors (  object ) ) ||  !   is.null (   normalizationFactors (  object ) ) )  {  if (  !  quiet )  {  if (  !   is.null (   normalizationFactors (  object ) ) )  {   message (  \"using pre-existing normalization factors\" ) } else  {   message (  \"using pre-existing size factors\" ) } } } else  {  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object ) }  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"fitting model and testing\" )  if (   test ==  \"Wald\" )  {   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , quiet =  quiet ) } else  if (   test ==  \"LRT\" )  {   object -   nbinomLRT (  object , full =  full , reduced =  reduced , quiet =  quiet ) }  object } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , test = c ( \"Wald\" , \"LRT\" ) , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , betaPrior , full = design ( object ) , reduced , quiet = FALSE , minReplicatesForReplace = 7 , modelMatrixType )",
    "body": "{  if (   missing (  test ) )  {   test -   match.arg (  test , choices =   c (  \"Wald\" ,  \"LRT\" ) ) }  if (   missing (  betaPrior ) )  {   betaPrior -   test ==  \"Wald\" }  if (   test ==  \"LRT\" )  {   checkLRT (  full ,  reduced ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior  if (   !   is.null (   sizeFactors (  object ) ) ||  !   is.null (   normalizationFactors (  object ) ) )  {  if (  !  quiet )  {  if (  !   is.null (   normalizationFactors (  object ) ) )  {   message (  \"using pre-existing normalization factors\" ) } else  {   message (  \"using pre-existing size factors\" ) } } } else  {  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object ) }  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"fitting model and testing\" )  if (   test ==  \"Wald\" )  {   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , quiet =  quiet , modelMatrixType =  modelMatrixType ) } else  if (   test ==  \"LRT\" )  {   object -   nbinomLRT (  object , full =  full , reduced =  reduced , betaPrior =  betaPrior , quiet =  quiet , modelMatrixType =  modelMatrixType ) } # if there are sufficient replicates, then pass through to refitting function  if (   any (   nOrMoreInCell (   attr (  object ,  \"modelMatrix\" ) ,  minReplicatesForReplace ) ) )  {   object -   refitWithoutOutliers (  object ,  test ,  betaPrior ,  full ,  reduced ,  quiet ,  minReplicatesForReplace ,  modelMatrixType ) }  object } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "estimateDispersionsGeneEst",
    "representation": "estimateDispersionsGeneEst",
    "parameters": "function ( object , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE )",
    "body": "{  if (   \"dispGeneEst\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated gene-wise dispersions, removing these\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) ==  \"dispGeneEst\" ] }   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (    log (   minDisp /  10 ) =  -  30 )  {   stop (  \"for computational stability, log(minDisp/10) should be above -30\" ) }   object -   getBaseMeansAndVariances (  object )  if (  !   is.null (   normalizationFactors (  object ) ) )  {   xim -   mean (   1 /   colMeans (   normalizationFactors (  object ) ) ) } else  {   xim -   mean (   1 /   sizeFactors (  object ) ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   bv -    mcols (  objectNZ ) $ baseVar   bm -    mcols (  objectNZ ) $ baseMean # this rough dispersion estimate (alpha_hat) # is for estimating beta and mu # and for the initial starting point for line search   alpha_hat -   pmax (  minDisp ,   (   bv -   xim *  bm ) /   bm ^  2 ) # fitNbinomGLMs returns mu and modelMatrix   fit -   fitNbinomGLMs (  objectNZ , alpha_hat =  alpha_hat ) # use of kappa_0 in backtracking search # initial proposal = log(alpha) + kappa_0 * deriv. of log lik. w.r.t. log(alpha) # use log(minDisp/10) to stop if dispersions going to -infinity   dispRes -   fitDisp ( ySEXP =   counts (  objectNZ ) , xSEXP =   fit $ modelMatrix , mu_hatSEXP =   fit $ mu , log_alphaSEXP =   log (  alpha_hat ) , log_alpha_prior_meanSEXP =   log (  alpha_hat ) , log_alpha_prior_sigmasqSEXP =  1 , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  FALSE )  if (    mean (    dispRes $ iter undefined  maxit ) undefined  .5 )  {   warning (  \"in calling estimateDispersionsGeneEst, less than 50% of gene-wise estimates converged. Use larger maxit argument with estimateDispersions\" ) } # dont accept moves if the log posterior did not # increase by more than one millionth, # and set the small estimates to the minimum dispersion   dispGeneEst -   exp (   dispRes $ log_alpha )   noIncrease -    dispRes $ last_lp undefined    dispRes $ initial_lp +    abs (   dispRes $ initial_lp ) /  1e6    dispGeneEst [   which (  noIncrease ) ] -   alpha_hat [   which (  noIncrease ) ]   dispGeneEst -   pmax (  dispGeneEst ,  minDisp )   dispGeneEstConv -    dispRes $ iter undefined  maxit   dispDataFrame -   buildDataFrameWithNARows (   list ( dispGeneEst =  dispGeneEst , dispGeneEstConv =  dispGeneEstConv ) ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"gene-wise estimates of dispersion\" ,  \"gene-wise dispersion estimate convergence\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsGeneEst",
    "representation": "estimateDispersionsGeneEst",
    "parameters": "function ( object , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE , modelMatrix , niter = 1 )",
    "body": "{  if (   \"dispGeneEst\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated gene-wise dispersions, removing these\" )   removeCols -   c (  \"dispGeneEst\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols ] }   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (    log (   minDisp /  10 ) =  -  30 )  {   stop (  \"for computational stability, log(minDisp/10) should be above -30\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   missing (  modelMatrix ) )  {   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) ) } else  {   message (  \"using supplied model matrix\" ) }   object -   getBaseMeansAndVariances (  object ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # this rough dispersion estimate (alpha_hat) # is for estimating mu # and for the initial starting point for line search # first check if model matrix is full rank   fullRank -     qr (  modelMatrix ) $ rank ==   ncol (  modelMatrix )   alpha_hat -  if (  fullRank )  { # if full rank use this estimator which compares normalized counts to mu   roughDisp -   roughDispEstimate ( y =   counts (  objectNZ , normalized =  TRUE ) , x =  modelMatrix )   momentsDisp -   momentsDispEstimate (  objectNZ )   pmin (  roughDisp ,  momentsDisp ) } else  { # if not full rank use method of moments across all samples   momentsDispEstimate (  objectNZ ) } # bound the rough estimated alpha between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   alpha_hat -   alpha_hat_new -   alpha_init -   pmin (   pmax (  minDisp ,  alpha_hat ) ,  maxDisp )   stopifnot (     length (  niter ) ==  1 undefined   niter undefined  0 ) # iterate between mean and dispersion estimation (niter) times   fitidx -   rep (  TRUE ,   nrow (  objectNZ ) )   mu -   matrix (  0 , nrow =   nrow (  objectNZ ) , ncol =   ncol (  objectNZ ) )   dispIter -   numeric (   nrow (  objectNZ ) )  for  ( iter in   seq_len (  niter ) )  {   fit -   fitNbinomGLMs (   objectNZ [  fitidx , , drop =  FALSE ] , alpha_hat =   alpha_hat [  fitidx ] , modelMatrix =  modelMatrix )   fitMu -   fit $ mu    fitMu [   fitMu undefined  .01 ] -  .01    mu [  fitidx , ] -  fitMu # use of kappa_0 in backtracking search # initial proposal = log(alpha) + kappa_0 * deriv. of log lik. w.r.t. log(alpha) # use log(minDisp/10) to stop if dispersions going to -infinity   dispRes -   fitDisp ( ySEXP =    counts (  objectNZ ) [  fitidx , , drop =  FALSE ] , xSEXP =   fit $ modelMatrix , mu_hatSEXP =  fitMu , log_alphaSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_meanSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_sigmasqSEXP =  1 , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  FALSE )    dispIter [  fitidx ] -   dispRes $ iter    alpha_hat_new [  fitidx ] -   pmin (   exp (   dispRes $ log_alpha ) ,  maxDisp ) # only rerun those rows which moved   fitidx -    abs (    log (  alpha_hat_new ) -   log (  alpha_hat ) ) undefined  .05   alpha_hat -  alpha_hat_new  if (    sum (  fitidx ) ==  0 )  break } # dont accept moves if the log posterior did not # increase by more than one millionth, # and set the small estimates to the minimum dispersion   dispGeneEst -  alpha_hat  if (   niter ==  1 )  {   noIncrease -    dispRes $ last_lp undefined    dispRes $ initial_lp +    abs (   dispRes $ initial_lp ) /  1e6    dispGeneEst [   which (  noIncrease ) ] -   alpha_init [   which (  noIncrease ) ] }   dispGeneEstConv -   dispIter undefined  maxit # when lacking convergence from the C++ routine # we use an R function to estimate dispersions. # This finds the maximum of a smooth curve along a # grid of posterior evaluations   refitDisp -   !  dispGeneEstConv undefined   dispGeneEst undefined   minDisp *  10  if (    sum (  refitDisp ) undefined  0 )  {   dispInR -   fitDispInR ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =   rep (  0 ,   sum (  refitDisp ) ) , logAlphaPriorSigmaSq =  1 , usePrior =  FALSE )    dispGeneEst [  refitDisp ] -  dispInR }   dispGeneEst -   pmin (   pmax (  dispGeneEst ,  minDisp ) ,  maxDisp )   dispDataFrame -   buildDataFrameWithNARows (   list ( dispGeneEst =  dispGeneEst ) ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"gene-wise estimates of dispersion\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (  mu ,    mcols (  object ) $ allZero )   return (  object ) } ",
    "filename": "core.txt"
  }
}

2.
{
  "old_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   \"dispersion\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated dispersions, removing these\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%   c (  \"dispersion\" ,  \"dispIter\" ,  \"dispIterAccept\" ,  \"dispConv\" ) ] }   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) )   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   useNotMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  10  if (    sum (  useNotMinDisp , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   minDisp *  10 )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } # estimate the variance of the distribution of the # log dispersion estimates around the fitted value   dispResiduals -    log (    mcols (  objectNZ ) $ dispGeneEst ) -   log (    mcols (  objectNZ ) $ dispFit )   useForPrior -  useNotMinDisp  if (    sum (  useForPrior , na.rm =  TRUE ) ==  0 )  {   stop (  \"no data found which is greater than minDisp, within quants, and converged in gene-wise estimates\" ) }   varLogDispEsts -   varLogDispEstsAll -    mad (   dispResiduals [  useForPrior ] , na.rm =  TRUE ) ^  2   m -   nrow (  modelMatrix )   p -   ncol (  modelMatrix ) # if the residual degrees of freedom is between 1 and 3, the distribution # of log dispersions is especially asymmetric and poorly estimated # by the MAD. we then use an alternate estimator, a monte carlo # approach to match the distribution  if (   (   (   m -  p ) =  3 ) undefined  (   m undefined  p ) )  { # in order to produce identical results we set the seed, # and so we need to save and restore the .Random.seed value first  if (   exists (  \".Random.seed\" ) )  {   oldRandomSeed -  .Random.seed }   set.seed (  2 ) # The residuals are the observed distribution we try to match   obsDist -   dispResiduals [  useForPrior ]   brks -    -  20 :  20 /  2   obsDist -   obsDist [    obsDist undefined   min (  brks ) undefined   obsDist undefined   max (  brks ) ]   obsVarGrid -   seq ( from =  0 , to =  8 , length =  200 )   obsDistHist -   hist (  obsDist , breaks =  brks , plot =  FALSE )   klDivs -   sapply (  obsVarGrid ,  function ( x )  {   randDist -     log (   rchisq (  1e4 , df =  (   m -  p ) ) ) +   rnorm (  1e4 ,  0 ,   sqrt (  x ) ) -   log (   m -  p )   randDist -   randDist [    randDist undefined   min (  brks ) undefined   randDist undefined   max (  brks ) ]   randDistHist -   hist (  randDist , breaks =  brks , plot =  FALSE )   z -   c (   obsDistHist $ density ,   randDistHist $ density )   small -   min (   z [   z undefined  0 ] )   kl -   sum (    obsDistHist $ density *  (    log (    obsDistHist $ density +  small ) -   log (    randDistHist $ density +  small ) ) )  kl } )   lofit -   loess (   klDivs ~  obsVarGrid , span =  .2 )   obsVarFineGrid -   seq ( from =  0 , to =  8 , length =  1000 )   lofitFitted -   predict (  lofit ,  obsVarFineGrid )   argminKL -   obsVarFineGrid [   which.min (  lofitFitted ) ]   expVarLogDisp -   trigamma (   (   m -  p ) /  2 )   varLogDispEsts -   argminKL +  expVarLogDisp # finally, restore the .Random.seed if it existed beforehand  if (   exists (  \"oldRandomSeed\" ) )  {   .Random.seed -  oldRandomSeed } }    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts # estimate the expected sampling variance of the log estimates # Var(log(cX)) = Var(log(X)) # X ~ chi-squared with m - p degrees of freedom  if (   m undefined  p )  {   expVarLogDisp -   trigamma (   (   m -  p ) /  2 )    attr (   dispersionFunction (  object ) ,  \"expVarLogDisp\" ) -  expVarLogDisp # set the variance of the prior using these two estimates # with a minimum of .25   dispPriorVarCalc -   pmax (  (   varLogDispEsts -  expVarLogDisp ) ,  .25 ) } else  { # we have m = p, so do not try to substract sampling variance   dispPriorVarCalc -  varLogDispEsts } # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  {   dispPriorVar -  dispPriorVarCalc }   stopifnot (    length (  dispPriorVar ) ==  1 )    attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" ) -  dispPriorVar # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one decade # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDisp ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  TRUE ) # prepare dispersions for storage in mcols(object)   dispersionFinal -   dispMAP -   exp (   dispResMAP $ log_alpha ) # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEstsAll )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispConv =  (    dispResMAP $ iter undefined  maxit ) , dispOutlier =  dispOutlier , dispMAP =  dispMAP )  if (   any (  !   resultsList $ dispConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   resultsList $ dispConv ) ,  \"rows did not converge in dispersion, labelled in mcols(object)$dispConv. Use larger maxit argument with estimateDispersions\" ) ) }   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"convergence of final estimate\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , modelMatrix , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   \"dispersion\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated dispersions, removing these\" )   removeCols -   c (  \"dispersion\" ,  \"dispOutlier\" ,  \"dispMAP\" ,  \"dispIter\" ,  \"dispConv\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols ] }  if (   missing (  modelMatrix ) )  {   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) ) } else  {   message (  \"using supplied model matrix\" ) }   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  {   aboveMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  100  if (    sum (  aboveMinDisp , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   minDisp *  10 )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )    attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" ) -  0.25   return (  object ) }   resList -   estimateDispersionPriorVar (  objectNZ ,  aboveMinDisp ,  modelMatrix )   dispPriorVar -   resList $ dispPriorVar   varLogDispEsts -   resList $ varLogDispEsts   expVarLogDisp -   resList $ expVarLogDisp    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts    attr (   dispersionFunction (  object ) ,  \"expVarLogDisp\" ) -  expVarLogDisp }   stopifnot (    length (  dispPriorVar ) ==  1 )    attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" ) -  dispPriorVar # could be coming from a previous run, and need to import varLogDispEsts # for the calculation of outliers  if (  !   is.null (   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) ) )  {   varLogDispEsts -   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) } else  { # provided dispPriorVar, so need to calculate observed varLogDispEsts # this code is copied from estimateDispPriorVar()   aboveMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  100   stopifnot (    sum (  aboveMinDisp , na.rm =  TRUE ) undefined  0 )   dispResiduals -    log (    mcols (  objectNZ ) $ dispGeneEst ) -   log (    mcols (  objectNZ ) $ dispFit )   varLogDispEsts -    mad (   dispResiduals [  aboveMinDisp ] , na.rm =  TRUE ) ^  2    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts } # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one order of magnitude # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDisp ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  TRUE ) # prepare dispersions for storage in mcols(object)   dispMAP -   exp (   dispResMAP $ log_alpha ) # when lacking convergence from the C++ routine # we use an R function to estimate dispersions. # This finds the maximum of a smooth curve along a # grid of posterior evaluations   dispConv -    dispResMAP $ iter undefined  maxit   refitDisp -  !  dispConv  if (    sum (  refitDisp ) undefined  0 )  {   dispInR -   fitDispInR ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =    log (    mcols (  objectNZ ) $ dispFit ) [  refitDisp ] , logAlphaPriorSigmaSq =  log_alpha_prior_sigmasq , usePrior =  TRUE )    dispMAP [  refitDisp ] -  dispInR }   dispersionFinal -  dispMAP # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEsts )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispOutlier =  dispOutlier , dispMAP =  dispMAP )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  }
}

3.
{
  "old_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{   stopifnot (    length (  maxit ) ==  1 )  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   H -   fit $ hat_diagonals # record the wide prior which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } # calculate the prior variance (on the log2 scale)  if (  betaPrior )  { # we need the MLE betas to fit the prior variance # and for the hat matrix diagonals in order to # calculate Cook's distance   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useQR =  useQR )   H -   fit $ hat_diagonals  if (   missing (  betaPriorVar ) )  { # estimate the variance of the prior on betas  if (    nrow (   fit $ betaMatrix ) undefined  1 )  {   betaPriorVar -   apply (   fit $ betaMatrix ,  2 ,  function ( x )  { # infinite betas are halted when |beta| # so this test removes them   useSmall -    abs (  x ) undefined  8 # if no more betas pass test, return wide prior  if (    sum (  useSmall ) ==  0 )  {   return (  1e6 ) } else  {   mean (    x [  useSmall ] ^  2 ) } } ) } else  {   betaPriorVar -   (   fit $ betaMatrix ) ^  2 } # except for intercept which we set to wide prior  if (   \"Intercept\" %in%   fit $ modelMatrixNames )  {    betaPriorVar [   which (    fit $ modelMatrixNames ==  \"Intercept\" ) ] -  1e6 } } else  { # else we are provided the prior variance: # check if the lambda is the correct length # given the design formula   p -   ncol (   fit $ modelMatrix )  if (    length (  betaPriorVar ) !=  p )  {   stop (   paste (  \"betaPriorVar should have length\" ,  p ) ) } }   lambda -   1 /  betaPriorVar   fit -   fitNbinomGLMs (  objectNZ , lambda =  lambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) } # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -   fit $ modelMatrix   m -   nrow (   fit $ modelMatrix )   p -   ncol (   fit $ modelMatrix ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,   fit $ modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )   modelMatrixNames -   fit $ modelMatrixNames # add betas, standard errors and Wald p-values to the object   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )  if (  betaPrior )  {   coefInfo -   paste (  \"log2 fold change (MAP):\" ,  modelMatrixNamesSpaces ) } else  {   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces ) }   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE , betaPriorUpperQuantile = .05 )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 )   stopifnot (      length (  betaPriorUpperQuantile ) ==  1 undefined   betaPriorUpperQuantile undefined  0 undefined   betaPriorUpperQuantile undefined  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  modelMatrixType ) )  {   blindDesign -    design (  object ) ==   formula (  ~  1 )   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # if there are interaction terms present in the design # then we should only use the prior on the interaction terms  if (    any (   termsOrder undefined  2 ) undefined   modelMatrixType ==  \"expanded\" )  {   stop (  \"interactions higher than 2nd order and usage of expanded model matrices\r\nhas not been implemented. we recommend instead using a likelihood\r\nratio test, i.e. DESeq with argument test='LRT' and betaPrior=FALSE.\" ) }   priorOnlyInteraction -    interactionPresent undefined  betaPrior undefined   missing (  betaPriorVar )  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) }  if (  betaPrior )  {   priorFitList -   fitGLMsWithPrior ( objectNZ =  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , modelMatrixType =  modelMatrixType , betaPriorVar =  betaPriorVar , priorOnlyInteraction =  priorOnlyInteraction , upperQuantile =  betaPriorUpperQuantile )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix } # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType    attr (  object ,  \"test\" ) -  \"Wald\"   m -   nrow (  modelMatrix )   p -   ncol (  modelMatrix ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,   fit $ modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -  if (  betaPrior )  {   paste (  \"log2 fold change (MAP):\" ,  modelMatrixNamesSpaces ) } else  {   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces ) }   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

4.
{
  "old_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"please provide a reduced formula for the likelihood ratio test, e.g. nbinomLRT(object, reduced = ~ 1)\" ) }  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) } # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix )  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )    attr (  object ,  \"modelMatrix\" ) -  fullModelMatrix   p -   ncol (  fullModelMatrix )   m -   nrow (  fullModelMatrix )   H -   fullModel $ hat_diagonals # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  fullModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" )   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE , betaPriorUpperQuantile = .05 )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (      length (  betaPriorUpperQuantile ) ==  1 undefined   betaPriorUpperQuantile undefined  0 undefined   betaPriorUpperQuantile undefined  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object ) # run check on the formula   modelsAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelsAsFormula )  {   checkLRT (  full ,  reduced ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  modelMatrixType ) )  {   blindDesign -    design (  object ) ==   formula (  ~  1 )   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # if there are interaction terms present in the design # then we should only use the prior on the interaction terms  if (    any (   termsOrder undefined  2 ) undefined   modelMatrixType ==  \"expanded\" )  {   stop (  \"interactions higher than 2nd order and usage of expanded model matrices\r\nhas not been implemented\" ) }   priorOnlyInteraction -    interactionPresent undefined  betaPrior undefined   missing (  betaPriorVar ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {  if (  modelsAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( objectNZ =  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , modelMatrixType =  modelMatrixType , betaPriorVar =  betaPriorVar , priorOnlyInteraction =  priorOnlyInteraction , upperQuantile =  betaPriorUpperQuantile )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType    attr (  object ,  \"test\" ) -  \"LRT\"   p -   ncol (  modelMatrix )   m -   nrow (  modelMatrix )   H -   fullModel $ hat_diagonals # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelsAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

5.
{
  "old_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , name , contrast , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta = seq ( 0 , 0.95 , by = 0.05 ) , pAdjustMethod = \"BH\" )",
    "body": "{  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  theta ) undefined  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } # determine test type from the names of mcols(object)  if (    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) ) )  {   test -  \"Wald\" } else  if (   \"LRTPvalue\" %in%   names (   mcols (  object ) ) )  {   test -  \"LRT\" } else  {   stop (  \"cannot find appropriate results, for available names call 'resultsNames(object)'\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  { # must have performed the Wald test steps  if (   test !=  \"Wald\" )  {   stop (  \"using contrasts requires that the Wald test was performed\" ) }   res -   cleanContrast (  object ,  contrast ) } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"modelMatrix\" ) )   p -   ncol (   attr (  object ,  \"modelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # perform independent filtering  if (  independentFiltering )  {  if (   missing (  filter ) )  {   filter -   res $ baseMean }   stopifnot (    length (  filter ) ==   nrow (  object ) )   filtPadj -   filtered_p ( filter =  filter , test =   res $ pvalue , theta =  theta , method =  pAdjustMethod )   numRej -   colSums (   filtPadj undefined  alpha , na.rm =  TRUE )   j -   which.max (  numRej )    res $ padj -   filtPadj [ ,  j , drop =  TRUE ]   cutoffs -   quantile (  filter ,  theta )    attr (  res ,  \"filterThreshold\" ) -   cutoffs [  j ]    attr (  res ,  \"filterNumRej\" ) -   data.frame ( theta =  theta , numRej =  numRej ) } else  { # regular p-value adjustment # which does not include those rows which were removed # by maximum Cook's distance    res $ padj -   p.adjust (   res $ pvalue , method =  pAdjustMethod ) }      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" )  res } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" )",
    "body": "{  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }   test -   attr (  object ,  \"test\" )   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # allows use of 'name' for expanded model matrices if there are interactions  if (     (   test ==  \"Wald\" ) undefined  isExpanded undefined   missing (  contrast ) undefined   all (   termsOrder undefined  2 ) )  {  if (   missing (  name ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) )   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  altHypothesis ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) } # check to see at least one of these are present   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) )  if (  !  (   WaldResults |  LRTResults ) )  {   stop (  \"cannot find appropriate results in the DESeqDataSet.\r\npossibly nbinomWaldTest or nbinomLRT has not yet been run.\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {  if (    is.character (  contrast ) undefined    length (  contrast ) !=  3 )  {   stop (  \"'contrast', as a character vector of length 3, should have the form:\r\ncontrast = c('factorName','numeratorLevel','denominatorLevel'),\r\nsee the manual page of ?results for more information\" ) }  if (    is.list (  contrast ) undefined    length (  contrast ) !=  2 )  {   stop (  \"'contrast', as a list, should have length 2,\r\nsee the manual page of ?results for more information\" ) }  if (    is.list (  contrast ) undefined  !  (    is.character (   contrast [[  1 ] ] ) undefined   is.character (   contrast [[  2 ] ] ) ) )  {   stop (  \"'contrast', as a list of length 2, should have character vectors as elements,\r\nsee the manual page of ?results for more information\" ) } # pass down whether the model matrix type was \"expanded\"   res -   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues ) } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   warning (  \"tests of log fold change above or below a theshold are Wald tests.\r\nLikelihood ratio test p-values are overwritten\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"modelMatrix\" ) )   p -   ncol (   attr (  object ,  \"modelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # perform independent filtering  if (  independentFiltering )  {  if (   missing (  filter ) )  {   filter -   res $ baseMean }  if (   missing (  theta ) )  {   lowerQuantile -   mean (   filter ==  0 )  if (   lowerQuantile undefined  .95 )   upperQuantile -  .95 else   upperQuantile -  1   theta -   seq (  lowerQuantile ,  upperQuantile , length =  20 ) }   stopifnot (    length (  theta ) undefined  1 )   stopifnot (    length (  filter ) ==   nrow (  object ) )   filtPadj -   filtered_p ( filter =  filter , test =   res $ pvalue , theta =  theta , method =  pAdjustMethod )   numRej -   colSums (   filtPadj undefined  alpha , na.rm =  TRUE )   j -   which.max (  numRej )    res $ padj -   filtPadj [ ,  j , drop =  TRUE ]   cutoffs -   quantile (  filter ,  theta )   filterThreshold -   cutoffs [  j ]   filterNumRej -   data.frame ( theta =  theta , numRej =  numRej ) } else  { # regular p-value adjustment # which does not include those rows which were removed # by maximum Cook's distance    res $ padj -   p.adjust (   res $ pvalue , method =  pAdjustMethod ) }      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" )   deseqRes -   DESeqResults (  res )  if (  independentFiltering )  {    attr (  deseqRes ,  \"filterThreshold\" ) -  filterThreshold    attr (  deseqRes ,  \"filterNumRej\" ) -  filterNumRej }  deseqRes } ",
    "filename": "results.txt"
  }
}

6.
{
  "old_function": {
    "name": "rlogData",
    "representation": "rlogData",
    "parameters": "function ( object , samplesVector , betaPriorVar , intercept )",
    "body": "{  if (   is.null (    mcols (  object ) $ dispFit ) )  {   stop (  \"first estimate dispersion with a design of formula(~ 1)\" ) }  if (   missing (  samplesVector ) )  {   samplesVector -   as.character (   seq_len (   ncol (  object ) ) ) }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {     mcols (  object ) $ allZero -    rowSums (   counts (  object ) ) ==  0 } # make a design matrix with a term for every sample # this would typically produce unidentifiable solution # for the GLM, but we add priors for all terms except # the intercept   samplesVector -   factor (  samplesVector , levels =   unique (  samplesVector ) )  if (   missing (  intercept ) )  {   samples -   factor (   c (  \"null_level\" ,   as.character (  samplesVector ) ) , levels =   c (  \"null_level\" ,   levels (  samplesVector ) ) )   modelMatrix -    model.matrix (  ~  samples ) [  -  1 , ]   modelMatrixNames -   colnames (  modelMatrix )    modelMatrixNames [   modelMatrixNames ==  \"(Intercept)\" ] -  \"Intercept\" } else  { # or we want to set the intercept using the # provided intercept instead   samples -   factor (  samplesVector )  if (    length (  samples ) undefined  1 )  {   modelMatrix -   model.matrix (  ~   0 +  samples ) } else  {   modelMatrix -   matrix (  1 , ncol =  1 )   modelMatrixNames -  \"samples1\" }   modelMatrixNames -   colnames (  modelMatrix )  if (  !   is.null (   normalizationFactors (  object ) ) )  {   nf -   normalizationFactors (  object ) } else  {   sf -   sizeFactors (  object )   nf -   matrix (   rep (  sf , each =   nrow (  object ) ) , ncol =   ncol (  object ) ) } # if the intercept is not finite, these rows # were all zero. here we put a small value instead   intercept -   as.numeric (  intercept )   infiniteIntercept -  !   is.finite (  intercept )    intercept [  infiniteIntercept ] -  -  10    normalizationFactors (  object ) -   nf *   2 ^  intercept # we set the intercept, so replace the all zero # column with the rows which were all zero # in the previous dataset     mcols (  object ) $ allZero -  infiniteIntercept } # only continue on the rows with non-zero row sums   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # if a prior sigma squared not provided, estimate this # by the variance of log2 counts plus a pseudocount  if (   missing (  betaPriorVar ) )  {   logCounts -   log2 (    counts (  objectNZ , normalized =  TRUE ) +  0.5 )   logFoldChangeMatrix -   logCounts -   rowMeans (  logCounts )   betaPriorVar -   var (   as.numeric (  logFoldChangeMatrix ) ) }   stopifnot (    length (  betaPriorVar ) ==  1 )   lambda -   1 /   rep (  betaPriorVar ,   ncol (  modelMatrix ) ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%  modelMatrixNames )  {    lambda [   which (   modelMatrixNames ==  \"Intercept\" ) ] -  1e-6 }   fit -   fitNbinomGLMs ( object =  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE , alpha_hat =    mcols (  objectNZ ) $ dispFit , betaTol =  1e-4 , useOptim =  FALSE , useQR =  TRUE )   normalizedDataNZ -   t (   modelMatrix %*%   t (   fit $ betaMatrix ) )   normalizedData -   buildMatrixWithZeroRows (  normalizedDataNZ ,    mcols (  object ) $ allZero ) # add back in the intercept, if finite  if (  !   missing (  intercept ) )  {   normalizedData -   normalizedData +   ifelse (  infiniteIntercept ,  0 ,  intercept ) }    colnames (  normalizedData ) -   colnames (  object )    attr (  normalizedData ,  \"betaPriorVar\" ) -  betaPriorVar  if (   \"Intercept\" %in%  modelMatrixNames )  {   fittedInterceptNZ -    fit $ betaMatrix [ ,   which (   modelMatrixNames ==  \"Intercept\" ) , drop =  FALSE ]   fittedIntercept -   buildMatrixWithNARows (  fittedInterceptNZ ,    mcols (  object ) $ allZero )    fittedIntercept [   is.na (  fittedIntercept ) ] -  -  Inf    attr (  normalizedData ,  \"intercept\" ) -  fittedIntercept }  normalizedData } ",
    "filename": "rlogTransformation.txt"
  },
  "new_function": {
    "name": "rlogData",
    "representation": "rlogData",
    "parameters": "function ( object , intercept , betaPriorVar )",
    "body": "{  if (   is.null (    mcols (  object ) $ dispFit ) )  {   stop (  \"first estimate dispersion with a design of formula(~ 1)\" ) }   samplesVector -   as.character (   seq_len (   ncol (  object ) ) )  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {     mcols (  object ) $ allZero -    rowSums (   counts (  object ) ) ==  0 }  if (  !   \"baseMean\" %in%   names (   mcols (  object ) ) )  {     mcols (  object ) $ baseMean -   rowMeans (   counts (  object , normalized =  TRUE ) ) } # make a design matrix with a term for every sample # this would typically produce unidentifiable solution # for the GLM, but we add priors for all terms except # the intercept   samplesVector -   factor (  samplesVector , levels =   unique (  samplesVector ) )  if (   missing (  intercept ) )  {   samples -   factor (   c (  \"null_level\" ,   as.character (  samplesVector ) ) , levels =   c (  \"null_level\" ,   levels (  samplesVector ) ) )   modelMatrix -    model.matrix (  ~  samples ) [  -  1 , ]   modelMatrixNames -   colnames (  modelMatrix )    modelMatrixNames [   modelMatrixNames ==  \"(Intercept)\" ] -  \"Intercept\" } else  { # or we want to set the intercept using the # provided intercept instead   samples -   factor (  samplesVector )  if (    length (  samples ) undefined  1 )  {   modelMatrix -   model.matrix (  ~   0 +  samples ) } else  {   modelMatrix -   matrix (  1 , ncol =  1 )   modelMatrixNames -  \"samples1\" }   modelMatrixNames -   colnames (  modelMatrix )  if (  !   is.null (   normalizationFactors (  object ) ) )  {   nf -   normalizationFactors (  object ) } else  {   sf -   sizeFactors (  object )   nf -   matrix (   rep (  sf , each =   nrow (  object ) ) , ncol =   ncol (  object ) ) } # if the intercept is not finite, these rows # were all zero. here we put a small value instead   intercept -   as.numeric (  intercept )   infiniteIntercept -  !   is.finite (  intercept )    intercept [  infiniteIntercept ] -  -  10    normalizationFactors (  object ) -   nf *   2 ^  intercept # we set the intercept, so replace the all zero # column with the rows which were all zero # in the previous dataset     mcols (  object ) $ allZero -  infiniteIntercept } # only continue on the rows with non-zero row sums   objectNZ -   object [  !    mcols (  object ) $ allZero , ]   stopifnot (   all (  !   is.na (    mcols (  objectNZ ) $ dispFit ) ) ) # if a prior sigma squared not provided, estimate this # by the matching upper quantiles of the # log2 counts plus a pseudocount  if (   missing (  betaPriorVar ) )  {   logCounts -   log2 (    counts (  objectNZ , normalized =  TRUE ) +  0.5 )   baseMean -   rowMeans (   counts (  objectNZ , normalized =  TRUE ) )   logFoldChangeMatrix -   logCounts -   log2 (   baseMean +  0.5 )   logFoldChangeVector -   as.numeric (  logFoldChangeMatrix )   betaPriorVar -   matchUpperQuantileForVariance (  logFoldChangeVector ) }   stopifnot (    length (  betaPriorVar ) ==  1 )   lambda -   1 /   rep (  betaPriorVar ,   ncol (  modelMatrix ) ) # except for intercept which we set to wide prior  if (   \"Intercept\" %in%  modelMatrixNames )  {    lambda [   which (   modelMatrixNames ==  \"Intercept\" ) ] -  1e-6 }   fit -   fitNbinomGLMs ( object =  objectNZ , modelMatrix =  modelMatrix , lambda =  lambda , renameCols =  FALSE , alpha_hat =    mcols (  objectNZ ) $ dispFit , betaTol =  1e-4 , useOptim =  FALSE , useQR =  TRUE )   normalizedDataNZ -   t (   modelMatrix %*%   t (   fit $ betaMatrix ) )   normalizedData -   buildMatrixWithZeroRows (  normalizedDataNZ ,    mcols (  object ) $ allZero ) # add back in the intercept, if finite  if (  !   missing (  intercept ) )  {   normalizedData -   normalizedData +   ifelse (  infiniteIntercept ,  0 ,  intercept ) }    colnames (  normalizedData ) -   colnames (  object )    attr (  normalizedData ,  \"betaPriorVar\" ) -  betaPriorVar  if (   \"Intercept\" %in%  modelMatrixNames )  {   fittedInterceptNZ -    fit $ betaMatrix [ ,   which (   modelMatrixNames ==  \"Intercept\" ) , drop =  FALSE ]   fittedIntercept -   buildMatrixWithNARows (  fittedInterceptNZ ,    mcols (  object ) $ allZero )    fittedIntercept [   is.na (  fittedIntercept ) ] -  -  Inf    attr (  normalizedData ,  \"intercept\" ) -  fittedIntercept }  normalizedData } ",
    "filename": "rlogTransformation.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_2_14 deseq2_release_3_1

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_2_14 deseq2_release_3_1",
    "desc_release_old": "1.4.5",
    "desc_release_new": "1.8.2",
    "old_release_number": 2,
    "new_release_number": 3,
    "function_removals": 2,
    "function_additions": 7,
    "parameter_removals": 3,
    "parameter_additions": 3,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 6,
    "total_count": 8
}

##########
Functions Removed
##########

rlogData
rlogDataFast


##########
Functions Added
##########

DESeqTransform
estimateBetaPriorVar
estimateDispersionsPriorVar
estimateMLEForBetaPriorVar
plotCounts
plotSparsity
summary.DESeqResults


##########
Removed Non Default Parameters
##########

0.
{
  "old_function": {
    "name": "estimateDispersionsGeneEst",
    "representation": "estimateDispersionsGeneEst",
    "parameters": "function ( object , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE , modelMatrix , niter = 1 )",
    "body": "{  if (   \"dispGeneEst\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated gene-wise dispersions, removing these\" )   removeCols -   c (  \"dispGeneEst\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols ] }   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (    log (   minDisp /  10 ) =  -  30 )  {   stop (  \"for computational stability, log(minDisp/10) should be above -30\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   missing (  modelMatrix ) )  {   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) ) } else  {   message (  \"using supplied model matrix\" ) }   object -   getBaseMeansAndVariances (  object ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # this rough dispersion estimate (alpha_hat) # is for estimating mu # and for the initial starting point for line search # first check if model matrix is full rank   fullRank -     qr (  modelMatrix ) $ rank ==   ncol (  modelMatrix )   alpha_hat -  if (  fullRank )  { # if full rank use this estimator which compares normalized counts to mu   roughDisp -   roughDispEstimate ( y =   counts (  objectNZ , normalized =  TRUE ) , x =  modelMatrix )   momentsDisp -   momentsDispEstimate (  objectNZ )   pmin (  roughDisp ,  momentsDisp ) } else  { # if not full rank use method of moments across all samples   momentsDispEstimate (  objectNZ ) } # bound the rough estimated alpha between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   alpha_hat -   alpha_hat_new -   alpha_init -   pmin (   pmax (  minDisp ,  alpha_hat ) ,  maxDisp )   stopifnot (     length (  niter ) ==  1 undefined   niter undefined  0 ) # iterate between mean and dispersion estimation (niter) times   fitidx -   rep (  TRUE ,   nrow (  objectNZ ) )   mu -   matrix (  0 , nrow =   nrow (  objectNZ ) , ncol =   ncol (  objectNZ ) )   dispIter -   numeric (   nrow (  objectNZ ) )  for  ( iter in   seq_len (  niter ) )  {   fit -   fitNbinomGLMs (   objectNZ [  fitidx , , drop =  FALSE ] , alpha_hat =   alpha_hat [  fitidx ] , modelMatrix =  modelMatrix )   fitMu -   fit $ mu    fitMu [   fitMu undefined  .01 ] -  .01    mu [  fitidx , ] -  fitMu # use of kappa_0 in backtracking search # initial proposal = log(alpha) + kappa_0 * deriv. of log lik. w.r.t. log(alpha) # use log(minDisp/10) to stop if dispersions going to -infinity   dispRes -   fitDisp ( ySEXP =    counts (  objectNZ ) [  fitidx , , drop =  FALSE ] , xSEXP =   fit $ modelMatrix , mu_hatSEXP =  fitMu , log_alphaSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_meanSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_sigmasqSEXP =  1 , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  FALSE )    dispIter [  fitidx ] -   dispRes $ iter    alpha_hat_new [  fitidx ] -   pmin (   exp (   dispRes $ log_alpha ) ,  maxDisp ) # only rerun those rows which moved   fitidx -    abs (    log (  alpha_hat_new ) -   log (  alpha_hat ) ) undefined  .05   alpha_hat -  alpha_hat_new  if (    sum (  fitidx ) ==  0 )  break } # dont accept moves if the log posterior did not # increase by more than one millionth, # and set the small estimates to the minimum dispersion   dispGeneEst -  alpha_hat  if (   niter ==  1 )  {   noIncrease -    dispRes $ last_lp undefined    dispRes $ initial_lp +    abs (   dispRes $ initial_lp ) /  1e6    dispGeneEst [   which (  noIncrease ) ] -   alpha_init [   which (  noIncrease ) ] }   dispGeneEstConv -   dispIter undefined  maxit # when lacking convergence from the C++ routine # we use an R function to estimate dispersions. # This finds the maximum of a smooth curve along a # grid of posterior evaluations   refitDisp -   !  dispGeneEstConv undefined   dispGeneEst undefined   minDisp *  10  if (    sum (  refitDisp ) undefined  0 )  {   dispInR -   fitDispInR ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =   rep (  0 ,   sum (  refitDisp ) ) , logAlphaPriorSigmaSq =  1 , usePrior =  FALSE )    dispGeneEst [  refitDisp ] -  dispInR }   dispGeneEst -   pmin (   pmax (  dispGeneEst ,  minDisp ) ,  maxDisp )   dispDataFrame -   buildDataFrameWithNARows (   list ( dispGeneEst =  dispGeneEst ) ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"gene-wise estimates of dispersion\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (  mu ,    mcols (  object ) $ allZero )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsGeneEst",
    "representation": "estimateDispersionsGeneEst",
    "parameters": "function ( object , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE , modelMatrix = NULL , niter = 1 )",
    "body": "{  if (  !   is.null (    mcols (  object ) $ dispGeneEst ) )  {  if (  !  quiet )   message (  \"found already estimated gene-wise dispersions, removing these\" )   removeCols -   c (  \"dispGeneEst\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols , drop =  FALSE ] }   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (    log (   minDisp /  10 ) =  -  30 )  {   stop (  \"for computational stability, log(minDisp/10) should be above -30\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   is.null (  modelMatrix ) )  {   modelMatrix -   model.matrix (   design (  object ) , data =   colData (  object ) )   checkFullRank (  modelMatrix )  if (    nrow (  modelMatrix ) ==   ncol (  modelMatrix ) )  {   stop (  \"the number of samples and the number of model coefficients are equal,\r\n  i.e., there are no replicates to estimate the dispersion.\r\n  use an alternate design formula\" ) } } else  {   message (  \"using supplied model matrix\" ) }   object -   getBaseMeansAndVariances (  object ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ] # this rough dispersion estimate (alpha_hat) # is for estimating mu # and for the initial starting point for line search # first check if model matrix is full rank   fullRank -     qr (  modelMatrix ) $ rank ==   ncol (  modelMatrix )   alpha_hat -  if (  fullRank )  { # if full rank use this estimator which compares normalized counts to mu   roughDisp -   roughDispEstimate ( y =   counts (  objectNZ , normalized =  TRUE ) , x =  modelMatrix )   momentsDisp -   momentsDispEstimate (  objectNZ )   pmin (  roughDisp ,  momentsDisp ) } else  { # if not full rank use method of moments across all samples   momentsDispEstimate (  objectNZ ) } # bound the rough estimated alpha between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   alpha_hat -   alpha_hat_new -   alpha_init -   pmin (   pmax (  minDisp ,  alpha_hat ) ,  maxDisp )   stopifnot (     length (  niter ) ==  1 undefined   niter undefined  0 ) # below, iterate between mean and dispersion estimation (niter) times   fitidx -   rep (  TRUE ,   nrow (  objectNZ ) )   mu -   matrix (  0 , nrow =   nrow (  objectNZ ) , ncol =   ncol (  objectNZ ) )   dispIter -   numeric (   nrow (  objectNZ ) ) # bound the estimated count at 0.1. # this helps make the fitting more robust, # because 1/mu occurs in the weights for the NB GLM   minmu -  0.1  for  ( iter in   seq_len (  niter ) )  {   fit -   fitNbinomGLMs (   objectNZ [  fitidx , , drop =  FALSE ] , alpha_hat =   alpha_hat [  fitidx ] , modelMatrix =  modelMatrix )   fitMu -   fit $ mu    fitMu [   fitMu undefined  minmu ] -  minmu    mu [  fitidx , ] -  fitMu # use of kappa_0 in backtracking search # initial proposal = log(alpha) + kappa_0 * deriv. of log lik. w.r.t. log(alpha) # use log(minDisp/10) to stop if dispersions going to -infinity   dispRes -   fitDispWrapper ( ySEXP =    counts (  objectNZ ) [  fitidx , , drop =  FALSE ] , xSEXP =   fit $ modelMatrix , mu_hatSEXP =  fitMu , log_alphaSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_meanSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_sigmasqSEXP =  1 , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  FALSE )    dispIter [  fitidx ] -   dispRes $ iter    alpha_hat_new [  fitidx ] -   pmin (   exp (   dispRes $ log_alpha ) ,  maxDisp ) # only rerun those rows which moved   fitidx -    abs (    log (  alpha_hat_new ) -   log (  alpha_hat ) ) undefined  .05   alpha_hat -  alpha_hat_new  if (    sum (  fitidx ) ==  0 )  break } # dont accept moves if the log posterior did not # increase by more than one millionth, # and set the small estimates to the minimum dispersion   dispGeneEst -  alpha_hat  if (   niter ==  1 )  {   noIncrease -    dispRes $ last_lp undefined    dispRes $ initial_lp +    abs (   dispRes $ initial_lp ) /  1e6    dispGeneEst [   which (  noIncrease ) ] -   alpha_init [   which (  noIncrease ) ] }   dispGeneEstConv -   dispIter undefined  maxit # when lacking convergence from the C++ routine # we use an R function to estimate dispersions # by evaluating a grid of posterior evaluations   refitDisp -   !  dispGeneEstConv undefined   dispGeneEst undefined   minDisp *  10  if (    sum (  refitDisp ) undefined  0 )  {   dispInR -   fitDispGridWrapper ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =   rep (  0 ,   sum (  refitDisp ) ) , logAlphaPriorSigmaSq =  1 , usePrior =  FALSE )    dispGeneEst [  refitDisp ] -  dispInR }   dispGeneEst -   pmin (   pmax (  dispGeneEst ,  minDisp ) ,  maxDisp )   dispDataFrame -   buildDataFrameWithNARows (   list ( dispGeneEst =  dispGeneEst ) ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"gene-wise estimates of dispersion\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (  mu ,    mcols (  object ) $ allZero )   return (  object ) } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , modelMatrix , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   \"dispersion\" %in%   names (   mcols (  object ) ) )  {  if (  !  quiet )   message (  \"you had estimated dispersions, removing these\" )   removeCols -   c (  \"dispersion\" ,  \"dispOutlier\" ,  \"dispMAP\" ,  \"dispIter\" ,  \"dispConv\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols ] }  if (   missing (  modelMatrix ) )  {   modelMatrix -   model.matrix (   design (  object ) , data =   as.data.frame (   colData (  object ) ) ) } else  {   message (  \"using supplied model matrix\" ) }   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  {   aboveMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  100  if (    sum (  aboveMinDisp , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   minDisp *  10 )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )    attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" ) -  0.25   return (  object ) }   resList -   estimateDispersionPriorVar (  objectNZ ,  aboveMinDisp ,  modelMatrix )   dispPriorVar -   resList $ dispPriorVar   varLogDispEsts -   resList $ varLogDispEsts   expVarLogDisp -   resList $ expVarLogDisp    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts    attr (   dispersionFunction (  object ) ,  \"expVarLogDisp\" ) -  expVarLogDisp }   stopifnot (    length (  dispPriorVar ) ==  1 )    attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" ) -  dispPriorVar # could be coming from a previous run, and need to import varLogDispEsts # for the calculation of outliers  if (  !   is.null (   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) ) )  {   varLogDispEsts -   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) } else  { # provided dispPriorVar, so need to calculate observed varLogDispEsts # this code is copied from estimateDispPriorVar()   aboveMinDisp -     mcols (  objectNZ ) $ dispGeneEst =   minDisp *  100   stopifnot (    sum (  aboveMinDisp , na.rm =  TRUE ) undefined  0 )   dispResiduals -    log (    mcols (  objectNZ ) $ dispGeneEst ) -   log (    mcols (  objectNZ ) $ dispFit )   varLogDispEsts -    mad (   dispResiduals [  aboveMinDisp ] , na.rm =  TRUE ) ^  2    attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) -  varLogDispEsts } # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one order of magnitude # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDisp ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  TRUE ) # prepare dispersions for storage in mcols(object)   dispMAP -   exp (   dispResMAP $ log_alpha ) # when lacking convergence from the C++ routine # we use an R function to estimate dispersions. # This finds the maximum of a smooth curve along a # grid of posterior evaluations   dispConv -    dispResMAP $ iter undefined  maxit   refitDisp -  !  dispConv  if (    sum (  refitDisp ) undefined  0 )  {   dispInR -   fitDispInR ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =    log (    mcols (  objectNZ ) $ dispFit ) [  refitDisp ] , logAlphaPriorSigmaSq =  log_alpha_prior_sigmasq , usePrior =  TRUE )    dispMAP [  refitDisp ] -  dispInR }   dispersionFinal -  dispMAP # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEsts )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispOutlier =  dispOutlier , dispMAP =  dispMAP )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , modelMatrix = NULL , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (  !   is.null (    mcols (  object ) $ dispersion ) )  {  if (  !  quiet )   message (  \"found already estimated dispersions, removing these\" )   removeCols -   c (  \"dispersion\" ,  \"dispOutlier\" ,  \"dispMAP\" ,  \"dispIter\" ,  \"dispConv\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols , drop =  FALSE ] }  if (   is.null (  modelMatrix ) )  {   modelMatrix -   model.matrix (   design (  object ) , data =   colData (  object ) ) } else  {   message (  \"using supplied model matrix\" ) } # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  { # if no gene-wise estimates above minimum  if (    sum (     mcols (  object ) $ dispGeneEst =   minDisp *  100 , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   minDisp *  10 )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  0.25    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn   return (  object ) }   dispPriorVar -   estimateDispersionsPriorVar (  object , modelMatrix =  modelMatrix )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn } else  {   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn }   stopifnot (    length (  dispPriorVar ) ==  1 )   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]   varLogDispEsts -   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one order of magnitude # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDispWrapper ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , use_priorSEXP =  TRUE ) # prepare dispersions for storage in mcols(object)   dispMAP -   exp (   dispResMAP $ log_alpha ) # when lacking convergence from the C++ routine # we use an R function to estimate dispersions. # This finds the maximum of a smooth curve along a # grid of posterior evaluations   dispConv -    dispResMAP $ iter undefined  maxit   refitDisp -  !  dispConv  if (    sum (  refitDisp ) undefined  0 )  {   dispInR -   fitDispGridWrapper ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =    log (    mcols (  objectNZ ) $ dispFit ) [  refitDisp ] , logAlphaPriorSigmaSq =  log_alpha_prior_sigmasq , usePrior =  TRUE )    dispMAP [  refitDisp ] -  dispInR } # bound the dispersion estimate between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   dispMAP -   pmin (   pmax (  dispMAP ,  minDisp ) ,  maxDisp )   dispersionFinal -  dispMAP # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEsts )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispOutlier =  dispOutlier , dispMAP =  dispMAP )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  }
}

2.
{
  "old_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE , betaPriorUpperQuantile = .05 )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (      length (  betaPriorUpperQuantile ) ==  1 undefined   betaPriorUpperQuantile undefined  0 undefined   betaPriorUpperQuantile undefined  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object ) # run check on the formula   modelsAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelsAsFormula )  {   checkLRT (  full ,  reduced ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  modelMatrixType ) )  {   blindDesign -    design (  object ) ==   formula (  ~  1 )   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # if there are interaction terms present in the design # then we should only use the prior on the interaction terms  if (    any (   termsOrder undefined  2 ) undefined   modelMatrixType ==  \"expanded\" )  {   stop (  \"interactions higher than 2nd order and usage of expanded model matrices\r\nhas not been implemented\" ) }   priorOnlyInteraction -    interactionPresent undefined  betaPrior undefined   missing (  betaPriorVar ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {  if (  modelsAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( objectNZ =  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , modelMatrixType =  modelMatrixType , betaPriorVar =  betaPriorVar , priorOnlyInteraction =  priorOnlyInteraction , upperQuantile =  betaPriorUpperQuantile )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType    attr (  object ,  \"test\" ) -  \"LRT\"   p -   ncol (  modelMatrix )   m -   nrow (  modelMatrix )   H -   fullModel $ hat_diagonals # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelsAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , modelMatrixType = \"standard\" , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object ) # run check on the formula   modelAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   colData (  object ) )   reducedModelMatrix -   model.matrix (  reduced , data =   colData (  object ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {  if (  betaPrior )  {   stop (  \"user-supplied model matrices require betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (  modelAsFormula )  {  if (   is.null (  modelMatrixType ) )  {   modelMatrixType -  \"standard\" } # check for intercept   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } } else  {   modelMatrixType -  \"user-supplied\"   renameCols -  FALSE } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (  !  betaPrior )  {  if (  modelAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , renameCols =  renameCols , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar   mleBetaMatrix -   priorFull $ mleBetaMatrix # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"test\" ) -  \"LRT\" # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fullModel $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero )   H -   fullModel $ hat_diagonals # calculate Cook's distance   dispModelMatrix -  if (   modelMatrixType ==  \"expanded\" )  {   model.matrix (   design (  object ) , data =   colData (  object ) ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE )   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL } # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,  mleBetas ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}



##########
Added Non Default Parameters
##########

0.
{
  "old_function": {
    "name": "estimateSizeFactorsForMatrix",
    "representation": "estimateSizeFactorsForMatrix",
    "parameters": "function ( counts , locfunc = median , geoMeans )",
    "body": "{  if (   missing (  geoMeans ) )  {   loggeomeans -   rowMeans (   log (  counts ) ) } else  {  if (    length (  geoMeans ) !=   nrow (  counts ) )  {   stop (  \"geoMeans should be as long as the number of rows of counts\" ) }   loggeomeans -   log (  geoMeans ) }  if (   all (   is.infinite (  loggeomeans ) ) )  {   stop (  \"every gene contains at least one zero, cannot compute log geometric means\" ) }   apply (  counts ,  2 ,  function ( cnts )  {   exp (   locfunc (   (    log (  cnts ) -  loggeomeans ) [    is.finite (  loggeomeans ) undefined   cnts undefined  0 ] ) ) } ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateSizeFactorsForMatrix",
    "representation": "estimateSizeFactorsForMatrix",
    "parameters": "function ( counts , locfunc = stats :: median , geoMeans , controlGenes )",
    "body": "{  if (   missing (  geoMeans ) )  {   loggeomeans -   rowMeans (   log (  counts ) ) } else  {  if (    length (  geoMeans ) !=   nrow (  counts ) )  {   stop (  \"geoMeans should be as long as the number of rows of counts\" ) }   loggeomeans -   log (  geoMeans ) }  if (   all (   is.infinite (  loggeomeans ) ) )  {   stop (  \"every gene contains at least one zero, cannot compute log geometric means\" ) }   sf -  if (   missing (  controlGenes ) )  {   apply (  counts ,  2 ,  function ( cnts )  {   exp (   locfunc (   (    log (  cnts ) -  loggeomeans ) [    is.finite (  loggeomeans ) undefined   cnts undefined  0 ] ) ) } ) } else  {  if (  !  (    is.numeric (  controlGenes ) |   is.logical (  controlGenes ) ) )  {   stop (  \"controlGenes should be either a numeric or logical vector\" ) }   loggeomeansSub -   loggeomeans [  controlGenes ]   apply (   counts [  controlGenes , , drop =  FALSE ] ,  2 ,  function ( cnts )  {   exp (   locfunc (   (    log (  cnts ) -  loggeomeansSub ) [    is.finite (  loggeomeansSub ) undefined   cnts undefined  0 ] ) ) } ) }  sf } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" )",
    "body": "{  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }   test -   attr (  object ,  \"test\" )   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # allows use of 'name' for expanded model matrices if there are interactions  if (     (   test ==  \"Wald\" ) undefined  isExpanded undefined   missing (  contrast ) undefined   all (   termsOrder undefined  2 ) )  {  if (   missing (  name ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) )   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  altHypothesis ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) } # check to see at least one of these are present   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) )  if (  !  (   WaldResults |  LRTResults ) )  {   stop (  \"cannot find appropriate results in the DESeqDataSet.\r\npossibly nbinomWaldTest or nbinomLRT has not yet been run.\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {  if (    is.character (  contrast ) undefined    length (  contrast ) !=  3 )  {   stop (  \"'contrast', as a character vector of length 3, should have the form:\r\ncontrast = c('factorName','numeratorLevel','denominatorLevel'),\r\nsee the manual page of ?results for more information\" ) }  if (    is.list (  contrast ) undefined    length (  contrast ) !=  2 )  {   stop (  \"'contrast', as a list, should have length 2,\r\nsee the manual page of ?results for more information\" ) }  if (    is.list (  contrast ) undefined  !  (    is.character (   contrast [[  1 ] ] ) undefined   is.character (   contrast [[  2 ] ] ) ) )  {   stop (  \"'contrast', as a list of length 2, should have character vectors as elements,\r\nsee the manual page of ?results for more information\" ) } # pass down whether the model matrix type was \"expanded\"   res -   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues ) } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   warning (  \"tests of log fold change above or below a theshold are Wald tests.\r\nLikelihood ratio test p-values are overwritten\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"modelMatrix\" ) )   p -   ncol (   attr (  object ,  \"modelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # perform independent filtering  if (  independentFiltering )  {  if (   missing (  filter ) )  {   filter -   res $ baseMean }  if (   missing (  theta ) )  {   lowerQuantile -   mean (   filter ==  0 )  if (   lowerQuantile undefined  .95 )   upperQuantile -  .95 else   upperQuantile -  1   theta -   seq (  lowerQuantile ,  upperQuantile , length =  20 ) }   stopifnot (    length (  theta ) undefined  1 )   stopifnot (    length (  filter ) ==   nrow (  object ) )   filtPadj -   filtered_p ( filter =  filter , test =   res $ pvalue , theta =  theta , method =  pAdjustMethod )   numRej -   colSums (   filtPadj undefined  alpha , na.rm =  TRUE )   j -   which.max (  numRej )    res $ padj -   filtPadj [ ,  j , drop =  TRUE ]   cutoffs -   quantile (  filter ,  theta )   filterThreshold -   cutoffs [  j ]   filterNumRej -   data.frame ( theta =  theta , numRej =  numRej ) } else  { # regular p-value adjustment # which does not include those rows which were removed # by maximum Cook's distance    res $ padj -   p.adjust (   res $ pvalue , method =  pAdjustMethod ) }      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" )   deseqRes -   DESeqResults (  res )  if (  independentFiltering )  {    attr (  deseqRes ,  \"filterThreshold\" ) -  filterThreshold    attr (  deseqRes ,  \"filterNumRej\" ) -  filterNumRej }  deseqRes } ",
    "filename": "results.txt"
  },
  "new_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" , format = c ( \"DataFrame\" , \"GRanges\" , \"GRangesList\" ) , test , addMLE = FALSE , tidy = FALSE , parallel = FALSE , BPPARAM = bpparam ( ) )",
    "body": "{ # match args   format -   match.arg (  format , choices =   c (  \"DataFrame\" ,  \"GRanges\" ,  \"GRangesList\" ) )   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) ) # initial argument testing   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call DESeq, nbinomWaldTest, or nbinomLRT\" ) }  if (   missing (  test ) )  {   test -   attr (  object ,  \"test\" ) } else  if (    test ==  \"Wald\" undefined    attr (  object ,  \"test\" ) ==  \"LRT\" )  { # initially test was LRT, now need to add Wald statistics and p-values   object -   makeWaldTest (  object ) } else  if (    test ==  \"LRT\" undefined    attr (  object ,  \"test\" ) ==  \"Wald\" )  {   stop (  \"the LRT requires the user run nbinomLRT or DESeq(dds,test='LRT')\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) }  if (   addMLE undefined  !   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"addMLE=TRUE is only for when a beta prior was used. otherwise, the log2 fold changes are already MLE\" ) }  if (    format ==  \"GRanges\" undefined   is (   rowRanges (  object ) ,  \"GRangesList\" ) )  {  if (   any (    elementLengths (   rowRanges (  object ) ) ==  0 ) )  {   stop (  \"rowRanges is GRangesList and one or more GRanges have length 0. Use format='DataFrame' or 'GRangesList'\" ) } }  if (  !   missing (  contrast ) )  {  if (     attr (  object ,  \"modelMatrixType\" ) ==  \"user-supplied\" undefined   is.character (  contrast ) )  {   stop (  \"only list- and numeric-type contrasts are supported for user-supplied model matrices\" ) } }   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # if neither 'contrast' nor 'name' were specified, create the default result table: # the last level / first level for the last variable in design. # (unless there are interactions, in which case the lastCoefName is pulled below)  if (      (   test ==  \"Wald\" ) undefined  (   isExpanded |  !  hasIntercept ) undefined   missing (  contrast ) undefined   missing (  name ) undefined   all (   termsOrder undefined  2 ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) } else  {  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } } # check to see at least one of these are present   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) )  if (  !  (   WaldResults |  LRTResults ) )  {   stop (  \"cannot find appropriate results in the DESeqDataSet.\r\npossibly nbinomWaldTest or nbinomLRT has not yet been run.\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {   resNames -   resultsNames (  object ) # do some arg checking/cleaning   contrast -   checkContrast (  contrast ,  resNames ) ### cleanContrast call ### # need to go back to C++ code in order to build the beta covariance matrix # then this is multiplied by the numeric contrast to get the Wald statistic. # with 100s of samples, this can get slow, so offer parallelization   res -  if (  !  parallel )  {   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } else  if (  parallel )  {   nworkers -   BPPARAM $ workers   idx -   factor (   sort (   rep (   seq_len (  nworkers ) , length =   nrow (  object ) ) ) )   do.call (  rbind ,   bplapply (   levels (  idx ) ,  function ( l )  {   cleanContrast (   object [   idx ==  l , , drop =  FALSE ] ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } , BPPARAM =  BPPARAM ) ) } } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # add unshrunken MLE coefficients to the results table  if (  addMLE )  {  if (  !   missing (  contrast ) )  {  if (   is.numeric (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )  if (   is.list (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )   res -   cbind (  res ,   mleContrast (  object ,  contrast ) ) } else  {   mleName -   paste0 (  \"MLE_\" ,  name )   mleNames -    names (   mcols (  object ) ) [   grep (  \"MLE_\" ,   names (   mcols (  object ) ) ) ]  if (  !   mleName %in%  mleNames )   stop (  \"MLE_ plus 'name' was not found as a column in mcols(dds)\" )   mleColumn -    mcols (  object ) [  mleName ]    names (  mleColumn ) -  \"lfcMLE\"     mcols (  mleColumn ) $ description -   paste (  \"log2 fold change (MLE):\" ,  name )   res -   cbind (  res ,  mleColumn ) }   res -   res [ ,   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcMLE\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) ] # if an all zero contrast, also zero out the lfcMLE     res $ lfcMLE [   which (     res $ log2FoldChange ==  0 undefined    res $ stat ==  0 ) ] -  0 } # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   warning (  \"tests of log fold change above or below a theshold are Wald tests.\r\nLikelihood ratio test p-values are overwritten\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newStat -     sign (   res $ log2FoldChange ) *   pmax (  0 ,  (    abs (   res $ log2FoldChange ) -  lfcThreshold ) ) /   res $ lfcSE   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   newStatAbove -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   newStatBelow -    pmax (  0 ,    res $ log2FoldChange +  lfcThreshold ) /   res $ lfcSE   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newStat -   pmin (  newStatAbove ,  newStatBelow )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newStat -    pmax (  0 ,    res $ log2FoldChange -  lfcThreshold ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newStat -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ stat -  newStat    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"dispModelMatrix\" ) )   p -   ncol (   attr (  object ,  \"dispModelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero due to replaced counts, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0  if (  addMLE )  {     res $ lfcMLE [  nowZero ] -  0 }     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # p-value adjustment   paRes -   pvalueAdjustment (  res ,  independentFiltering ,  filter ,  theta ,  alpha ,  pAdjustMethod )    res $ padj -   paRes $ padj # adding metadata columns for padj      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" ) # make results object   deseqRes -   DESeqResults (  res ) # finalize object / add attributes / make GRanges  if (  independentFiltering )  {    attr (  deseqRes ,  \"filterThreshold\" ) -   paRes $ filterThreshold    attr (  deseqRes ,  \"filterNumRej\" ) -   paRes $ filterNumRej } # remove rownames and attach as a new column, 'row'  if (  tidy )  {   colnms -   colnames (  deseqRes )    deseqRes $ row -   rownames (  deseqRes )     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"type\" ] -  \"results\"     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"description\" ] -  \"row names\"   deseqRes -   deseqRes [ ,   c (  \"row\" ,  colnms ) ]    rownames (  deseqRes ) -  NULL   deseqRes -   as.data.frame (  deseqRes ) }  if (   format ==  \"DataFrame\" )  {   return (  deseqRes ) } else  if (   format ==  \"GRangesList\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRanges\" )   message (  \"rowRanges is GRanges\" )   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } else  if (   format ==  \"GRanges\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRangesList\" )  {   message (  \"rowRanges is GRangesList, unlisting the ranges\" )   out -   unlist (   range (   rowRanges (  object ) ) )    mcols (  out ) -  deseqRes   return (  out ) } else  {   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } } } ",
    "filename": "results.txt"
  }
}

2.
{
  "old_function": {
    "name": "estimateSizeFactors",
    "representation": "estimateSizeFactors",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , locfunc = median , geoMeans )",
    "body": "{   object -   sanitizeColData (  object )    sizeFactors (  object ) -   estimateSizeFactorsForMatrix (   counts (  object ) ,  locfunc , geoMeans =  geoMeans )  object } ",
    "replacementFunction": "estimateSizeFactors.DESeqDataSet",
    "filename": "methods.txt"
  },
  "new_function": {
    "name": "estimateSizeFactors",
    "representation": "estimateSizeFactors",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , type = c ( \"ratio\" , \"iterate\" ) , locfunc = stats :: median , geoMeans , controlGenes , normMatrix )",
    "body": "{   type -   match.arg (  type ,   c (  \"ratio\" ,  \"iterate\" ) )   object -   sanitizeColData (  object )  if (   type ==  \"iterate\" )  {    sizeFactors (  object ) -   estimateSizeFactorsIterate (  object ) } else  {  if (   missing (  normMatrix ) )  {    sizeFactors (  object ) -   estimateSizeFactorsForMatrix (   counts (  object ) , locfunc =  locfunc , geoMeans =  geoMeans , controlGenes =  controlGenes ) } else  {    normalizationFactors (  object ) -   estimateNormFactors (   counts (  object ) , normMatrix =  normMatrix , locfunc =  locfunc , geoMeans =  geoMeans , controlGenes =  controlGenes )   message (  \"adding normalization factors which account for library size\" ) } }  object } ",
    "replacementFunction": "estimateSizeFactors.DESeqDataSet",
    "filename": "methods.txt"
  }
}



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "estimateSizeFactorsForMatrix",
    "representation": "estimateSizeFactorsForMatrix",
    "parameters": "function ( counts , locfunc = median , geoMeans )",
    "body": "{  if (   missing (  geoMeans ) )  {   loggeomeans -   rowMeans (   log (  counts ) ) } else  {  if (    length (  geoMeans ) !=   nrow (  counts ) )  {   stop (  \"geoMeans should be as long as the number of rows of counts\" ) }   loggeomeans -   log (  geoMeans ) }  if (   all (   is.infinite (  loggeomeans ) ) )  {   stop (  \"every gene contains at least one zero, cannot compute log geometric means\" ) }   apply (  counts ,  2 ,  function ( cnts )  {   exp (   locfunc (   (    log (  cnts ) -  loggeomeans ) [    is.finite (  loggeomeans ) undefined   cnts undefined  0 ] ) ) } ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateSizeFactorsForMatrix",
    "representation": "estimateSizeFactorsForMatrix",
    "parameters": "function ( counts , locfunc = stats :: median , geoMeans , controlGenes )",
    "body": "{  if (   missing (  geoMeans ) )  {   loggeomeans -   rowMeans (   log (  counts ) ) } else  {  if (    length (  geoMeans ) !=   nrow (  counts ) )  {   stop (  \"geoMeans should be as long as the number of rows of counts\" ) }   loggeomeans -   log (  geoMeans ) }  if (   all (   is.infinite (  loggeomeans ) ) )  {   stop (  \"every gene contains at least one zero, cannot compute log geometric means\" ) }   sf -  if (   missing (  controlGenes ) )  {   apply (  counts ,  2 ,  function ( cnts )  {   exp (   locfunc (   (    log (  cnts ) -  loggeomeans ) [    is.finite (  loggeomeans ) undefined   cnts undefined  0 ] ) ) } ) } else  {  if (  !  (    is.numeric (  controlGenes ) |   is.logical (  controlGenes ) ) )  {   stop (  \"controlGenes should be either a numeric or logical vector\" ) }   loggeomeansSub -   loggeomeans [  controlGenes ]   apply (   counts [  controlGenes , , drop =  FALSE ] ,  2 ,  function ( cnts )  {   exp (   locfunc (   (    log (  cnts ) -  loggeomeansSub ) [    is.finite (  loggeomeansSub ) undefined   cnts undefined  0 ] ) ) } ) }  sf } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE , betaPriorUpperQuantile = .05 )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 )   stopifnot (      length (  betaPriorUpperQuantile ) ==  1 undefined   betaPriorUpperQuantile undefined  0 undefined   betaPriorUpperQuantile undefined  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ] # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  modelMatrixType ) )  {   blindDesign -    design (  object ) ==   formula (  ~  1 )   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # if there are interaction terms present in the design # then we should only use the prior on the interaction terms  if (    any (   termsOrder undefined  2 ) undefined   modelMatrixType ==  \"expanded\" )  {   stop (  \"interactions higher than 2nd order and usage of expanded model matrices\r\nhas not been implemented. we recommend instead using a likelihood\r\nratio test, i.e. DESeq with argument test='LRT' and betaPrior=FALSE.\" ) }   priorOnlyInteraction -    interactionPresent undefined  betaPrior undefined   missing (  betaPriorVar )  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) }  if (  betaPrior )  {   priorFitList -   fitGLMsWithPrior ( objectNZ =  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , modelMatrixType =  modelMatrixType , betaPriorVar =  betaPriorVar , priorOnlyInteraction =  priorOnlyInteraction , upperQuantile =  betaPriorUpperQuantile )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix } # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType    attr (  object ,  \"test\" ) -  \"Wald\"   m -   nrow (  modelMatrix )   p -   ncol (  modelMatrix ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,   fit $ modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -  if (  betaPrior )  {   paste (  \"log2 fold change (MAP):\" ,  modelMatrixNamesSpaces ) } else  {   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces ) }   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , modelMatrix = NULL , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 )  if (   !   is.null (  modelMatrix ) undefined  betaPrior )  {   stop (  \"the model matrix can only be user-supplied if betaPrior=FALSE\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (   is.null (  modelMatrix ) )  {   modelAsFormula -  TRUE # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )   blindDesign -    design (  object ) ==   formula (  ~  1 )  if (    missing (  modelMatrixType ) ||   is.null (  modelMatrixType ) )  {   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (     modelMatrixType ==  \"standard\" undefined  betaPrior undefined  !  blindDesign )  {   message (  \"-- standard model matrices are used for factors with two levels and an interaction,\r\n   where the main effects are for the reference level of other factors.\r\n   see the 'Interactions' section of the vignette for more details: vignette('DESeq2')\" ) }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {   message (  \"using supplied model matrix\" )   modelAsFormula -  FALSE    attr (  object ,  \"modelMatrixType\" ) -  \"user-supplied\"   renameCols -  FALSE }  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , renameCols =  renameCols , modelMatrix =  modelMatrix )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } else  {   priorFitList -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix   mleBetaMatrix -   priorFitList $ mleBetaMatrix # will add the MLE betas, so remove any which exist already # (possibly coming from estimateMLEForBetaPriorVar)    mcols (  object ) -    mcols (  object ) [ ,   grep (  \"MLE_\" ,   names (   mcols (  object ) ) , invert =  TRUE ) ] } # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fit $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"test\" ) -  \"Wald\" # calculate Cook's distance   dispModelMatrix -  if (  modelAsFormula )  {   model.matrix (   design (  object ) , data =   colData (  object ) ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,  mleBetas ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

2.
{
  "old_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE , betaPriorUpperQuantile = .05 )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (      length (  betaPriorUpperQuantile ) ==  1 undefined   betaPriorUpperQuantile undefined  0 undefined   betaPriorUpperQuantile undefined  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object ) # run check on the formula   modelsAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelsAsFormula )  {   checkLRT (  full ,  reduced ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   model.matrix (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"you had results columns, replacing these\" )   object -   removeResults (  object ) }  if (  !   \"allZero\" %in%   names (   mcols (  object ) ) )  {   object -   getBaseMeansAndVariances (  object ) } # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  modelMatrixType ) )  {   blindDesign -    design (  object ) ==   formula (  ~  1 )   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # if there are interaction terms present in the design # then we should only use the prior on the interaction terms  if (    any (   termsOrder undefined  2 ) undefined   modelMatrixType ==  \"expanded\" )  {   stop (  \"interactions higher than 2nd order and usage of expanded model matrices\r\nhas not been implemented\" ) }   priorOnlyInteraction -    interactionPresent undefined  betaPrior undefined   missing (  betaPriorVar ) # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , ]  if (  !  betaPrior )  {  if (  modelsAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( objectNZ =  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , modelMatrixType =  modelMatrixType , betaPriorVar =  betaPriorVar , priorOnlyInteraction =  priorOnlyInteraction , upperQuantile =  betaPriorUpperQuantile )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType    attr (  object ,  \"test\" ) -  \"LRT\"   p -   ncol (  modelMatrix )   m -   nrow (  modelMatrix )   H -   fullModel $ hat_diagonals # store mu in case the user did not call estimateDispersionsGeneEst     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero ) # calculate Cook's distance   cooks -   calculateCooksDistance (  objectNZ ,  H ,  p ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  modelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelsAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   coefInfo -   paste (  \"log2 fold change:\" ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , modelMatrixType = \"standard\" , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object ) # run check on the formula   modelAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   colData (  object ) )   reducedModelMatrix -   model.matrix (  reduced , data =   colData (  object ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {  if (  betaPrior )  {   stop (  \"user-supplied model matrices require betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (  modelAsFormula )  {  if (   is.null (  modelMatrixType ) )  {   modelMatrixType -  \"standard\" } # check for intercept   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } } else  {   modelMatrixType -  \"user-supplied\"   renameCols -  FALSE } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (  !  betaPrior )  {  if (  modelAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , renameCols =  renameCols , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar   mleBetaMatrix -   priorFull $ mleBetaMatrix # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"test\" ) -  \"LRT\" # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fullModel $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero )   H -   fullModel $ hat_diagonals # calculate Cook's distance   dispModelMatrix -  if (   modelMatrixType ==  \"expanded\" )  {   model.matrix (   design (  object ) , data =   colData (  object ) ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE )   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL } # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,  mleBetas ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

3.
{
  "old_function": {
    "name": "replaceOutliers",
    "representation": "replaceOutliers",
    "parameters": "function ( dds , trim = .2 , cooksCutoff , minReplicates = 7 , whichSamples )",
    "body": "{  if (    is.null (   attr (  dds ,  \"modelMatrix\" ) ) |  !  (   \"cooks\" %in%   names (   assays (  dds ) ) ) )  {   stop (  \"first run DESeq, nbinomWaldTest, or nbinomLRT to identify outliers\" ) }  if (   minReplicates undefined  3 )  {   stop (  \"at least 3 replicates are necessary in order to indentify a sample as a count outlier\" ) }   stopifnot (    is.numeric (  minReplicates ) undefined    length (  minReplicates ) ==  1 )   p -   ncol (   attr (  dds ,  \"modelMatrix\" ) )   m -   ncol (  dds )  if (   m =  p )  {     assays (  dds ) [[  \"originalCounts\" ] ] -   counts (  dds )   return (  dds ) }  if (   missing (  cooksCutoff ) )  {   cooksCutoff -   qf (  .99 ,  p ,   m -  p ) }   idx -   which (     assays (  dds ) [[  \"cooks\" ] ] undefined  cooksCutoff )     mcols (  dds ) $ replace -   apply (    assays (  dds ) [[  \"cooks\" ] ] ,  1 ,  function ( row )   any (   row undefined  cooksCutoff ) )     mcols (   mcols (  dds ) , use.names =  TRUE ) [  \"replace\" , ] -   DataFrame ( type =  \"intermediate\" , description =  \"had counts replaced\" )   trimBaseMean -   apply (   counts (  dds , normalized =  TRUE ) ,  1 ,  mean , trim =  trim ) # build a matrix of counts based on the trimmed mean and the size factors   replacementCounts -  if (  !   is.null (   normalizationFactors (  dds ) ) )  {   as.integer (    matrix (   rep (  trimBaseMean ,   ncol (  dds ) ) , ncol =   ncol (  dds ) ) *   normalizationFactors (  dds ) ) } else  {   as.integer (   outer (  trimBaseMean ,   sizeFactors (  dds ) ,  \"*\" ) ) } # replace only those values which fall above the cutoff on Cook's distance   newCounts -   counts (  dds )    newCounts [  idx ] -   replacementCounts [  idx ]  if (   missing (  whichSamples ) )  {   whichSamples -   nOrMoreInCell (   attr (  dds ,  \"modelMatrix\" ) , n =  minReplicates ) }   stopifnot (   is.logical (  whichSamples ) )    dds $ replaceable -  whichSamples     mcols (   colData (  dds ) , use.names =  TRUE ) [  \"replaceable\" , ] -   DataFrame ( type =  \"intermediate\" , description =  \"outliers can be replaced\" )     assays (  dds ) [[  \"originalCounts\" ] ] -   counts (  dds )  if (    sum (  whichSamples ) ==  0 )  {   return (  dds ) }     counts (  dds ) [ ,  whichSamples ] -   newCounts [ ,  whichSamples ]  dds } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "replaceOutliers",
    "representation": "replaceOutliers",
    "parameters": "function ( object , trim = .2 , cooksCutoff , minReplicates = 7 , whichSamples )",
    "body": "{  if (    is.null (   attr (  object ,  \"modelMatrix\" ) ) |  !  (   \"cooks\" %in%   assayNames (  object ) ) )  {   stop (  \"first run DESeq, nbinomWaldTest, or nbinomLRT to identify outliers\" ) }  if (   minReplicates undefined  3 )  {   stop (  \"at least 3 replicates are necessary in order to indentify a sample as a count outlier\" ) }   stopifnot (    is.numeric (  minReplicates ) undefined    length (  minReplicates ) ==  1 )   p -   ncol (   attr (  object ,  \"modelMatrix\" ) )   m -   ncol (  object )  if (   m =  p )  {     assays (  object ) [[  \"originalCounts\" ] ] -   counts (  object )   return (  object ) }  if (   missing (  cooksCutoff ) )  {   cooksCutoff -   qf (  .99 ,  p ,   m -  p ) }   idx -   which (     assays (  object ) [[  \"cooks\" ] ] undefined  cooksCutoff )     mcols (  object ) $ replace -   apply (    assays (  object ) [[  \"cooks\" ] ] ,  1 ,  function ( row )   any (   row undefined  cooksCutoff ) )     mcols (   mcols (  object ) , use.names =  TRUE ) [  \"replace\" , ] -   DataFrame ( type =  \"intermediate\" , description =  \"had counts replaced\" )   trimBaseMean -   apply (   counts (  object , normalized =  TRUE ) ,  1 ,  mean , trim =  trim ) # build a matrix of counts based on the trimmed mean and the size factors   replacementCounts -  if (  !   is.null (   normalizationFactors (  object ) ) )  {   as.integer (    matrix (   rep (  trimBaseMean ,   ncol (  object ) ) , ncol =   ncol (  object ) ) *   normalizationFactors (  object ) ) } else  {   as.integer (   outer (  trimBaseMean ,   sizeFactors (  object ) ,  \"*\" ) ) } # replace only those values which fall above the cutoff on Cook's distance   newCounts -   counts (  object )    newCounts [  idx ] -   replacementCounts [  idx ]  if (   missing (  whichSamples ) )  {   whichSamples -   nOrMoreInCell (   attr (  object ,  \"modelMatrix\" ) , n =  minReplicates ) }   stopifnot (   is.logical (  whichSamples ) )    object $ replaceable -  whichSamples     mcols (   colData (  object ) , use.names =  TRUE ) [  \"replaceable\" , ] -   DataFrame ( type =  \"intermediate\" , description =  \"outliers can be replaced\" )     assays (  object ) [[  \"originalCounts\" ] ] -   counts (  object )  if (    sum (  whichSamples ) ==  0 )  {   return (  object ) }     counts (  object ) [ ,  whichSamples ] -   newCounts [ ,  whichSamples , drop =  FALSE ]  object } ",
    "filename": "core.txt"
  }
}

4.
{
  "old_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" )",
    "body": "{  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call 'DESeq','nbinomWaldTest', or 'nbinomLRT'\" ) }   test -   attr (  object ,  \"test\" )   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # allows use of 'name' for expanded model matrices if there are interactions  if (     (   test ==  \"Wald\" ) undefined  isExpanded undefined   missing (  contrast ) undefined   all (   termsOrder undefined  2 ) )  {  if (   missing (  name ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) }   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) )   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  altHypothesis ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) } # check to see at least one of these are present   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) )  if (  !  (   WaldResults |  LRTResults ) )  {   stop (  \"cannot find appropriate results in the DESeqDataSet.\r\npossibly nbinomWaldTest or nbinomLRT has not yet been run.\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {  if (    is.character (  contrast ) undefined    length (  contrast ) !=  3 )  {   stop (  \"'contrast', as a character vector of length 3, should have the form:\r\ncontrast = c('factorName','numeratorLevel','denominatorLevel'),\r\nsee the manual page of ?results for more information\" ) }  if (    is.list (  contrast ) undefined    length (  contrast ) !=  2 )  {   stop (  \"'contrast', as a list, should have length 2,\r\nsee the manual page of ?results for more information\" ) }  if (    is.list (  contrast ) undefined  !  (    is.character (   contrast [[  1 ] ] ) undefined   is.character (   contrast [[  2 ] ] ) ) )  {   stop (  \"'contrast', as a list of length 2, should have character vectors as elements,\r\nsee the manual page of ?results for more information\" ) } # pass down whether the model matrix type was \"expanded\"   res -   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues ) } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   warning (  \"tests of log fold change above or below a theshold are Wald tests.\r\nLikelihood ratio test p-values are overwritten\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"modelMatrix\" ) )   p -   ncol (   attr (  object ,  \"modelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # perform independent filtering  if (  independentFiltering )  {  if (   missing (  filter ) )  {   filter -   res $ baseMean }  if (   missing (  theta ) )  {   lowerQuantile -   mean (   filter ==  0 )  if (   lowerQuantile undefined  .95 )   upperQuantile -  .95 else   upperQuantile -  1   theta -   seq (  lowerQuantile ,  upperQuantile , length =  20 ) }   stopifnot (    length (  theta ) undefined  1 )   stopifnot (    length (  filter ) ==   nrow (  object ) )   filtPadj -   filtered_p ( filter =  filter , test =   res $ pvalue , theta =  theta , method =  pAdjustMethod )   numRej -   colSums (   filtPadj undefined  alpha , na.rm =  TRUE )   j -   which.max (  numRej )    res $ padj -   filtPadj [ ,  j , drop =  TRUE ]   cutoffs -   quantile (  filter ,  theta )   filterThreshold -   cutoffs [  j ]   filterNumRej -   data.frame ( theta =  theta , numRej =  numRej ) } else  { # regular p-value adjustment # which does not include those rows which were removed # by maximum Cook's distance    res $ padj -   p.adjust (   res $ pvalue , method =  pAdjustMethod ) }      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" )   deseqRes -   DESeqResults (  res )  if (  independentFiltering )  {    attr (  deseqRes ,  \"filterThreshold\" ) -  filterThreshold    attr (  deseqRes ,  \"filterNumRej\" ) -  filterNumRej }  deseqRes } ",
    "filename": "results.txt"
  },
  "new_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" , format = c ( \"DataFrame\" , \"GRanges\" , \"GRangesList\" ) , test , addMLE = FALSE , tidy = FALSE , parallel = FALSE , BPPARAM = bpparam ( ) )",
    "body": "{ # match args   format -   match.arg (  format , choices =   c (  \"DataFrame\" ,  \"GRanges\" ,  \"GRangesList\" ) )   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) ) # initial argument testing   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call DESeq, nbinomWaldTest, or nbinomLRT\" ) }  if (   missing (  test ) )  {   test -   attr (  object ,  \"test\" ) } else  if (    test ==  \"Wald\" undefined    attr (  object ,  \"test\" ) ==  \"LRT\" )  { # initially test was LRT, now need to add Wald statistics and p-values   object -   makeWaldTest (  object ) } else  if (    test ==  \"LRT\" undefined    attr (  object ,  \"test\" ) ==  \"Wald\" )  {   stop (  \"the LRT requires the user run nbinomLRT or DESeq(dds,test='LRT')\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) }  if (   addMLE undefined  !   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"addMLE=TRUE is only for when a beta prior was used. otherwise, the log2 fold changes are already MLE\" ) }  if (    format ==  \"GRanges\" undefined   is (   rowRanges (  object ) ,  \"GRangesList\" ) )  {  if (   any (    elementLengths (   rowRanges (  object ) ) ==  0 ) )  {   stop (  \"rowRanges is GRangesList and one or more GRanges have length 0. Use format='DataFrame' or 'GRangesList'\" ) } }  if (  !   missing (  contrast ) )  {  if (     attr (  object ,  \"modelMatrixType\" ) ==  \"user-supplied\" undefined   is.character (  contrast ) )  {   stop (  \"only list- and numeric-type contrasts are supported for user-supplied model matrices\" ) } }   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # if neither 'contrast' nor 'name' were specified, create the default result table: # the last level / first level for the last variable in design. # (unless there are interactions, in which case the lastCoefName is pulled below)  if (      (   test ==  \"Wald\" ) undefined  (   isExpanded |  !  hasIntercept ) undefined   missing (  contrast ) undefined   missing (  name ) undefined   all (   termsOrder undefined  2 ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) } else  {  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } } # check to see at least one of these are present   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) )  if (  !  (   WaldResults |  LRTResults ) )  {   stop (  \"cannot find appropriate results in the DESeqDataSet.\r\npossibly nbinomWaldTest or nbinomLRT has not yet been run.\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {   resNames -   resultsNames (  object ) # do some arg checking/cleaning   contrast -   checkContrast (  contrast ,  resNames ) ### cleanContrast call ### # need to go back to C++ code in order to build the beta covariance matrix # then this is multiplied by the numeric contrast to get the Wald statistic. # with 100s of samples, this can get slow, so offer parallelization   res -  if (  !  parallel )  {   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } else  if (  parallel )  {   nworkers -   BPPARAM $ workers   idx -   factor (   sort (   rep (   seq_len (  nworkers ) , length =   nrow (  object ) ) ) )   do.call (  rbind ,   bplapply (   levels (  idx ) ,  function ( l )  {   cleanContrast (   object [   idx ==  l , , drop =  FALSE ] ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } , BPPARAM =  BPPARAM ) ) } } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # add unshrunken MLE coefficients to the results table  if (  addMLE )  {  if (  !   missing (  contrast ) )  {  if (   is.numeric (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )  if (   is.list (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )   res -   cbind (  res ,   mleContrast (  object ,  contrast ) ) } else  {   mleName -   paste0 (  \"MLE_\" ,  name )   mleNames -    names (   mcols (  object ) ) [   grep (  \"MLE_\" ,   names (   mcols (  object ) ) ) ]  if (  !   mleName %in%  mleNames )   stop (  \"MLE_ plus 'name' was not found as a column in mcols(dds)\" )   mleColumn -    mcols (  object ) [  mleName ]    names (  mleColumn ) -  \"lfcMLE\"     mcols (  mleColumn ) $ description -   paste (  \"log2 fold change (MLE):\" ,  name )   res -   cbind (  res ,  mleColumn ) }   res -   res [ ,   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcMLE\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) ] # if an all zero contrast, also zero out the lfcMLE     res $ lfcMLE [   which (     res $ log2FoldChange ==  0 undefined    res $ stat ==  0 ) ] -  0 } # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   warning (  \"tests of log fold change above or below a theshold are Wald tests.\r\nLikelihood ratio test p-values are overwritten\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newStat -     sign (   res $ log2FoldChange ) *   pmax (  0 ,  (    abs (   res $ log2FoldChange ) -  lfcThreshold ) ) /   res $ lfcSE   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   newStatAbove -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   newStatBelow -    pmax (  0 ,    res $ log2FoldChange +  lfcThreshold ) /   res $ lfcSE   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newStat -   pmin (  newStatAbove ,  newStatBelow )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newStat -    pmax (  0 ,    res $ log2FoldChange -  lfcThreshold ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newStat -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ stat -  newStat    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"dispModelMatrix\" ) )   p -   ncol (   attr (  object ,  \"dispModelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero due to replaced counts, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0  if (  addMLE )  {     res $ lfcMLE [  nowZero ] -  0 }     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # p-value adjustment   paRes -   pvalueAdjustment (  res ,  independentFiltering ,  filter ,  theta ,  alpha ,  pAdjustMethod )    res $ padj -   paRes $ padj # adding metadata columns for padj      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" ) # make results object   deseqRes -   DESeqResults (  res ) # finalize object / add attributes / make GRanges  if (  independentFiltering )  {    attr (  deseqRes ,  \"filterThreshold\" ) -   paRes $ filterThreshold    attr (  deseqRes ,  \"filterNumRej\" ) -   paRes $ filterNumRej } # remove rownames and attach as a new column, 'row'  if (  tidy )  {   colnms -   colnames (  deseqRes )    deseqRes $ row -   rownames (  deseqRes )     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"type\" ] -  \"results\"     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"description\" ] -  \"row names\"   deseqRes -   deseqRes [ ,   c (  \"row\" ,  colnms ) ]    rownames (  deseqRes ) -  NULL   deseqRes -   as.data.frame (  deseqRes ) }  if (   format ==  \"DataFrame\" )  {   return (  deseqRes ) } else  if (   format ==  \"GRangesList\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRanges\" )   message (  \"rowRanges is GRanges\" )   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } else  if (   format ==  \"GRanges\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRangesList\" )  {   message (  \"rowRanges is GRangesList, unlisting the ranges\" )   out -   unlist (   range (   rowRanges (  object ) ) )    mcols (  out ) -  deseqRes   return (  out ) } else  {   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } } } ",
    "filename": "results.txt"
  }
}

5.
{
  "old_function": {
    "name": "estimateSizeFactors",
    "representation": "estimateSizeFactors",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , locfunc = median , geoMeans )",
    "body": "{   object -   sanitizeColData (  object )    sizeFactors (  object ) -   estimateSizeFactorsForMatrix (   counts (  object ) ,  locfunc , geoMeans =  geoMeans )  object } ",
    "replacementFunction": "estimateSizeFactors.DESeqDataSet",
    "filename": "methods.txt"
  },
  "new_function": {
    "name": "estimateSizeFactors",
    "representation": "estimateSizeFactors",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , type = c ( \"ratio\" , \"iterate\" ) , locfunc = stats :: median , geoMeans , controlGenes , normMatrix )",
    "body": "{   type -   match.arg (  type ,   c (  \"ratio\" ,  \"iterate\" ) )   object -   sanitizeColData (  object )  if (   type ==  \"iterate\" )  {    sizeFactors (  object ) -   estimateSizeFactorsIterate (  object ) } else  {  if (   missing (  normMatrix ) )  {    sizeFactors (  object ) -   estimateSizeFactorsForMatrix (   counts (  object ) , locfunc =  locfunc , geoMeans =  geoMeans , controlGenes =  controlGenes ) } else  {    normalizationFactors (  object ) -   estimateNormFactors (   counts (  object ) , normMatrix =  normMatrix , locfunc =  locfunc , geoMeans =  geoMeans , controlGenes =  controlGenes )   message (  \"adding normalization factors which account for library size\" ) } }  object } ",
    "replacementFunction": "estimateSizeFactors.DESeqDataSet",
    "filename": "methods.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_1 deseq2_release_3_2

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_1 deseq2_release_3_2",
    "desc_release_old": "1.8.2",
    "desc_release_new": "1.10.1",
    "old_release_number": 3,
    "new_release_number": 4,
    "function_removals": 0,
    "function_additions": 2,
    "parameter_removals": 1,
    "parameter_additions": 2,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 4,
    "total_count": 4
}

##########
Functions Removed
##########



##########
Functions Added
##########

normTransform
normalizeGeneLength


##########
Removed Non Default Parameters
##########

0.
{
  "old_function": {
    "name": "rlog",
    "representation": "rlog",
    "parameters": "function ( object , blind = TRUE , fast = FALSE , intercept , betaPriorVar , B , fitType = \"parametric\" )",
    "body": "{  if (   is.null (   colnames (  object ) ) )  {    colnames (  object ) -   seq_len (   ncol (  object ) ) }  if (   is.matrix (  object ) )  {   matrixIn -  TRUE   object -   DESeqDataSetFromMatrix (  object ,   DataFrame ( row.names =   colnames (  object ) ) ,  ~  1 ) } else  {   matrixIn -  FALSE }  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   object -   estimateSizeFactors (  object ) }  if (  blind )  {    design (  object ) -  ~  1 } # sparsity test  if (    missing (  intercept ) undefined   missing (  B ) )  {   sparseTest (   counts (  object , normalized =  TRUE ) ,  .9 ,  100 ,  .1 ) }  if (   blind |   is.null (    mcols (  object ) $ dispFit ) )  { # estimate the dispersions on all genes, or if fast=TRUE subset to 1000 non-zero genes  if (   is.null (    mcols (  object ) $ baseMean ) )  {   object -   getBaseMeansAndVariances (  object ) }  if (   !  fast |    sum (     mcols (  object ) $ baseMean undefined  0 ) =  1000 )  {   object -   estimateDispersionsGeneEst (  object , quiet =  TRUE )   object -   estimateDispersionsFit (  object ,  fitType , quiet =  TRUE ) } else  { # select 1000 genes along the range of non-zero base means   idx -    order (    mcols (  object ) $ baseMean ) [   round (   seq ( from =  (    sum (     mcols (  object ) $ baseMean ==  0 ) +  1 ) , to =   nrow (  object ) , length =  1000 ) ) ]   objectSub -   object [  idx , ]   objectSub -   estimateDispersionsGeneEst (  objectSub , quiet =  TRUE )   objectSub -   estimateDispersionsFit (  objectSub ,  fitType , quiet =  TRUE ) # fill in the fitted dispersions for all genes     mcols (  object ) $ dispFit -    dispersionFunction (  objectSub ) (    mcols (  object ) $ baseMean ) } }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }  if (  !   missing (  B ) )  {  if (    length (  B ) !=   nrow (  object ) )  {   stop (  \"B should be as long as the number of rows of object\" ) }  if (  !   all (    B =  0 undefined   B =  1 ) )  {   stop (  \"B should be defined between 0 and 1\" ) } }  if (  fast )  {   rld -   rlogDataFast (  object ,  intercept ,  betaPriorVar ,  B ) } else  {   rld -   rlogData (  object ,  intercept ,  betaPriorVar ) }  if (  matrixIn )  {   return (  rld ) }   se -   SummarizedExperiment ( assays =  rld , colData =   colData (  object ) , rowRanges =   rowRanges (  object ) , exptData =   exptData (  object ) )   dt -   DESeqTransform (  se )    attr (  dt ,  \"betaPriorVar\" ) -   attr (  rld ,  \"betaPriorVar\" )  if (  !   is.null (   attr (  rld ,  \"intercept\" ) ) )  {     mcols (  dt ) $ rlogIntercept -   attr (  rld ,  \"intercept\" ) }  if (  !   is.null (   attr (  rld ,  \"B\" ) ) )  {    attr (  dt ,  \"B\" ) -   attr (  rld ,  \"B\" ) }  dt } ",
    "filename": "rlogTransformation.txt"
  },
  "new_function": {
    "name": "rlog",
    "representation": "rlog",
    "parameters": "function ( object , blind = TRUE , intercept , betaPriorVar , fitType = \"parametric\" )",
    "body": "{  if (   is.null (   colnames (  object ) ) )  {    colnames (  object ) -   seq_len (   ncol (  object ) ) }  if (   is.matrix (  object ) )  {   matrixIn -  TRUE   object -   DESeqDataSetFromMatrix (  object ,   DataFrame ( row.names =   colnames (  object ) ) ,  ~  1 ) } else  {   matrixIn -  FALSE }  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   object -   estimateSizeFactors (  object ) }  if (  blind )  {    design (  object ) -  ~  1 } # sparsity test  if (   missing (  intercept ) )  {   sparseTest (   counts (  object , normalized =  TRUE ) ,  .9 ,  100 ,  .1 ) }  if (   blind |   is.null (    mcols (  object ) $ dispFit ) )  { # estimate the dispersions on all genes  if (   is.null (    mcols (  object ) $ baseMean ) )  {   object -   getBaseMeansAndVariances (  object ) }   object -   estimateDispersionsGeneEst (  object , quiet =  TRUE )   object -   estimateDispersionsFit (  object ,  fitType , quiet =  TRUE ) }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }   rld -   rlogData (  object ,  intercept ,  betaPriorVar )  if (  matrixIn )  {   return (  rld ) }   se -   SummarizedExperiment ( assays =  rld , colData =   colData (  object ) , rowRanges =   rowRanges (  object ) , metadata =   metadata (  object ) )   dt -   DESeqTransform (  se )    attr (  dt ,  \"betaPriorVar\" ) -   attr (  rld ,  \"betaPriorVar\" )  if (  !   is.null (   attr (  rld ,  \"intercept\" ) ) )  {     mcols (  dt ) $ rlogIntercept -   attr (  rld ,  \"intercept\" ) }  dt } ",
    "filename": "rlog.txt"
  }
}



##########
Added Non Default Parameters
##########

0.
{
  "old_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , modelMatrix = NULL , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 )  if (   !   is.null (  modelMatrix ) undefined  betaPrior )  {   stop (  \"the model matrix can only be user-supplied if betaPrior=FALSE\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (   is.null (  modelMatrix ) )  {   modelAsFormula -  TRUE # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )   blindDesign -    design (  object ) ==   formula (  ~  1 )  if (    missing (  modelMatrixType ) ||   is.null (  modelMatrixType ) )  {   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (     modelMatrixType ==  \"standard\" undefined  betaPrior undefined  !  blindDesign )  {   message (  \"-- standard model matrices are used for factors with two levels and an interaction,\r\n   where the main effects are for the reference level of other factors.\r\n   see the 'Interactions' section of the vignette for more details: vignette('DESeq2')\" ) }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {   message (  \"using supplied model matrix\" )   modelAsFormula -  FALSE    attr (  object ,  \"modelMatrixType\" ) -  \"user-supplied\"   renameCols -  FALSE }  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , renameCols =  renameCols , modelMatrix =  modelMatrix )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } else  {   priorFitList -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix   mleBetaMatrix -   priorFitList $ mleBetaMatrix # will add the MLE betas, so remove any which exist already # (possibly coming from estimateMLEForBetaPriorVar)    mcols (  object ) -    mcols (  object ) [ ,   grep (  \"MLE_\" ,   names (   mcols (  object ) ) , invert =  TRUE ) ] } # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fit $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"test\" ) -  \"Wald\" # calculate Cook's distance   dispModelMatrix -  if (  modelAsFormula )  {   model.matrix (   design (  object ) , data =   colData (  object ) ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,  mleBetas ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior , betaPriorVar , modelMatrix = NULL , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (   is.null (  modelMatrix ) )  {   modelAsFormula -  TRUE   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  betaPrior ) )  {   betaPrior -  !  interactionPresent } # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   blindDesign -    design (  object ) ==   formula (  ~  1 )  if (  blindDesign )  {   betaPrior -  FALSE }  if (    missing (  modelMatrixType ) ||   is.null (  modelMatrixType ) )  {   modelMatrixType -  if (  betaPrior )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } else  {  if (  betaPrior )   stop (  \"the model matrix can only be user-supplied if betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   modelAsFormula -  FALSE    attr (  object ,  \"modelMatrixType\" ) -  \"user-supplied\"   renameCols -  FALSE }  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , renameCols =  renameCols , modelMatrix =  modelMatrix )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } else  {   priorFitList -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix   mleBetaMatrix -   priorFitList $ mleBetaMatrix # will add the MLE betas, so remove any which exist already # (possibly coming from estimateMLEForBetaPriorVar)    mcols (  object ) -    mcols (  object ) [ ,   grep (  \"MLE_\" ,   names (   mcols (  object ) ) , invert =  TRUE ) ] } # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fit $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"test\" ) -  \"Wald\" # calculate Cook's distance   dispModelMatrix -  if (  modelAsFormula )  {   model.matrix (   design (  object ) , data =   colData (  object ) ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,  mleBetas ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" , format = c ( \"DataFrame\" , \"GRanges\" , \"GRangesList\" ) , test , addMLE = FALSE , tidy = FALSE , parallel = FALSE , BPPARAM = bpparam ( ) )",
    "body": "{ # match args   format -   match.arg (  format , choices =   c (  \"DataFrame\" ,  \"GRanges\" ,  \"GRangesList\" ) )   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) ) # initial argument testing   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call DESeq, nbinomWaldTest, or nbinomLRT\" ) }  if (   missing (  test ) )  {   test -   attr (  object ,  \"test\" ) } else  if (    test ==  \"Wald\" undefined    attr (  object ,  \"test\" ) ==  \"LRT\" )  { # initially test was LRT, now need to add Wald statistics and p-values   object -   makeWaldTest (  object ) } else  if (    test ==  \"LRT\" undefined    attr (  object ,  \"test\" ) ==  \"Wald\" )  {   stop (  \"the LRT requires the user run nbinomLRT or DESeq(dds,test='LRT')\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) }  if (   addMLE undefined  !   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"addMLE=TRUE is only for when a beta prior was used. otherwise, the log2 fold changes are already MLE\" ) }  if (    format ==  \"GRanges\" undefined   is (   rowRanges (  object ) ,  \"GRangesList\" ) )  {  if (   any (    elementLengths (   rowRanges (  object ) ) ==  0 ) )  {   stop (  \"rowRanges is GRangesList and one or more GRanges have length 0. Use format='DataFrame' or 'GRangesList'\" ) } }  if (  !   missing (  contrast ) )  {  if (     attr (  object ,  \"modelMatrixType\" ) ==  \"user-supplied\" undefined   is.character (  contrast ) )  {   stop (  \"only list- and numeric-type contrasts are supported for user-supplied model matrices\" ) } }   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # if neither 'contrast' nor 'name' were specified, create the default result table: # the last level / first level for the last variable in design. # (unless there are interactions, in which case the lastCoefName is pulled below)  if (      (   test ==  \"Wald\" ) undefined  (   isExpanded |  !  hasIntercept ) undefined   missing (  contrast ) undefined   missing (  name ) undefined   all (   termsOrder undefined  2 ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) } else  {  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } } # check to see at least one of these are present   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) )  if (  !  (   WaldResults |  LRTResults ) )  {   stop (  \"cannot find appropriate results in the DESeqDataSet.\r\npossibly nbinomWaldTest or nbinomLRT has not yet been run.\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {   resNames -   resultsNames (  object ) # do some arg checking/cleaning   contrast -   checkContrast (  contrast ,  resNames ) ### cleanContrast call ### # need to go back to C++ code in order to build the beta covariance matrix # then this is multiplied by the numeric contrast to get the Wald statistic. # with 100s of samples, this can get slow, so offer parallelization   res -  if (  !  parallel )  {   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } else  if (  parallel )  {   nworkers -   BPPARAM $ workers   idx -   factor (   sort (   rep (   seq_len (  nworkers ) , length =   nrow (  object ) ) ) )   do.call (  rbind ,   bplapply (   levels (  idx ) ,  function ( l )  {   cleanContrast (   object [   idx ==  l , , drop =  FALSE ] ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } , BPPARAM =  BPPARAM ) ) } } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # add unshrunken MLE coefficients to the results table  if (  addMLE )  {  if (  !   missing (  contrast ) )  {  if (   is.numeric (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )  if (   is.list (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )   res -   cbind (  res ,   mleContrast (  object ,  contrast ) ) } else  {   mleName -   paste0 (  \"MLE_\" ,  name )   mleNames -    names (   mcols (  object ) ) [   grep (  \"MLE_\" ,   names (   mcols (  object ) ) ) ]  if (  !   mleName %in%  mleNames )   stop (  \"MLE_ plus 'name' was not found as a column in mcols(dds)\" )   mleColumn -    mcols (  object ) [  mleName ]    names (  mleColumn ) -  \"lfcMLE\"     mcols (  mleColumn ) $ description -   paste (  \"log2 fold change (MLE):\" ,  name )   res -   cbind (  res ,  mleColumn ) }   res -   res [ ,   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcMLE\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) ] # if an all zero contrast, also zero out the lfcMLE     res $ lfcMLE [   which (     res $ log2FoldChange ==  0 undefined    res $ stat ==  0 ) ] -  0 } # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   warning (  \"tests of log fold change above or below a theshold are Wald tests.\r\nLikelihood ratio test p-values are overwritten\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newStat -     sign (   res $ log2FoldChange ) *   pmax (  0 ,  (    abs (   res $ log2FoldChange ) -  lfcThreshold ) ) /   res $ lfcSE   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   newStatAbove -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   newStatBelow -    pmax (  0 ,    res $ log2FoldChange +  lfcThreshold ) /   res $ lfcSE   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newStat -   pmin (  newStatAbove ,  newStatBelow )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newStat -    pmax (  0 ,    res $ log2FoldChange -  lfcThreshold ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newStat -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ stat -  newStat    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"dispModelMatrix\" ) )   p -   ncol (   attr (  object ,  \"dispModelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero due to replaced counts, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0  if (  addMLE )  {     res $ lfcMLE [  nowZero ] -  0 }     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # p-value adjustment   paRes -   pvalueAdjustment (  res ,  independentFiltering ,  filter ,  theta ,  alpha ,  pAdjustMethod )    res $ padj -   paRes $ padj # adding metadata columns for padj      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" ) # make results object   deseqRes -   DESeqResults (  res ) # finalize object / add attributes / make GRanges  if (  independentFiltering )  {    attr (  deseqRes ,  \"filterThreshold\" ) -   paRes $ filterThreshold    attr (  deseqRes ,  \"filterNumRej\" ) -   paRes $ filterNumRej } # remove rownames and attach as a new column, 'row'  if (  tidy )  {   colnms -   colnames (  deseqRes )    deseqRes $ row -   rownames (  deseqRes )     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"type\" ] -  \"results\"     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"description\" ] -  \"row names\"   deseqRes -   deseqRes [ ,   c (  \"row\" ,  colnms ) ]    rownames (  deseqRes ) -  NULL   deseqRes -   as.data.frame (  deseqRes ) }  if (   format ==  \"DataFrame\" )  {   return (  deseqRes ) } else  if (   format ==  \"GRangesList\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRanges\" )   message (  \"rowRanges is GRanges\" )   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } else  if (   format ==  \"GRanges\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRangesList\" )  {   message (  \"rowRanges is GRangesList, unlisting the ranges\" )   out -   unlist (   range (   rowRanges (  object ) ) )    mcols (  out ) -  deseqRes   return (  out ) } else  {   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } } } ",
    "filename": "results.txt"
  },
  "new_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" , filterFun , format = c ( \"DataFrame\" , \"GRanges\" , \"GRangesList\" ) , test , addMLE = FALSE , tidy = FALSE , parallel = FALSE , BPPARAM = bpparam ( ) )",
    "body": "{ # match args   format -   match.arg (  format , choices =   c (  \"DataFrame\" ,  \"GRanges\" ,  \"GRangesList\" ) )   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) )  if (  !   missing (  test ) )  {   test -   match.arg (  test , choices =   c (  \"Wald\" ,  \"LRT\" ) ) } # initial argument testing   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"couldn't find results. you should first run DESeq()\" ) }  if (   missing (  test ) )  {   test -   attr (  object ,  \"test\" ) } else  if (    test ==  \"Wald\" undefined    attr (  object ,  \"test\" ) ==  \"LRT\" )  { # initially test was LRT, now need to add Wald statistics and p-values   object -   makeWaldTest (  object ) } else  if (    test ==  \"LRT\" undefined    attr (  object ,  \"test\" ) ==  \"Wald\" )  {   stop (  \"the LRT requires the user run nbinomLRT or DESeq(dds,test='LRT')\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) }  if (  addMLE )  {  if (  !   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"addMLE=TRUE is only for when a beta prior was used.\r\notherwise, the log2 fold changes are already MLE\" ) }  if (   !   missing (  name ) undefined   missing (  contrast ) )  {   stop (  \"addMLE=TRUE should be used by providing character vector\r\nof length 3 to 'contrast' instead of using 'name'\" ) } }  if (    format ==  \"GRanges\" undefined   is (   rowRanges (  object ) ,  \"GRangesList\" ) )  {  if (   any (    elementLengths (   rowRanges (  object ) ) ==  0 ) )  {   stop (  \"rowRanges is GRangesList and one or more GRanges have length 0. Use format='DataFrame' or 'GRangesList'\" ) } }  if (  !   missing (  contrast ) )  {  if (     attr (  object ,  \"modelMatrixType\" ) ==  \"user-supplied\" undefined   is.character (  contrast ) )  {   stop (  \"only list- and numeric-type contrasts are supported for user-supplied model matrices\" ) } }   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # if neither 'contrast' nor 'name' were specified, create the default result table: # the last level / first level for the last variable in design. # (unless there are interactions, in which case the lastCoefName is pulled below)  if (      (   test ==  \"Wald\" ) undefined  (   isExpanded |  !  hasIntercept ) undefined   missing (  contrast ) undefined   missing (  name ) undefined   all (   termsOrder undefined  2 ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) } else  {  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } }   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) ) # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {   resNames -   resultsNames (  object ) # do some arg checking/cleaning   contrast -   checkContrast (  contrast ,  resNames ) ### cleanContrast call ### # need to go back to C++ code in order to build the beta covariance matrix # then this is multiplied by the numeric contrast to get the Wald statistic. # with 100s of samples, this can get slow, so offer parallelization   res -  if (  !  parallel )  {   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } else  if (  parallel )  {   nworkers -   BPPARAM $ workers   idx -   factor (   sort (   rep (   seq_len (  nworkers ) , length =   nrow (  object ) ) ) )   do.call (  rbind ,   bplapply (   levels (  idx ) ,  function ( l )  {   cleanContrast (   object [   idx ==  l , , drop =  FALSE ] ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } , BPPARAM =  BPPARAM ) ) } } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # add unshrunken MLE coefficients to the results table  if (  addMLE )  {  if (   is.numeric (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )  if (   is.list (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )   res -   cbind (  res ,   mleContrast (  object ,  contrast ) )   res -   res [ ,   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcMLE\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) ] # if an all zero contrast, also zero out the lfcMLE     res $ lfcMLE [   which (     res $ log2FoldChange ==  0 undefined    res $ stat ==  0 ) ] -  0 } # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   stop (  \"tests of log fold change above or below a theshold must be Wald tests.\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newStat -     sign (   res $ log2FoldChange ) *   pmax (  0 ,  (    abs (   res $ log2FoldChange ) -  lfcThreshold ) ) /   res $ lfcSE   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   newStatAbove -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   newStatBelow -    pmax (  0 ,    res $ log2FoldChange +  lfcThreshold ) /   res $ lfcSE   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newStat -   pmin (  newStatAbove ,  newStatBelow )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newStat -    pmax (  0 ,    res $ log2FoldChange -  lfcThreshold ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newStat -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ stat -  newStat    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"dispModelMatrix\" ) )   p -   ncol (   attr (  object ,  \"dispModelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero due to replaced counts, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0  if (  addMLE )  {     res $ lfcMLE [  nowZero ] -  0 }     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # p-value adjustment   paRes -   pvalueAdjustment (  res ,  independentFiltering ,  filter ,  theta ,  alpha ,  pAdjustMethod ,  filterFun )    res $ padj -   paRes $ padj # adding metadata columns for padj      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" ) # make results object   deseqRes -   DESeqResults (  res ) # finalize object / add attributes / make GRanges  if (  independentFiltering )  {    metadata (  deseqRes ) -   list ( filterThreshold =   paRes $ filterThreshold , filterTheta =   paRes $ filterTheta , filterNumRej =   paRes $ filterNumRej , lo.fit =   paRes $ lo.fit , alpha =  alpha ) } # remove rownames and attach as a new column, 'row'  if (  tidy )  {   colnms -   colnames (  deseqRes )    deseqRes $ row -   rownames (  deseqRes )     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"type\" ] -  \"results\"     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"description\" ] -  \"row names\"   deseqRes -   deseqRes [ ,   c (  \"row\" ,  colnms ) ]    rownames (  deseqRes ) -  NULL   deseqRes -   as.data.frame (  deseqRes ) }  if (   format ==  \"DataFrame\" )  {   return (  deseqRes ) } else  if (   format ==  \"GRangesList\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRanges\" )   warning (  \"rowRanges is GRanges\" )   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } else  if (   format ==  \"GRanges\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRangesList\" )  {   warning (  \"rowRanges is GRangesList, performing unlist(range(x)) on the rowRanges\" )   out -   unlist (   range (   rowRanges (  object ) ) )    mcols (  out ) -  deseqRes   return (  out ) } else  {   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } } } ",
    "filename": "results.txt"
  }
}



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = TRUE , betaPriorVar , modelMatrix = NULL , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 )  if (   !   is.null (  modelMatrix ) undefined  betaPrior )  {   stop (  \"the model matrix can only be user-supplied if betaPrior=FALSE\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (   is.null (  modelMatrix ) )  {   modelAsFormula -  TRUE # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )   blindDesign -    design (  object ) ==   formula (  ~  1 )  if (    missing (  modelMatrixType ) ||   is.null (  modelMatrixType ) )  {   twoLevelsInteraction -   !   factorPresentThreeOrMoreLevels (  object ) undefined  interactionPresent   mmTypeTest -    betaPrior undefined  !  blindDesign undefined  !  twoLevelsInteraction   modelMatrixType -  if (  mmTypeTest )  {  \"expanded\" } else  {  \"standard\" } }  if (     modelMatrixType ==  \"standard\" undefined  betaPrior undefined  !  blindDesign )  {   message (  \"-- standard model matrices are used for factors with two levels and an interaction,\r\n   where the main effects are for the reference level of other factors.\r\n   see the 'Interactions' section of the vignette for more details: vignette('DESeq2')\" ) }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {   message (  \"using supplied model matrix\" )   modelAsFormula -  FALSE    attr (  object ,  \"modelMatrixType\" ) -  \"user-supplied\"   renameCols -  FALSE }  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , renameCols =  renameCols , modelMatrix =  modelMatrix )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } else  {   priorFitList -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix   mleBetaMatrix -   priorFitList $ mleBetaMatrix # will add the MLE betas, so remove any which exist already # (possibly coming from estimateMLEForBetaPriorVar)    mcols (  object ) -    mcols (  object ) [ ,   grep (  \"MLE_\" ,   names (   mcols (  object ) ) , invert =  TRUE ) ] } # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fit $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"test\" ) -  \"Wald\" # calculate Cook's distance   dispModelMatrix -  if (  modelAsFormula )  {   model.matrix (   design (  object ) , data =   colData (  object ) ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,  mleBetas ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior , betaPriorVar , modelMatrix = NULL , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (   is.null (  modelMatrix ) )  {   modelAsFormula -  TRUE   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  betaPrior ) )  {   betaPrior -  !  interactionPresent } # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   blindDesign -    design (  object ) ==   formula (  ~  1 )  if (  blindDesign )  {   betaPrior -  FALSE }  if (    missing (  modelMatrixType ) ||   is.null (  modelMatrixType ) )  {   modelMatrixType -  if (  betaPrior )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } else  {  if (  betaPrior )   stop (  \"the model matrix can only be user-supplied if betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   modelAsFormula -  FALSE    attr (  object ,  \"modelMatrixType\" ) -  \"user-supplied\"   renameCols -  FALSE }  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , renameCols =  renameCols , modelMatrix =  modelMatrix )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } else  {   priorFitList -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix   mleBetaMatrix -   priorFitList $ mleBetaMatrix # will add the MLE betas, so remove any which exist already # (possibly coming from estimateMLEForBetaPriorVar)    mcols (  object ) -    mcols (  object ) [ ,   grep (  \"MLE_\" ,   names (   mcols (  object ) ) , invert =  TRUE ) ] } # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fit $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"test\" ) -  \"Wald\" # calculate Cook's distance   dispModelMatrix -  if (  modelAsFormula )  {   model.matrix (   design (  object ) , data =   colData (  object ) ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,  mleBetas ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , modelMatrixType = \"standard\" , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowData (  object ) # run check on the formula   modelAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   colData (  object ) )   reducedModelMatrix -   model.matrix (  reduced , data =   colData (  object ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {  if (  betaPrior )  {   stop (  \"user-supplied model matrices require betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (  modelAsFormula )  {  if (   is.null (  modelMatrixType ) )  {   modelMatrixType -  \"standard\" } # check for intercept   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } } else  {   modelMatrixType -  \"user-supplied\"   renameCols -  FALSE } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (  !  betaPrior )  {  if (  modelAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , renameCols =  renameCols , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar   mleBetaMatrix -   priorFull $ mleBetaMatrix # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"test\" ) -  \"LRT\" # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fullModel $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero )   H -   fullModel $ hat_diagonals # calculate Cook's distance   dispModelMatrix -  if (   modelMatrixType ==  \"expanded\" )  {   model.matrix (   design (  object ) , data =   colData (  object ) ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE )   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL } # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,  mleBetas ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"provide a reduced formula for the LRT, e.g. nbinomLRT(object, reduced= ~1)\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object ) # run check on the formula   modelAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   model.matrix (  full , data =   colData (  object ) )   reducedModelMatrix -   model.matrix (  reduced , data =   colData (  object ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {  if (  betaPrior )  {   stop (  \"user-supplied model matrices require betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) }   stopifnot (   is.logical (  betaPrior ) )  if (  modelAsFormula )  {   modelMatrixType -  \"standard\" # check for intercept   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {   modelMatrixType -  \"user-supplied\"   renameCols -  FALSE } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (  !  betaPrior )  {  if (  modelAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , renameCols =  renameCols , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar   mleBetaMatrix -   priorFull $ mleBetaMatrix # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"test\" ) -  \"LRT\" # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fullModel $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero )   H -   fullModel $ hat_diagonals # calculate Cook's distance   dispModelMatrix -  modelMatrix    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE )   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL } # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,  mleBetas ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

2.
{
  "old_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" , format = c ( \"DataFrame\" , \"GRanges\" , \"GRangesList\" ) , test , addMLE = FALSE , tidy = FALSE , parallel = FALSE , BPPARAM = bpparam ( ) )",
    "body": "{ # match args   format -   match.arg (  format , choices =   c (  \"DataFrame\" ,  \"GRanges\" ,  \"GRangesList\" ) )   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) ) # initial argument testing   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"cannot find results columns in object, first call DESeq, nbinomWaldTest, or nbinomLRT\" ) }  if (   missing (  test ) )  {   test -   attr (  object ,  \"test\" ) } else  if (    test ==  \"Wald\" undefined    attr (  object ,  \"test\" ) ==  \"LRT\" )  { # initially test was LRT, now need to add Wald statistics and p-values   object -   makeWaldTest (  object ) } else  if (    test ==  \"LRT\" undefined    attr (  object ,  \"test\" ) ==  \"Wald\" )  {   stop (  \"the LRT requires the user run nbinomLRT or DESeq(dds,test='LRT')\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) }  if (   addMLE undefined  !   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"addMLE=TRUE is only for when a beta prior was used. otherwise, the log2 fold changes are already MLE\" ) }  if (    format ==  \"GRanges\" undefined   is (   rowRanges (  object ) ,  \"GRangesList\" ) )  {  if (   any (    elementLengths (   rowRanges (  object ) ) ==  0 ) )  {   stop (  \"rowRanges is GRangesList and one or more GRanges have length 0. Use format='DataFrame' or 'GRangesList'\" ) } }  if (  !   missing (  contrast ) )  {  if (     attr (  object ,  \"modelMatrixType\" ) ==  \"user-supplied\" undefined   is.character (  contrast ) )  {   stop (  \"only list- and numeric-type contrasts are supported for user-supplied model matrices\" ) } }   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # if neither 'contrast' nor 'name' were specified, create the default result table: # the last level / first level for the last variable in design. # (unless there are interactions, in which case the lastCoefName is pulled below)  if (      (   test ==  \"Wald\" ) undefined  (   isExpanded |  !  hasIntercept ) undefined   missing (  contrast ) undefined   missing (  name ) undefined   all (   termsOrder undefined  2 ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) } else  {  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } } # check to see at least one of these are present   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) )  if (  !  (   WaldResults |  LRTResults ) )  {   stop (  \"cannot find appropriate results in the DESeqDataSet.\r\npossibly nbinomWaldTest or nbinomLRT has not yet been run.\" ) } # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {   resNames -   resultsNames (  object ) # do some arg checking/cleaning   contrast -   checkContrast (  contrast ,  resNames ) ### cleanContrast call ### # need to go back to C++ code in order to build the beta covariance matrix # then this is multiplied by the numeric contrast to get the Wald statistic. # with 100s of samples, this can get slow, so offer parallelization   res -  if (  !  parallel )  {   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } else  if (  parallel )  {   nworkers -   BPPARAM $ workers   idx -   factor (   sort (   rep (   seq_len (  nworkers ) , length =   nrow (  object ) ) ) )   do.call (  rbind ,   bplapply (   levels (  idx ) ,  function ( l )  {   cleanContrast (   object [   idx ==  l , , drop =  FALSE ] ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } , BPPARAM =  BPPARAM ) ) } } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # add unshrunken MLE coefficients to the results table  if (  addMLE )  {  if (  !   missing (  contrast ) )  {  if (   is.numeric (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )  if (   is.list (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )   res -   cbind (  res ,   mleContrast (  object ,  contrast ) ) } else  {   mleName -   paste0 (  \"MLE_\" ,  name )   mleNames -    names (   mcols (  object ) ) [   grep (  \"MLE_\" ,   names (   mcols (  object ) ) ) ]  if (  !   mleName %in%  mleNames )   stop (  \"MLE_ plus 'name' was not found as a column in mcols(dds)\" )   mleColumn -    mcols (  object ) [  mleName ]    names (  mleColumn ) -  \"lfcMLE\"     mcols (  mleColumn ) $ description -   paste (  \"log2 fold change (MLE):\" ,  name )   res -   cbind (  res ,  mleColumn ) }   res -   res [ ,   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcMLE\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) ] # if an all zero contrast, also zero out the lfcMLE     res $ lfcMLE [   which (     res $ log2FoldChange ==  0 undefined    res $ stat ==  0 ) ] -  0 } # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   warning (  \"tests of log fold change above or below a theshold are Wald tests.\r\nLikelihood ratio test p-values are overwritten\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newStat -     sign (   res $ log2FoldChange ) *   pmax (  0 ,  (    abs (   res $ log2FoldChange ) -  lfcThreshold ) ) /   res $ lfcSE   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   newStatAbove -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   newStatBelow -    pmax (  0 ,    res $ log2FoldChange +  lfcThreshold ) /   res $ lfcSE   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newStat -   pmin (  newStatAbove ,  newStatBelow )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newStat -    pmax (  0 ,    res $ log2FoldChange -  lfcThreshold ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newStat -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ stat -  newStat    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"dispModelMatrix\" ) )   p -   ncol (   attr (  object ,  \"dispModelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero due to replaced counts, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0  if (  addMLE )  {     res $ lfcMLE [  nowZero ] -  0 }     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # p-value adjustment   paRes -   pvalueAdjustment (  res ,  independentFiltering ,  filter ,  theta ,  alpha ,  pAdjustMethod )    res $ padj -   paRes $ padj # adding metadata columns for padj      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" ) # make results object   deseqRes -   DESeqResults (  res ) # finalize object / add attributes / make GRanges  if (  independentFiltering )  {    attr (  deseqRes ,  \"filterThreshold\" ) -   paRes $ filterThreshold    attr (  deseqRes ,  \"filterNumRej\" ) -   paRes $ filterNumRej } # remove rownames and attach as a new column, 'row'  if (  tidy )  {   colnms -   colnames (  deseqRes )    deseqRes $ row -   rownames (  deseqRes )     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"type\" ] -  \"results\"     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"description\" ] -  \"row names\"   deseqRes -   deseqRes [ ,   c (  \"row\" ,  colnms ) ]    rownames (  deseqRes ) -  NULL   deseqRes -   as.data.frame (  deseqRes ) }  if (   format ==  \"DataFrame\" )  {   return (  deseqRes ) } else  if (   format ==  \"GRangesList\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRanges\" )   message (  \"rowRanges is GRanges\" )   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } else  if (   format ==  \"GRanges\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRangesList\" )  {   message (  \"rowRanges is GRangesList, unlisting the ranges\" )   out -   unlist (   range (   rowRanges (  object ) ) )    mcols (  out ) -  deseqRes   return (  out ) } else  {   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } } } ",
    "filename": "results.txt"
  },
  "new_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" , filterFun , format = c ( \"DataFrame\" , \"GRanges\" , \"GRangesList\" ) , test , addMLE = FALSE , tidy = FALSE , parallel = FALSE , BPPARAM = bpparam ( ) )",
    "body": "{ # match args   format -   match.arg (  format , choices =   c (  \"DataFrame\" ,  \"GRanges\" ,  \"GRangesList\" ) )   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) )  if (  !   missing (  test ) )  {   test -   match.arg (  test , choices =   c (  \"Wald\" ,  \"LRT\" ) ) } # initial argument testing   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"couldn't find results. you should first run DESeq()\" ) }  if (   missing (  test ) )  {   test -   attr (  object ,  \"test\" ) } else  if (    test ==  \"Wald\" undefined    attr (  object ,  \"test\" ) ==  \"LRT\" )  { # initially test was LRT, now need to add Wald statistics and p-values   object -   makeWaldTest (  object ) } else  if (    test ==  \"LRT\" undefined    attr (  object ,  \"test\" ) ==  \"Wald\" )  {   stop (  \"the LRT requires the user run nbinomLRT or DESeq(dds,test='LRT')\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) }  if (  addMLE )  {  if (  !   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"addMLE=TRUE is only for when a beta prior was used.\r\notherwise, the log2 fold changes are already MLE\" ) }  if (   !   missing (  name ) undefined   missing (  contrast ) )  {   stop (  \"addMLE=TRUE should be used by providing character vector\r\nof length 3 to 'contrast' instead of using 'name'\" ) } }  if (    format ==  \"GRanges\" undefined   is (   rowRanges (  object ) ,  \"GRangesList\" ) )  {  if (   any (    elementLengths (   rowRanges (  object ) ) ==  0 ) )  {   stop (  \"rowRanges is GRangesList and one or more GRanges have length 0. Use format='DataFrame' or 'GRangesList'\" ) } }  if (  !   missing (  contrast ) )  {  if (     attr (  object ,  \"modelMatrixType\" ) ==  \"user-supplied\" undefined   is.character (  contrast ) )  {   stop (  \"only list- and numeric-type contrasts are supported for user-supplied model matrices\" ) } }   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # if neither 'contrast' nor 'name' were specified, create the default result table: # the last level / first level for the last variable in design. # (unless there are interactions, in which case the lastCoefName is pulled below)  if (      (   test ==  \"Wald\" ) undefined  (   isExpanded |  !  hasIntercept ) undefined   missing (  contrast ) undefined   missing (  name ) undefined   all (   termsOrder undefined  2 ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) } else  {  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } }   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) ) # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {   resNames -   resultsNames (  object ) # do some arg checking/cleaning   contrast -   checkContrast (  contrast ,  resNames ) ### cleanContrast call ### # need to go back to C++ code in order to build the beta covariance matrix # then this is multiplied by the numeric contrast to get the Wald statistic. # with 100s of samples, this can get slow, so offer parallelization   res -  if (  !  parallel )  {   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } else  if (  parallel )  {   nworkers -   BPPARAM $ workers   idx -   factor (   sort (   rep (   seq_len (  nworkers ) , length =   nrow (  object ) ) ) )   do.call (  rbind ,   bplapply (   levels (  idx ) ,  function ( l )  {   cleanContrast (   object [   idx ==  l , , drop =  FALSE ] ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test ) } , BPPARAM =  BPPARAM ) ) } } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # add unshrunken MLE coefficients to the results table  if (  addMLE )  {  if (   is.numeric (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )  if (   is.list (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )   res -   cbind (  res ,   mleContrast (  object ,  contrast ) )   res -   res [ ,   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcMLE\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) ] # if an all zero contrast, also zero out the lfcMLE     res $ lfcMLE [   which (     res $ log2FoldChange ==  0 undefined    res $ stat ==  0 ) ] -  0 } # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   stop (  \"tests of log fold change above or below a theshold must be Wald tests.\" ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newStat -     sign (   res $ log2FoldChange ) *   pmax (  0 ,  (    abs (   res $ log2FoldChange ) -  lfcThreshold ) ) /   res $ lfcSE   newPvalue -   pmin (  1 ,   2 *   pnorm (   abs (   res $ log2FoldChange ) , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  { # check requirement if betaPrior was set to FALSE  if (   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) }   newStatAbove -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   pvalueAbove -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE )   newStatBelow -    pmax (  0 ,    res $ log2FoldChange +  lfcThreshold ) /   res $ lfcSE   pvalueBelow -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE )   newStat -   pmin (  newStatAbove ,  newStatBelow )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newStat -    pmax (  0 ,    res $ log2FoldChange -  lfcThreshold ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  lfcThreshold , sd =   res $ lfcSE , lower.tail =  FALSE ) } else  if (   altHypothesis ==  \"less\" )  {   newStat -    pmax (  0 ,   lfcThreshold -   res $ log2FoldChange ) /   res $ lfcSE   newPvalue -   pnorm (   res $ log2FoldChange , mean =  -  lfcThreshold , sd =   res $ lfcSE , lower.tail =  TRUE ) }    res $ stat -  newStat    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"dispModelMatrix\" ) )   p -   ncol (   attr (  object ,  \"dispModelMatrix\" ) ) # only if more samples than parameters:  if (   m undefined  p )  {   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } } else  {   cooksCutoff -  FALSE } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (   (   m undefined  p ) undefined  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff     res $ pvalue [  cooksOutlier ] -  NA } # if original baseMean was positive, but now zero due to replaced counts, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0  if (  addMLE )  {     res $ lfcMLE [  nowZero ] -  0 }     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # p-value adjustment   paRes -   pvalueAdjustment (  res ,  independentFiltering ,  filter ,  theta ,  alpha ,  pAdjustMethod ,  filterFun )    res $ padj -   paRes $ padj # adding metadata columns for padj      mcols (  res ) $ type [    names (  res ) ==  \"padj\" ] -  \"results\"      mcols (  res ) $ description [    names (  res ) ==  \"padj\" ] -   paste (  pAdjustMethod ,  \"adjusted p-values\" ) # make results object   deseqRes -   DESeqResults (  res ) # finalize object / add attributes / make GRanges  if (  independentFiltering )  {    metadata (  deseqRes ) -   list ( filterThreshold =   paRes $ filterThreshold , filterTheta =   paRes $ filterTheta , filterNumRej =   paRes $ filterNumRej , lo.fit =   paRes $ lo.fit , alpha =  alpha ) } # remove rownames and attach as a new column, 'row'  if (  tidy )  {   colnms -   colnames (  deseqRes )    deseqRes $ row -   rownames (  deseqRes )     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"type\" ] -  \"results\"     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"description\" ] -  \"row names\"   deseqRes -   deseqRes [ ,   c (  \"row\" ,  colnms ) ]    rownames (  deseqRes ) -  NULL   deseqRes -   as.data.frame (  deseqRes ) }  if (   format ==  \"DataFrame\" )  {   return (  deseqRes ) } else  if (   format ==  \"GRangesList\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRanges\" )   warning (  \"rowRanges is GRanges\" )   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } else  if (   format ==  \"GRanges\" )  {  if (    class (   rowRanges (  object ) ) ==  \"GRangesList\" )  {   warning (  \"rowRanges is GRangesList, performing unlist(range(x)) on the rowRanges\" )   out -   unlist (   range (   rowRanges (  object ) ) )    mcols (  out ) -  deseqRes   return (  out ) } else  {   out -   rowRanges (  object )    mcols (  out ) -  deseqRes   return (  out ) } } } ",
    "filename": "results.txt"
  }
}

3.
{
  "old_function": {
    "name": "rlog",
    "representation": "rlog",
    "parameters": "function ( object , blind = TRUE , fast = FALSE , intercept , betaPriorVar , B , fitType = \"parametric\" )",
    "body": "{  if (   is.null (   colnames (  object ) ) )  {    colnames (  object ) -   seq_len (   ncol (  object ) ) }  if (   is.matrix (  object ) )  {   matrixIn -  TRUE   object -   DESeqDataSetFromMatrix (  object ,   DataFrame ( row.names =   colnames (  object ) ) ,  ~  1 ) } else  {   matrixIn -  FALSE }  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   object -   estimateSizeFactors (  object ) }  if (  blind )  {    design (  object ) -  ~  1 } # sparsity test  if (    missing (  intercept ) undefined   missing (  B ) )  {   sparseTest (   counts (  object , normalized =  TRUE ) ,  .9 ,  100 ,  .1 ) }  if (   blind |   is.null (    mcols (  object ) $ dispFit ) )  { # estimate the dispersions on all genes, or if fast=TRUE subset to 1000 non-zero genes  if (   is.null (    mcols (  object ) $ baseMean ) )  {   object -   getBaseMeansAndVariances (  object ) }  if (   !  fast |    sum (     mcols (  object ) $ baseMean undefined  0 ) =  1000 )  {   object -   estimateDispersionsGeneEst (  object , quiet =  TRUE )   object -   estimateDispersionsFit (  object ,  fitType , quiet =  TRUE ) } else  { # select 1000 genes along the range of non-zero base means   idx -    order (    mcols (  object ) $ baseMean ) [   round (   seq ( from =  (    sum (     mcols (  object ) $ baseMean ==  0 ) +  1 ) , to =   nrow (  object ) , length =  1000 ) ) ]   objectSub -   object [  idx , ]   objectSub -   estimateDispersionsGeneEst (  objectSub , quiet =  TRUE )   objectSub -   estimateDispersionsFit (  objectSub ,  fitType , quiet =  TRUE ) # fill in the fitted dispersions for all genes     mcols (  object ) $ dispFit -    dispersionFunction (  objectSub ) (    mcols (  object ) $ baseMean ) } }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }  if (  !   missing (  B ) )  {  if (    length (  B ) !=   nrow (  object ) )  {   stop (  \"B should be as long as the number of rows of object\" ) }  if (  !   all (    B =  0 undefined   B =  1 ) )  {   stop (  \"B should be defined between 0 and 1\" ) } }  if (  fast )  {   rld -   rlogDataFast (  object ,  intercept ,  betaPriorVar ,  B ) } else  {   rld -   rlogData (  object ,  intercept ,  betaPriorVar ) }  if (  matrixIn )  {   return (  rld ) }   se -   SummarizedExperiment ( assays =  rld , colData =   colData (  object ) , rowRanges =   rowRanges (  object ) , exptData =   exptData (  object ) )   dt -   DESeqTransform (  se )    attr (  dt ,  \"betaPriorVar\" ) -   attr (  rld ,  \"betaPriorVar\" )  if (  !   is.null (   attr (  rld ,  \"intercept\" ) ) )  {     mcols (  dt ) $ rlogIntercept -   attr (  rld ,  \"intercept\" ) }  if (  !   is.null (   attr (  rld ,  \"B\" ) ) )  {    attr (  dt ,  \"B\" ) -   attr (  rld ,  \"B\" ) }  dt } ",
    "filename": "rlogTransformation.txt"
  },
  "new_function": {
    "name": "rlog",
    "representation": "rlog",
    "parameters": "function ( object , blind = TRUE , intercept , betaPriorVar , fitType = \"parametric\" )",
    "body": "{  if (   is.null (   colnames (  object ) ) )  {    colnames (  object ) -   seq_len (   ncol (  object ) ) }  if (   is.matrix (  object ) )  {   matrixIn -  TRUE   object -   DESeqDataSetFromMatrix (  object ,   DataFrame ( row.names =   colnames (  object ) ) ,  ~  1 ) } else  {   matrixIn -  FALSE }  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   object -   estimateSizeFactors (  object ) }  if (  blind )  {    design (  object ) -  ~  1 } # sparsity test  if (   missing (  intercept ) )  {   sparseTest (   counts (  object , normalized =  TRUE ) ,  .9 ,  100 ,  .1 ) }  if (   blind |   is.null (    mcols (  object ) $ dispFit ) )  { # estimate the dispersions on all genes  if (   is.null (    mcols (  object ) $ baseMean ) )  {   object -   getBaseMeansAndVariances (  object ) }   object -   estimateDispersionsGeneEst (  object , quiet =  TRUE )   object -   estimateDispersionsFit (  object ,  fitType , quiet =  TRUE ) }  if (  !   missing (  intercept ) )  {  if (    length (  intercept ) !=   nrow (  object ) )  {   stop (  \"intercept should be as long as the number of rows of object\" ) } }   rld -   rlogData (  object ,  intercept ,  betaPriorVar )  if (  matrixIn )  {   return (  rld ) }   se -   SummarizedExperiment ( assays =  rld , colData =   colData (  object ) , rowRanges =   rowRanges (  object ) , metadata =   metadata (  object ) )   dt -   DESeqTransform (  se )    attr (  dt ,  \"betaPriorVar\" ) -   attr (  rld ,  \"betaPriorVar\" )  if (  !   is.null (   attr (  rld ,  \"intercept\" ) ) )  {     mcols (  dt ) $ rlogIntercept -   attr (  rld ,  \"intercept\" ) }  dt } ",
    "filename": "rlog.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_2 deseq2_release_3_3

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_2 deseq2_release_3_3",
    "desc_release_old": "1.10.1",
    "desc_release_new": "1.12.4",
    "old_release_number": 4,
    "new_release_number": 5,
    "function_removals": 0,
    "function_additions": 2,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 0,
    "total_count": 0
}

##########
Functions Removed
##########



##########
Functions Added
##########

DESeqDataSetFromTximport
vst


##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_3 deseq2_release_3_4

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_3 deseq2_release_3_4",
    "desc_release_old": "1.12.4",
    "desc_release_new": "1.14.1",
    "old_release_number": 5,
    "new_release_number": 6,
    "function_removals": 0,
    "function_additions": 0,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 0,
    "total_count": 0
}

##########
Functions Removed
##########



##########
Functions Added
##########



##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_4 deseq2_release_3_5

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_4 deseq2_release_3_5",
    "desc_release_old": "1.14.1",
    "desc_release_new": "1.16.1",
    "old_release_number": 6,
    "new_release_number": 7,
    "function_removals": 0,
    "function_additions": 2,
    "parameter_removals": 2,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 2,
    "total_count": 2
}

##########
Functions Removed
##########



##########
Functions Added
##########

lfcShrink
unmix


##########
Removed Non Default Parameters
##########

0.
{
  "old_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior , betaPriorVar , modelMatrix = NULL , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (   is.null (  modelMatrix ) )  {   modelAsFormula -  TRUE   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  betaPrior ) )  {   betaPrior -  !  interactionPresent } # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   blindDesign -    design (  object ) ==   formula (  ~  1 )  if (  blindDesign )  {   betaPrior -  FALSE }  if (    missing (  modelMatrixType ) ||   is.null (  modelMatrixType ) )  {   modelMatrixType -  if (  betaPrior )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } else  {  if (  betaPrior )   stop (  \"the model matrix can only be user-supplied if betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   modelAsFormula -  FALSE    attr (  object ,  \"modelMatrixType\" ) -  \"user-supplied\"   renameCols -  FALSE }  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , renameCols =  renameCols , modelMatrix =  modelMatrix )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } else  {   priorFitList -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix   mleBetaMatrix -   priorFitList $ mleBetaMatrix # will add the MLE betas, so remove any which exist already # (possibly coming from estimateMLEForBetaPriorVar)    mcols (  object ) -    mcols (  object ) [ ,   grep (  \"MLE_\" ,   names (   mcols (  object ) ) , invert =  TRUE ) ] } # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fit $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"test\" ) -  \"Wald\" # calculate Cook's distance   dispModelMatrix -  if (  modelAsFormula )  {   getModelMatrix (  object ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,  mleBetas ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = FALSE , betaPriorVar , modelMatrix = NULL , modelMatrixType , betaTol = 1e-8 , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ] # model matrix not provided...  if (   is.null (  modelMatrix ) )  {   modelAsFormula -  TRUE   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   blindDesign -    design (  object ) ==   formula (  ~  1 )  if (  blindDesign )  {   betaPrior -  FALSE }  if (    missing (  modelMatrixType ) ||   is.null (  modelMatrixType ) )  {   modelMatrixType -  if (  betaPrior )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  { # model matrix was provided...  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } else  {  if (  betaPrior )   stop (  \"the model matrix can only be user-supplied if betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   modelAsFormula -  FALSE    attr (  object ,  \"modelMatrixType\" ) -  \"user-supplied\"   renameCols -  FALSE }  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , renameCols =  renameCols , modelMatrix =  modelMatrix )   H -   fit $ hat_diagonals   mu -   fit $ mu   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } else  {   priorFitList -   fitGLMsWithPrior ( object =  object , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fit -   priorFitList $ fit   H -   priorFitList $ H   mu -   priorFitList $ mu   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix   mleBetaMatrix -   priorFitList $ mleBetaMatrix # will add the MLE betas, so remove any which exist already # (possibly coming from estimateMLEForBetaPriorVar)    mcols (  object ) -    mcols (  object ) [ ,   grep (  \"MLE_\" ,   names (   mcols (  object ) ) , invert =  TRUE ) ] } # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (  mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -  mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (  mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"test\" ) -  \"Wald\" # calculate Cook's distance   dispModelMatrix -  if (  modelAsFormula )  {   getModelMatrix (  object ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,  mleBetas ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"provide a reduced formula for the LRT, e.g. nbinomLRT(object, reduced= ~1)\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object ) # run check on the formula   modelAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   stats :: model.matrix.default (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   stats :: model.matrix.default (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {  if (  betaPrior )  {   stop (  \"user-supplied model matrices require betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) }   stopifnot (   is.logical (  betaPrior ) )  if (  modelAsFormula )  {   modelMatrixType -  \"standard\" # check for intercept   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {   modelMatrixType -  \"user-supplied\"   renameCols -  FALSE } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (  !  betaPrior )  {  if (  modelAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , renameCols =  renameCols , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar   mleBetaMatrix -   priorFull $ mleBetaMatrix # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"test\" ) -  \"LRT\" # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fullModel $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero )   H -   fullModel $ hat_diagonals # calculate Cook's distance   dispModelMatrix -  modelMatrix    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE )   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL } # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,  mleBetas ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaTol = 1e-8 , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"provide a reduced formula for the LRT, e.g. nbinomLRT(object, reduced= ~1)\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object ) # run check on the formula   modelAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object , betaPrior =  FALSE ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   stats :: model.matrix.default (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   stats :: model.matrix.default (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {   message (  \"using supplied model matrix\" )   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) }  if (  modelAsFormula )  {   modelMatrixType -  \"standard\" # check for intercept   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {   modelMatrixType -  \"user-supplied\"   renameCols -  FALSE } # store modelMatrixType    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (  modelAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , renameCols =  renameCols , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , renameCols =  FALSE , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , renameCols =  FALSE , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) )    attr (  object ,  \"betaPrior\" ) -  FALSE    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"test\" ) -  \"LRT\" # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fullModel $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero )   H -   fullModel $ hat_diagonals # calculate Cook's distance   dispModelMatrix -  modelMatrix    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # no need to store additional betas (no beta prior)   mleBetas -  NULL # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,  mleBetas ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  NULL   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior , betaPriorVar , modelMatrix = NULL , modelMatrixType , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (   is.null (  modelMatrix ) )  {   modelAsFormula -  TRUE   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  betaPrior ) )  {   betaPrior -  !  interactionPresent } # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   blindDesign -    design (  object ) ==   formula (  ~  1 )  if (  blindDesign )  {   betaPrior -  FALSE }  if (    missing (  modelMatrixType ) ||   is.null (  modelMatrixType ) )  {   modelMatrixType -  if (  betaPrior )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } else  {  if (  betaPrior )   stop (  \"the model matrix can only be user-supplied if betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   modelAsFormula -  FALSE    attr (  object ,  \"modelMatrixType\" ) -  \"user-supplied\"   renameCols -  FALSE }  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , renameCols =  renameCols , modelMatrix =  modelMatrix )   H -   fit $ hat_diagonals   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } else  {   priorFitList -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fit -   priorFitList $ fit   H -   priorFitList $ H   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix   mleBetaMatrix -   priorFitList $ mleBetaMatrix # will add the MLE betas, so remove any which exist already # (possibly coming from estimateMLEForBetaPriorVar)    mcols (  object ) -    mcols (  object ) [ ,   grep (  \"MLE_\" ,   names (   mcols (  object ) ) , invert =  TRUE ) ] } # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fit $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fit $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fit $ mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"test\" ) -  \"Wald\" # calculate Cook's distance   dispModelMatrix -  if (  modelAsFormula )  {   getModelMatrix (  object ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,  mleBetas ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomWaldTest",
    "representation": "nbinomWaldTest",
    "parameters": "function ( object , betaPrior = FALSE , betaPriorVar , modelMatrix = NULL , modelMatrixType , betaTol = 1e-8 , maxit = 100 , useOptim = TRUE , quiet = FALSE , useT = FALSE , df , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }   stopifnot (    length (  maxit ) ==  1 ) # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object )  if (   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) } # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ] # model matrix not provided...  if (   is.null (  modelMatrix ) )  {   modelAsFormula -  TRUE   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" )   interactionPresent -   any (   termsOrder undefined  1 )  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # what kind of model matrix to use   stopifnot (   is.logical (  betaPrior ) )   blindDesign -    design (  object ) ==   formula (  ~  1 )  if (  blindDesign )  {   betaPrior -  FALSE }  if (    missing (  modelMatrixType ) ||   is.null (  modelMatrixType ) )  {   modelMatrixType -  if (  betaPrior )  {  \"expanded\" } else  {  \"standard\" } }  if (    modelMatrixType ==  \"expanded\" undefined  !  betaPrior )  {   stop (  \"expanded model matrices require a beta prior\" ) } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  { # model matrix was provided...  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } else  {  if (  betaPrior )   stop (  \"the model matrix can only be user-supplied if betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   modelAsFormula -  FALSE    attr (  object ,  \"modelMatrixType\" ) -  \"user-supplied\"   renameCols -  FALSE }  if (  !  betaPrior )  { # fit the negative binomial GLM without a prior # (in actuality a very wide prior with standard deviation 1e3 on log2 fold changes)   fit -   fitNbinomGLMs (  objectNZ , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , renameCols =  renameCols , modelMatrix =  modelMatrix )   H -   fit $ hat_diagonals   mu -   fit $ mu   modelMatrix -   fit $ modelMatrix   modelMatrixNames -   fit $ modelMatrixNames # record the wide prior variance which was used in fitting   betaPriorVar -   rep (  1e6 ,   ncol (   fit $ modelMatrix ) ) } else  {   priorFitList -   fitGLMsWithPrior ( object =  object , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fit -   priorFitList $ fit   H -   priorFitList $ H   mu -   priorFitList $ mu   betaPriorVar -   priorFitList $ betaPriorVar   modelMatrix -   priorFitList $ modelMatrix   mleBetaMatrix -   priorFitList $ mleBetaMatrix # will add the MLE betas, so remove any which exist already # (possibly coming from estimateMLEForBetaPriorVar)    mcols (  object ) -    mcols (  object ) [ ,   grep (  \"MLE_\" ,   names (   mcols (  object ) ) , invert =  TRUE ) ] } # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (  mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -  mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (  mu ,    mcols (  object ) $ allZero ) # store the prior variance directly as an attribute # of the DESeqDataSet object, so it can be pulled later by # the results function (necessary for setting max Cook's distance)    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"test\" ) -  \"Wald\" # calculate Cook's distance   dispModelMatrix -  if (  modelAsFormula )  {   getModelMatrix (  object ) } else  {  modelMatrix }    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero ) # add betas, standard errors and Wald p-values to the object   modelMatrixNames -   colnames (  modelMatrix )   betaMatrix -   fit $ betaMatrix    colnames (  betaMatrix ) -  modelMatrixNames   betaSE -   fit $ betaSE    colnames (  betaSE ) -   paste0 (  \"SE_\" ,  modelMatrixNames )   WaldStatistic -   betaMatrix /  betaSE    colnames (  WaldStatistic ) -   paste0 (  \"WaldStatistic_\" ,  modelMatrixNames ) # if useT is set to TRUE, use a t-distribution  if (  useT )  {   dispPriorVar -   attr (   dispersionFunction (  object ) ,  \"dispPriorVar\" )   stopifnot (    length (  df ) ==  1 )   WaldPvalue -   2 *   pt (   abs (  WaldStatistic ) , df =  df , lower.tail =  FALSE ) } else  {   WaldPvalue -   2 *   pnorm (   abs (  WaldStatistic ) , lower.tail =  FALSE ) }    colnames (  WaldPvalue ) -   paste0 (  \"WaldPvalue_\" ,  modelMatrixNames )   betaConv -   fit $ betaConv  if (   any (  !  betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !  betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$betaConv. Use larger maxit argument with nbinomWaldTest\" ) ) }   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL }   resultsList -   c (   matrixToList (  betaMatrix ) ,   matrixToList (  betaSE ) ,  mleBetas ,   matrixToList (  WaldStatistic ) ,   matrixToList (  WaldPvalue ) ,   list ( betaConv =  betaConv , betaIter =   fit $ betaIter , deviance =   -  2 *   fit $ logLike , maxCooks =  maxCooks ) )   WaldResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"Wald statistic:\" ,  modelMatrixNamesSpaces )   pvalInfo -   paste (  \"Wald test p-value:\" ,  modelMatrixNamesSpaces )    mcols (  WaldResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  WaldResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas\" ,  \"iterations for betas\" ,  \"deviance for the fitted model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  WaldResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaPrior = FALSE , betaPriorVar , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"provide a reduced formula for the LRT, e.g. nbinomLRT(object, reduced= ~1)\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object ) # run check on the formula   modelAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   stats :: model.matrix.default (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   stats :: model.matrix.default (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {  if (  betaPrior )  {   stop (  \"user-supplied model matrices require betaPrior=FALSE\" ) }   message (  \"using supplied model matrix\" )   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) }   stopifnot (   is.logical (  betaPrior ) )  if (  modelAsFormula )  {   modelMatrixType -  \"standard\" # check for intercept   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {   modelMatrixType -  \"user-supplied\"   renameCols -  FALSE } # store modelMatrixType so it can be accessed by estimateBetaPriorVar    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (  !  betaPrior )  {  if (  modelAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , renameCols =  renameCols , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , renameCols =  FALSE , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) ) } else  {   priorFull -   fitGLMsWithPrior ( object =  object , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , betaPriorVar =  betaPriorVar )   fullModel -   priorFull $ fit   modelMatrix -   fullModel $ modelMatrix   betaPriorVar -   priorFull $ betaPriorVar   mleBetaMatrix -   priorFull $ mleBetaMatrix # form a reduced model matrix: # first find the dropped terms # then remove columns from the full model matrix which are # assigned to these terms   fullModelTerms -   attr (   terms (  full ) ,  \"term.labels\" )   reducedModelTerms -   attr (   terms (  reduced ) ,  \"term.labels\" )   droppedTerms -   which (  !   fullModelTerms %in%  reducedModelTerms )   fullAssign -   attr (  modelMatrix ,  \"assign\" )   idx -  !   fullAssign %in%  droppedTerms # now subsetting the relevant columns   reducedModelMatrix -   modelMatrix [ ,  idx , drop =  FALSE ]   reducedBetaPriorVar -   betaPriorVar [  idx ]   reducedLambda -   1 /  reducedBetaPriorVar   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reducedModelMatrix , lambda =  reducedLambda , maxit =  maxit , useOptim =  useOptim , useQR =  useQR ) }    attr (  object ,  \"betaPrior\" ) -  betaPrior    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"test\" ) -  \"LRT\" # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fullModel $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero )   H -   fullModel $ hat_diagonals # calculate Cook's distance   dispModelMatrix -  modelMatrix    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE )   mleBetas -  if (  betaPrior )  {   matrixToList (  mleBetaMatrix ) } else  {  NULL } # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,  mleBetas ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  if (   attr (  object ,  \"betaPrior\" ) )  \"MAP\" else  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  if (  betaPrior )  {   gsub (  \"_\" ,  \" \" ,   colnames (  mleBetaMatrix ) ) } else  {  NULL }   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "nbinomLRT",
    "representation": "nbinomLRT",
    "parameters": "function ( object , full = design ( object ) , reduced , betaTol = 1e-8 , maxit = 100 , useOptim = TRUE , quiet = FALSE , useQR = TRUE )",
    "body": "{  if (   is.null (   dispersions (  object ) ) )  {   stop (  \"testing requires dispersion estimates, first call estimateDispersions()\" ) }  if (   missing (  reduced ) )  {   stop (  \"provide a reduced formula for the LRT, e.g. nbinomLRT(object, reduced= ~1)\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object ) # run check on the formula   modelAsFormula -  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) )  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object , betaPrior =  FALSE ) # try to form model matrices, test for difference # in residual degrees of freedom   fullModelMatrix -   stats :: model.matrix.default (  full , data =   as.data.frame (   colData (  object ) ) )   reducedModelMatrix -   stats :: model.matrix.default (  reduced , data =   as.data.frame (   colData (  object ) ) )   df -    ncol (  fullModelMatrix ) -   ncol (  reducedModelMatrix ) } else  {   message (  \"using supplied model matrix\" )   df -    ncol (  full ) -   ncol (  reduced ) }  if (   df undefined  1 )   stop (  \"less than one degree of freedom, perhaps full and reduced models are not in the correct order\" )  if (   any (     mcols (   mcols (  object ) ) $ type ==  \"results\" ) )  {  if (  !  quiet )   message (  \"found results columns, replacing these\" )   object -   removeResults (  object ) }  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) }  if (  modelAsFormula )  {   modelMatrixType -  \"standard\" # check for intercept   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   renameCols -  hasIntercept } else  {   modelMatrixType -  \"user-supplied\"   renameCols -  FALSE } # store modelMatrixType    attr (  object ,  \"modelMatrixType\" ) -  modelMatrixType # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (  modelAsFormula )  {   fullModel -   fitNbinomGLMs (  objectNZ , modelFormula =  full , renameCols =  renameCols , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -   fullModel $ modelMatrix   reducedModel -   fitNbinomGLMs (  objectNZ , modelFormula =  reduced , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) } else  {   fullModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  full , renameCols =  FALSE , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE )   modelMatrix -  full   reducedModel -   fitNbinomGLMs (  objectNZ , modelMatrix =  reduced , renameCols =  FALSE , betaTol =  betaTol , maxit =  maxit , useOptim =  useOptim , useQR =  useQR , warnNonposVar =  FALSE ) }   betaPriorVar -   rep (  1e6 ,   ncol (  modelMatrix ) )    attr (  object ,  \"betaPrior\" ) -  FALSE    attr (  object ,  \"betaPriorVar\" ) -  betaPriorVar    attr (  object ,  \"modelMatrix\" ) -  modelMatrix    attr (  object ,  \"reducedModelMatrix\" ) -   reducedModel $ modelMatrix    attr (  object ,  \"test\" ) -  \"LRT\" # store mu in case the user did not call estimateDispersionsGeneEst    dimnames (   fullModel $ mu ) -  NULL     assays (  objectNZ ) [[  \"mu\" ] ] -   fullModel $ mu     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (   fullModel $ mu ,    mcols (  object ) $ allZero )   H -   fullModel $ hat_diagonals # calculate Cook's distance   dispModelMatrix -  modelMatrix    attr (  object ,  \"dispModelMatrix\" ) -  dispModelMatrix   cooks -   calculateCooksDistance (  objectNZ ,  H ,  dispModelMatrix ) # record maximum of Cook's   maxCooks -   recordMaxCooks (   design (  object ) ,   colData (  object ) ,  dispModelMatrix ,  cooks ,   nrow (  objectNZ ) ) # store Cook's distance for each sample     assays (  object ) [[  \"cooks\" ] ] -   buildMatrixWithNARows (  cooks ,    mcols (  object ) $ allZero )  if (   any (  !   fullModel $ betaConv ) )  {  if (  !  quiet )   message (   paste (   sum (  !   fullModel $ betaConv ) ,  \"rows did not converge in beta, labelled in mcols(object)$fullBetaConv. Use larger maxit argument with nbinomLRT\" ) ) } # calculate LRT statistic and p-values   LRTStatistic -  (   2 *  (    fullModel $ logLike -   reducedModel $ logLike ) )   LRTPvalue -   pchisq (  LRTStatistic , df =  df , lower.tail =  FALSE ) # no need to store additional betas (no beta prior)   mleBetas -  NULL # continue storing LRT results   resultsList -   c (   matrixToList (   fullModel $ betaMatrix ) ,   matrixToList (   fullModel $ betaSE ) ,  mleBetas ,   list ( LRTStatistic =  LRTStatistic , LRTPvalue =  LRTPvalue , fullBetaConv =   fullModel $ betaConv , reducedBetaConv =   reducedModel $ betaConv , betaIter =   fullModel $ betaIter , deviance =   -  2 *   fullModel $ logLike , maxCooks =  maxCooks ) )   LRTResults -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )   modelComparison -  if (  modelAsFormula )  {   paste0 (  \"'\" ,   paste (   as.character (  full ) , collapse =  \" \" ) ,  \"' vs '\" ,   paste (   as.character (  reduced ) , collapse =  \" \" ) ,  \"'\" ) } else  {  \"full vs reduced\" }   modelMatrixNames -   colnames (   fullModel $ betaMatrix )   modelMatrixNamesSpaces -   gsub (  \"_\" ,  \" \" ,  modelMatrixNames )   lfcType -  \"MLE\"   coefInfo -   paste (   paste0 (  \"log2 fold change (\" ,  lfcType ,  \"):\" ) ,  modelMatrixNamesSpaces )   seInfo -   paste (  \"standard error:\" ,  modelMatrixNamesSpaces )   mleInfo -  NULL   statInfo -   paste (  \"LRT statistic:\" ,  modelComparison )   pvalInfo -   paste (  \"LRT p-value:\" ,  modelComparison )    mcols (  LRTResults ) -   DataFrame ( type =   rep (  \"results\" ,   ncol (  LRTResults ) ) , description =   c (  coefInfo ,  seInfo ,  mleInfo ,  statInfo ,  pvalInfo ,  \"convergence of betas for full model\" ,  \"convergence of betas for reduced model\" ,  \"iterations for betas for full model\" ,  \"deviance of the full model\" ,  \"maximum Cook's distance for row\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  LRTResults )   return (  object ) } ",
    "filename": "core.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_5 deseq2_release_3_6

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_5 deseq2_release_3_6",
    "desc_release_old": "1.16.1",
    "desc_release_new": "1.18.1",
    "old_release_number": 7,
    "new_release_number": 8,
    "function_removals": 0,
    "function_additions": 2,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 0,
    "total_count": 0
}

##########
Functions Removed
##########



##########
Functions Added
##########

priorInfo<-
priorInfo


##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_6 deseq2_release_3_7

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_6 deseq2_release_3_7",
    "desc_release_old": "1.18.1",
    "desc_release_new": "1.20.0",
    "old_release_number": 8,
    "new_release_number": 9,
    "function_removals": 0,
    "function_additions": 0,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 1,
    "total_count": 1
}

##########
Functions Removed
##########



##########
Functions Added
##########



##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , test = c ( \"Wald\" , \"LRT\" ) , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , betaPrior , full = design ( object ) , reduced , quiet = FALSE , minReplicatesForReplace = 7 , modelMatrixType , parallel = FALSE , BPPARAM = bpparam ( ) )",
    "body": "{ # check arguments   stopifnot (   is (  object ,  \"DESeqDataSet\" ) )   test -   match.arg (  test , choices =   c (  \"Wald\" ,  \"LRT\" ) )   fitType -   match.arg (  fitType , choices =   c (  \"parametric\" ,  \"local\" ,  \"mean\" ) )   stopifnot (   is.logical (  quiet ) )   stopifnot (   is.numeric (  minReplicatesForReplace ) )   stopifnot (   is.logical (  parallel ) )   modelAsFormula -  !   is.matrix (  full )  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } else  {   stopifnot (   is.logical (  betaPrior ) ) } # get rid of any NA in the mcols(mcols(object))   object -   sanitizeRowRanges (  object )  if (   test ==  \"LRT\" )  {  if (   missing (  reduced ) )  {   stop (  \"likelihood ratio test requires a 'reduced' design, see ?DESeq\" ) }  if (  betaPrior )  {   stop (  \"test='LRT' does not support use of LFC shrinkage, use betaPrior=FALSE\" ) }  if (   !   missing (  modelMatrixType ) undefined   modelMatrixType ==  \"expanded\" )  {   stop (  \"test='LRT' does not support use of expanded model matrix\" ) }  if (    is.matrix (  full ) |   is.matrix (  reduced ) )  {  if (  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) ) )  {   stop (  \"if one of 'full' and 'reduced' is a matrix, the other must be also a matrix\" ) } }  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) } else  {   checkFullRank (  full )   checkFullRank (  reduced )  if (    ncol (  full ) =   ncol (  reduced ) )  {   stop (  \"the number of columns of 'full' should be more than the number of columns of 'reduced'\" ) } } }  if (    test ==  \"Wald\" undefined  !   missing (  reduced ) )  {   stop (  \"'reduced' ignored when test='Wald'\" ) }  if (  modelAsFormula )  { # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior )  if (    design (  object ) ==   formula (  ~  1 ) )  {   warning (  \"the design is ~ 1 (just an intercept). is this intended?\" ) }  if (   full !=   design (  object ) )  {   stop (  \"'full' specified as formula should equal design(object)\" ) }   modelMatrix -  NULL } else  {  if (   betaPrior ==  TRUE )  {   stop (  \"betaPrior=TRUE is not supported for user-provided model matrices\" ) }   checkFullRank (  full ) # this will be used for dispersion estimation and testing   modelMatrix -  full }    attr (  object ,  \"betaPrior\" ) -  betaPrior   stopifnot (     length (  parallel ) ==  1 undefined   is.logical (  parallel ) )  if (   !   is.null (   sizeFactors (  object ) ) ||  !   is.null (   normalizationFactors (  object ) ) )  {  if (  !  quiet )  {  if (  !   is.null (   normalizationFactors (  object ) ) )  {   message (  \"using pre-existing normalization factors\" ) } else  {   message (  \"using pre-existing size factors\" ) } } } else  {  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object ) }  if (  !  parallel )  {  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet , modelMatrix =  modelMatrix )  if (  !  quiet )   message (  \"fitting model and testing\" )  if (   test ==  \"Wald\" )  {   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , quiet =  quiet , modelMatrix =  modelMatrix , modelMatrixType =  modelMatrixType ) } else  if (   test ==  \"LRT\" )  {   object -   nbinomLRT (  object , full =  full , reduced =  reduced , quiet =  quiet ) } } else  if (  parallel )  {   object -   DESeqParallel (  object , test =  test , fitType =  fitType , betaPrior =  betaPrior , full =  full , reduced =  reduced , quiet =  quiet , modelMatrix =  modelMatrix , modelMatrixType =  modelMatrixType , BPPARAM =  BPPARAM ) } # if there are sufficient replicates, then pass through to refitting function   sufficientReps -   any (   nOrMoreInCell (   attr (  object ,  \"modelMatrix\" ) ,  minReplicatesForReplace ) )  if (  sufficientReps )  {   object -   refitWithoutOutliers (  object , test =  test , betaPrior =  betaPrior , full =  full , reduced =  reduced , quiet =  quiet , minReplicatesForReplace =  minReplicatesForReplace , modelMatrix =  modelMatrix , modelMatrixType =  modelMatrixType ) } # stash the package version (again, also in construction)     metadata (  object ) [[  \"version\" ] ] -   packageVersion (  \"DESeq2\" )  object } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "DESeq",
    "representation": "DESeq",
    "parameters": "function ( object , test = c ( \"Wald\" , \"LRT\" ) , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , sfType = c ( \"ratio\" , \"poscounts\" , \"iterate\" ) , betaPrior , full = design ( object ) , reduced , quiet = FALSE , minReplicatesForReplace = 7 , modelMatrixType , useT = FALSE , minmu = 0.5 , parallel = FALSE , BPPARAM = bpparam ( ) )",
    "body": "{ # check arguments   stopifnot (   is (  object ,  \"DESeqDataSet\" ) )   test -   match.arg (  test , choices =   c (  \"Wald\" ,  \"LRT\" ) )   fitType -   match.arg (  fitType , choices =   c (  \"parametric\" ,  \"local\" ,  \"mean\" ) )   sfType -   match.arg (  sfType , choices =   c (  \"ratio\" ,  \"poscounts\" ,  \"iterate\" ) ) # more check arguments   stopifnot (   is.logical (  quiet ) )   stopifnot (   is.numeric (  minReplicatesForReplace ) )   stopifnot (   is.logical (  parallel ) )   modelAsFormula -   !   is.matrix (  full ) undefined   is (   design (  object ) ,  \"formula\" )  if (   missing (  betaPrior ) )  {   betaPrior -  FALSE } else  {   stopifnot (   is.logical (  betaPrior ) ) } # get rid of any NA in the mcols(mcols(object))   object -   sanitizeRowRanges (  object )  if (   test ==  \"LRT\" )  {  if (   missing (  reduced ) )  {   stop (  \"likelihood ratio test requires a 'reduced' design, see ?DESeq\" ) }  if (  betaPrior )  {   stop (  \"test='LRT' does not support use of LFC shrinkage, use betaPrior=FALSE\" ) }  if (   !   missing (  modelMatrixType ) undefined   modelMatrixType ==  \"expanded\" )  {   stop (  \"test='LRT' does not support use of expanded model matrix\" ) }  if (    is.matrix (  full ) |   is.matrix (  reduced ) )  {  if (  !  (    is.matrix (  full ) undefined   is.matrix (  reduced ) ) )  {   stop (  \"if one of 'full' and 'reduced' is a matrix, the other must be also a matrix\" ) } }  if (  modelAsFormula )  {   checkLRT (  full ,  reduced ) } else  {   checkFullRank (  full )   checkFullRank (  reduced )  if (    ncol (  full ) =   ncol (  reduced ) )  {   stop (  \"the number of columns of 'full' should be more than the number of columns of 'reduced'\" ) } } }  if (    test ==  \"Wald\" undefined  !   missing (  reduced ) )  {   stop (  \"'reduced' ignored when test='Wald'\" ) }  if (  modelAsFormula )  { # run some tests common to DESeq, nbinomWaldTest, nbinomLRT   designAndArgChecker (  object ,  betaPrior )  if (    design (  object ) ==   formula (  ~  1 ) )  {   warning (  \"the design is ~ 1 (just an intercept). is this intended?\" ) }  if (   full !=   design (  object ) )  {   stop (  \"'full' specified as formula should equal design(object)\" ) }   modelMatrix -  NULL } else  {  if (   betaPrior ==  TRUE )  {   stop (  \"betaPrior=TRUE is not supported for user-provided model matrices\" ) }   checkFullRank (  full ) # this will be used for dispersion estimation and testing   modelMatrix -  full }    attr (  object ,  \"betaPrior\" ) -  betaPrior   stopifnot (     length (  parallel ) ==  1 undefined   is.logical (  parallel ) )  if (   !   is.null (   sizeFactors (  object ) ) ||  !   is.null (   normalizationFactors (  object ) ) )  {  if (  !  quiet )  {  if (  !   is.null (   normalizationFactors (  object ) ) )  {   message (  \"using pre-existing normalization factors\" ) } else  {   message (  \"using pre-existing size factors\" ) } } } else  {  if (  !  quiet )   message (  \"estimating size factors\" )   object -   estimateSizeFactors (  object , type =  sfType ) }  if (  !  parallel )  {  if (  !  quiet )   message (  \"estimating dispersions\" )   object -   estimateDispersions (  object , fitType =  fitType , quiet =  quiet , modelMatrix =  modelMatrix , minmu =  minmu )  if (  !  quiet )   message (  \"fitting model and testing\" )  if (   test ==  \"Wald\" )  {   object -   nbinomWaldTest (  object , betaPrior =  betaPrior , quiet =  quiet , modelMatrix =  modelMatrix , modelMatrixType =  modelMatrixType , useT =  useT , minmu =  minmu ) } else  if (   test ==  \"LRT\" )  {   object -   nbinomLRT (  object , full =  full , reduced =  reduced , quiet =  quiet , minmu =  minmu ) } } else  if (  parallel )  {  if (  !   missing (  modelMatrixType ) )  {  if (  betaPrior )   stopifnot (   modelMatrixType ==  \"expanded\" ) }   object -   DESeqParallel (  object , test =  test , fitType =  fitType , betaPrior =  betaPrior , full =  full , reduced =  reduced , quiet =  quiet , modelMatrix =  modelMatrix , useT =  useT , minmu =  minmu , BPPARAM =  BPPARAM ) } # if there are sufficient replicates, then pass through to refitting function   sufficientReps -   any (   nOrMoreInCell (   attr (  object ,  \"modelMatrix\" ) ,  minReplicatesForReplace ) )  if (  sufficientReps )  {   object -   refitWithoutOutliers (  object , test =  test , betaPrior =  betaPrior , full =  full , reduced =  reduced , quiet =  quiet , minReplicatesForReplace =  minReplicatesForReplace , modelMatrix =  modelMatrix , modelMatrixType =  modelMatrixType ) } # stash the package version (again, also in construction)     metadata (  object ) [[  \"version\" ] ] -   packageVersion (  \"DESeq2\" )  object } ",
    "filename": "core.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_7 deseq2_release_3_8

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_7 deseq2_release_3_8",
    "desc_release_old": "1.20.0",
    "desc_release_new": "1.22.2",
    "old_release_number": 9,
    "new_release_number": 10,
    "function_removals": 0,
    "function_additions": 0,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 1,
    "total_count": 1
}

##########
Functions Removed
##########



##########
Functions Added
##########



##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "unmix",
    "representation": "unmix",
    "parameters": "function ( x , pure , alpha , shift , loss = 1 , quiet = FALSE )",
    "body": "{  if (   missing (  alpha ) )   stopifnot (  !   missing (  shift ) )  if (   missing (  shift ) )   stopifnot (  !   missing (  alpha ) )   stopifnot (    missing (  shift ) |   missing (  alpha ) )   stopifnot (   loss %in%   1 :  2 )   stopifnot (    nrow (  x ) ==   nrow (  pure ) )   stopifnot (    ncol (  pure ) undefined  1 )  if (    requireNamespace (  \"pbapply\" , quietly =  TRUE ) undefined  !  quiet )  {   lapply -  pbapply :: pblapply }  if (   missing (  shift ) )  {   stopifnot (   alpha undefined  0 ) # variance stabilizing transformation for NB w/ fixed dispersion alpha   vst -  function ( q , alpha )   (     2 *   asinh (   sqrt (   alpha *  q ) ) -   log (  alpha ) -   log (  4 ) ) /   log (  2 )   distVST -  function ( p , i , vst , alpha , loss )  {   sum (    abs (    vst (   x [ ,  i ] ,  alpha ) -   vst (   pure %*%  p ,  alpha ) ) ^  loss ) }   res -   lapply (   seq_len (   ncol (  x ) ) ,  function ( i )  {    optim ( par =   rep (  1 ,   ncol (  pure ) ) , fn =  distVST , gr =  NULL ,  i ,  vst ,  alpha ,  loss , method =  \"L-BFGS-B\" , lower =  0 , upper =  100 ) $ par } ) } else  {   stopifnot (   shift undefined  0 ) # VST of shifted log   vstSL -  function ( q , shift )   log (   q +  shift )   distSL -  function ( p , i , vst , shift , loss )  {   sum (    abs (    vstSL (   x [ ,  i ] ,  shift ) -   vstSL (   pure %*%  p ,  shift ) ) ^  loss ) }   res -   lapply (   seq_len (   ncol (  x ) ) ,  function ( i )  {    optim ( par =   rep (  1 ,   ncol (  pure ) ) , fn =  distSL , gr =  NULL ,  i ,  vstSL ,  shift ,  loss , method =  \"L-BFGS-B\" , lower =  0 , upper =  100 ) $ par } ) }   mix -   do.call (  rbind ,  res )   mix -   mix /   rowSums (  mix )    colnames (  mix ) -   colnames (  pure )    rownames (  mix ) -   colnames (  x )   return (  mix ) } ",
    "filename": "helper.txt"
  },
  "new_function": {
    "name": "unmix",
    "representation": "unmix",
    "parameters": "function ( x , pure , alpha , shift , power = 1 , format = \"matrix\" , quiet = FALSE )",
    "body": "{   format -   match.arg (  format ,   c (  \"matrix\" ,  \"list\" ) )  if (   missing (  alpha ) )   stopifnot (  !   missing (  shift ) )  if (   missing (  shift ) )   stopifnot (  !   missing (  alpha ) )   stopifnot (    missing (  shift ) |   missing (  alpha ) )   stopifnot (   power %in%   1 :  2 )   stopifnot (    nrow (  x ) ==   nrow (  pure ) )   stopifnot (    ncol (  pure ) undefined  1 )  if (    requireNamespace (  \"pbapply\" , quietly =  TRUE ) undefined  !  quiet )  {   lapply -  pbapply :: pblapply }   cor.msg -  \"some columns of 'pure' are highly correlated (  if (   missing (  shift ) )  {   stopifnot (   alpha undefined  0 ) # variance stabilizing transformation for NB w/ fixed dispersion alpha   vst -  function ( q , alpha )   (     2 *   asinh (   sqrt (   alpha *  q ) ) -   log (  alpha ) -   log (  4 ) ) /   log (  2 )   pure.cor -   cor (   vst (  pure ,  alpha ) ) ;    diag (  pure.cor ) -  0  if (   any (   pure.cor undefined  .99 ) )   warning (  cor.msg )   sumLossVST -  function ( p , i , vst , alpha , power )  {   sum (    abs (    vst (   x [ ,  i ] ,  alpha ) -   vst (   pure %*%  p ,  alpha ) ) ^  power ) }   res -   lapply (   seq_len (   ncol (  x ) ) ,  function ( i )  {    optim ( par =   rep (  1 ,   ncol (  pure ) ) , fn =  sumLossVST , gr =  NULL ,  i ,  vst ,  alpha ,  power , method =  \"L-BFGS-B\" , lower =  0 , upper =  100 ) $ par } ) } else  {   stopifnot (   shift undefined  0 ) # VST of shifted log   vstSL -  function ( q , shift )   log (   q +  shift )   pure.cor -   cor (   vstSL (  pure ,  shift ) ) ;    diag (  pure.cor ) -  0  if (   any (   pure.cor undefined  .99 ) )   warning (  cor.msg )   sumLossSL -  function ( p , i , vst , shift , power )  {   sum (    abs (    vstSL (   x [ ,  i ] ,  shift ) -   vstSL (   pure %*%  p ,  shift ) ) ^  power ) }   res -   lapply (   seq_len (   ncol (  x ) ) ,  function ( i )  {    optim ( par =   rep (  1 ,   ncol (  pure ) ) , fn =  sumLossSL , gr =  NULL ,  i ,  vstSL ,  shift ,  power , method =  \"L-BFGS-B\" , lower =  0 , upper =  100 ) $ par } ) }   mix -   do.call (  rbind ,  res )   mix -   mix /   rowSums (  mix )    colnames (  mix ) -   colnames (  pure )    rownames (  mix ) -   colnames (  x )  if (   format ==  \"matrix\" )  {   return (  mix ) } else  {   fitted -   pure %*%   t (  mix )   cor -  if (   missing (  shift ) )  {   cor (   vst (  x ,  alpha ) ,   vst (  fitted ,  alpha ) ) } else  {   cor (   vstSL (  x ,  shift ) ,   vstSL (  fitted ,  shift ) ) }   return (   list ( mix =  mix , cor =   diag (  cor ) , fitted =  fitted ) ) } } ",
    "filename": "helper.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_8 deseq2_release_3_9

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_8 deseq2_release_3_9",
    "desc_release_old": "1.22.2",
    "desc_release_new": "1.24.0",
    "old_release_number": 10,
    "new_release_number": 11,
    "function_removals": 0,
    "function_additions": 0,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 0,
    "total_count": 0
}

##########
Functions Removed
##########



##########
Functions Added
##########



##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_9 deseq2_release_3_11

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_9 deseq2_release_3_11",
    "desc_release_old": "1.24.0",
    "desc_release_new": "1.28.1",
    "old_release_number": 11,
    "new_release_number": 12,
    "function_removals": 1,
    "function_additions": 1,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 3,
    "total_count": 4
}

##########
Functions Removed
##########

summary.DESeqResults


##########
Functions Added
##########

summary


##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "estimateDispersionsGeneEst",
    "representation": "estimateDispersionsGeneEst",
    "parameters": "function ( object , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , quiet = FALSE , modelMatrix = NULL , niter = 1 , linearMu = NULL , minmu = 0.5 )",
    "body": "{  if (  !   is.null (    mcols (  object ) $ dispGeneEst ) )  {  if (  !  quiet )   message (  \"found already estimated gene-wise dispersions, removing these\" )   removeCols -   c (  \"dispGeneEst\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols , drop =  FALSE ] }   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (    log (   minDisp /  10 ) =  -  30 )  {   stop (  \"for computational stability, log(minDisp/10) should be above -30\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object )  if (   is.null (  modelMatrix ) )  {   modelMatrix -   getModelMatrix (  object ) }   checkFullRank (  modelMatrix )  if (    nrow (  modelMatrix ) ==   ncol (  modelMatrix ) )  {   stop (  \"the number of samples and the number of model coefficients are equal,\r\n  i.e., there are no replicates to estimate the dispersion.\r\n  use an alternate design formula\" ) }   object -   getBaseMeansAndVariances (  object ) # use weights if they are present in assays(object) # (we need this already to decide about linear mu fitting)   wlist -   getAndCheckWeights (  object ,  modelMatrix )   object -   wlist $ object   weights -   wlist $ weights # don't let weights go below 1e-6   weights -   pmax (  weights ,  1e-6 )   useWeights -   wlist $ useWeights # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ] # this rough dispersion estimate (alpha_hat) # is for estimating mu # and for the initial starting point for line search   roughDisp -   roughDispEstimate ( y =   counts (  objectNZ , normalized =  TRUE ) , x =  modelMatrix )   momentsDisp -   momentsDispEstimate (  objectNZ )   alpha_hat -   pmin (  roughDisp ,  momentsDisp ) # bound the rough estimated alpha between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   alpha_hat -   alpha_hat_new -   alpha_init -   pmin (   pmax (  minDisp ,  alpha_hat ) ,  maxDisp )   stopifnot (     length (  niter ) ==  1 undefined   niter undefined  0 ) # use a linear model to estimate the expected counts # if the number of groups according to the model matrix # is equal to the number of columns  if (   is.null (  linearMu ) )  {   modelMatrixGroups -   modelMatrixGroups (  modelMatrix )   linearMu -    nlevels (  modelMatrixGroups ) ==   ncol (  modelMatrix ) # also check for weights (then can't do linear mu)  if (  useWeights )  {   linearMu -  FALSE } } # below, iterate between mean and dispersion estimation (niter) times   fitidx -   rep (  TRUE ,   nrow (  objectNZ ) )   mu -   matrix (  0 , nrow =   nrow (  objectNZ ) , ncol =   ncol (  objectNZ ) )   dispIter -   numeric (   nrow (  objectNZ ) ) # bound the estimated count by 'minmu' # this helps make the fitting more robust, # because 1/mu occurs in the weights for the NB GLM  for  ( iter in   seq_len (  niter ) )  {  if (  !  linearMu )  {   fit -   fitNbinomGLMs (   objectNZ [  fitidx , , drop =  FALSE ] , alpha_hat =   alpha_hat [  fitidx ] , modelMatrix =  modelMatrix )   fitMu -   fit $ mu } else  {   fitMu -   linearModelMuNormalized (   objectNZ [  fitidx , , drop =  FALSE ] ,  modelMatrix ) }    fitMu [   fitMu undefined  minmu ] -  minmu    mu [  fitidx , ] -  fitMu # use of kappa_0 in backtracking search # initial proposal = log(alpha) + kappa_0 * deriv. of log lik. w.r.t. log(alpha) # use log(minDisp/10) to stop if dispersions going to -infinity   dispRes -   fitDispWrapper ( ySEXP =    counts (  objectNZ ) [  fitidx , , drop =  FALSE ] , xSEXP =  modelMatrix , mu_hatSEXP =  fitMu , log_alphaSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_meanSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_sigmasqSEXP =  1 , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , usePriorSEXP =  FALSE , weightsSEXP =  weights , useWeightsSEXP =  useWeights )    dispIter [  fitidx ] -   dispRes $ iter    alpha_hat_new [  fitidx ] -   pmin (   exp (   dispRes $ log_alpha ) ,  maxDisp ) # only rerun those rows which moved   fitidx -    abs (    log (  alpha_hat_new ) -   log (  alpha_hat ) ) undefined  .05   alpha_hat -  alpha_hat_new  if (    sum (  fitidx ) ==  0 )  break } # dont accept moves if the log posterior did not # increase by more than one millionth, # and set the small estimates to the minimum dispersion   dispGeneEst -  alpha_hat  if (   niter ==  1 )  {   noIncrease -    dispRes $ last_lp undefined    dispRes $ initial_lp +    abs (   dispRes $ initial_lp ) /  1e6    dispGeneEst [   which (  noIncrease ) ] -   alpha_init [   which (  noIncrease ) ] } # didn't reach the maxmium and iterated more than once   dispGeneEstConv -    dispIter undefined  maxit undefined  !  (   dispIter ==  1 ) # if lacking convergence from fitDisp() (C++)...   refitDisp -   !  dispGeneEstConv undefined   dispGeneEst undefined   minDisp *  10  if (    sum (  refitDisp ) undefined  0 )  {   dispGrid -   fitDispGridWrapper ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =   rep (  0 ,   sum (  refitDisp ) ) , logAlphaPriorSigmaSq =  1 , usePrior =  FALSE , weightsSEXP =   weights [  refitDisp , , drop =  FALSE ] , useWeightsSEXP =  useWeights )    dispGeneEst [  refitDisp ] -  dispGrid }   dispGeneEst -   pmin (   pmax (  dispGeneEst ,  minDisp ) ,  maxDisp )   dispDataFrame -   buildDataFrameWithNARows (   list ( dispGeneEst =  dispGeneEst , dispGeneIter =  dispIter ) ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"gene-wise estimates of dispersion\" ,  \"number of iterations for gene-wise\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )     assays (  object ) [[  \"mu\" ] ] -   buildMatrixWithNARows (  mu ,    mcols (  object ) $ allZero )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsGeneEst",
    "representation": "estimateDispersionsGeneEst",
    "parameters": "function ( object , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , useCR = TRUE , weightThreshold = 1e-2 , quiet = FALSE , modelMatrix = NULL , niter = 1 , linearMu = NULL , minmu = 0.5 , alphaInit = NULL )",
    "body": "{  if (  !   is.null (    mcols (  object ) $ dispGeneEst ) )  {  if (  !  quiet )   message (  \"found already estimated gene-wise dispersions, removing these\" )   removeCols -   c (  \"dispGeneEst\" ,  \"dispGeneIter\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols , drop =  FALSE ] }   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (    log (   minDisp /  10 ) =  -  30 )  {   stop (  \"for computational stability, log(minDisp/10) should be above -30\" ) } # in case the class of the mcols(mcols(object)) are not character   object -   sanitizeRowRanges (  object )  if (   is.null (  modelMatrix ) )  {   modelMatrix -   getModelMatrix (  object ) }   checkFullRank (  modelMatrix )  if (    nrow (  modelMatrix ) ==   ncol (  modelMatrix ) )  {   stop (  \"the number of samples and the number of model coefficients are equal,\r\n  i.e., there are no replicates to estimate the dispersion.\r\n  use an alternate design formula\" ) }   object -   getBaseMeansAndVariances (  object ) # use weights if they are present in assays(object) # (we need this already to decide about linear mu fitting)    attr (  object ,  \"weightsOK\" ) -  NULL # reset any information   wlist -   getAndCheckWeights (  object ,  modelMatrix , weightThreshold =  weightThreshold )   object -   wlist $ object   weights -   wlist $ weights # don't let weights go below 1e-6   weights -   pmax (  weights ,  1e-6 )   useWeights -   wlist $ useWeights # only continue on the rows with non-zero row mean   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]   weights -   weights [  !    mcols (  object ) $ allZero , , drop =  FALSE ]  if (   is.null (  alphaInit ) )  { # this rough dispersion estimate (alpha_hat) # is for estimating mu # and for the initial starting point for line search   roughDisp -   roughDispEstimate ( y =   counts (  objectNZ , normalized =  TRUE ) , x =  modelMatrix )   momentsDisp -   momentsDispEstimate (  objectNZ )   alpha_hat -   pmin (  roughDisp ,  momentsDisp ) } else  {  if (    length (  alphaInit ) ==  1 )  {   alpha_hat -   rep (  alphaInit ,   nrow (  objectNZ ) ) } else  {   stopifnot (    length (  alphaInit ) ==   nrow (  objectNZ ) )   alpha_hat -  alphaInit } } # bound the rough estimated alpha between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   alpha_hat -   alpha_hat_new -   alpha_init -   pmin (   pmax (  minDisp ,  alpha_hat ) ,  maxDisp )   stopifnot (     length (  niter ) ==  1 undefined   niter undefined  0 ) # use a linear model to estimate the expected counts # if the number of groups according to the model matrix # is equal to the number of columns  if (   is.null (  linearMu ) )  {   modelMatrixGroups -   modelMatrixGroups (  modelMatrix )   linearMu -    nlevels (  modelMatrixGroups ) ==   ncol (  modelMatrix ) # also check for weights (then can't do linear mu)  if (  useWeights )  {   linearMu -  FALSE } } # below, iterate between mean and dispersion estimation (niter) times   fitidx -   rep (  TRUE ,   nrow (  objectNZ ) )   mu -   matrix (  0 , nrow =   nrow (  objectNZ ) , ncol =   ncol (  objectNZ ) )   dispIter -   numeric (   nrow (  objectNZ ) ) # bound the estimated count by 'minmu' # this helps make the fitting more robust, # because 1/mu occurs in the weights for the NB GLM  for  ( iter in   seq_len (  niter ) )  {  if (  !  linearMu )  {   fit -   fitNbinomGLMs (   objectNZ [  fitidx , , drop =  FALSE ] , alpha_hat =   alpha_hat [  fitidx ] , modelMatrix =  modelMatrix )   fitMu -   fit $ mu } else  {   fitMu -   linearModelMuNormalized (   objectNZ [  fitidx , , drop =  FALSE ] ,  modelMatrix ) }    fitMu [   fitMu undefined  minmu ] -  minmu    mu [  fitidx , ] -  fitMu # use of kappa_0 in backtracking search # initial proposal = log(alpha) + kappa_0 * deriv. of log lik. w.r.t. log(alpha) # use log(minDisp/10) to stop if dispersions going to -infinity   dispRes -   fitDispWrapper ( ySEXP =    counts (  objectNZ ) [  fitidx , , drop =  FALSE ] , xSEXP =  modelMatrix , mu_hatSEXP =  fitMu , log_alphaSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_meanSEXP =    log (  alpha_hat ) [  fitidx ] , log_alpha_prior_sigmasqSEXP =  1 , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , usePriorSEXP =  FALSE , weightsSEXP =  weights , useWeightsSEXP =  useWeights , weightThresholdSEXP =  weightThreshold , useCRSEXP =  useCR )    dispIter [  fitidx ] -   dispRes $ iter    alpha_hat_new [  fitidx ] -   pmin (   exp (   dispRes $ log_alpha ) ,  maxDisp ) # only rerun those rows which moved   fitidx -    abs (    log (  alpha_hat_new ) -   log (  alpha_hat ) ) undefined  .05   alpha_hat -  alpha_hat_new  if (    sum (  fitidx ) ==  0 )  break } # dont accept moves if the log posterior did not # increase by more than one millionth, # and set the small estimates to the minimum dispersion   dispGeneEst -  alpha_hat  if (   niter ==  1 )  {   noIncrease -    dispRes $ last_lp undefined    dispRes $ initial_lp +    abs (   dispRes $ initial_lp ) /  1e6    dispGeneEst [   which (  noIncrease ) ] -   alpha_init [   which (  noIncrease ) ] } # didn't reach the maxmium and iterated more than once   dispGeneEstConv -    dispIter undefined  maxit undefined  !  (   dispIter ==  1 ) # if lacking convergence from fitDisp() (C++)...   refitDisp -   !  dispGeneEstConv undefined   dispGeneEst undefined   minDisp *  10  if (    sum (  refitDisp ) undefined  0 )  {   dispGrid -   fitDispGridWrapper ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =   rep (  0 ,   sum (  refitDisp ) ) , logAlphaPriorSigmaSq =  1 , usePrior =  FALSE , weightsSEXP =   weights [  refitDisp , , drop =  FALSE ] , useWeightsSEXP =  useWeights , weightThresholdSEXP =  weightThreshold , useCRSEXP =  useCR )    dispGeneEst [  refitDisp ] -  dispGrid }   dispGeneEst -   pmin (   pmax (  dispGeneEst ,  minDisp ) ,  maxDisp )   dispDataFrame -   buildDataFrameWithNARows (   list ( dispGeneEst =  dispGeneEst , dispGeneIter =  dispIter ) ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"gene-wise estimates of dispersion\" ,  \"number of iterations for gene-wise\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )     assays (  object , withDimnames =  FALSE ) [[  \"mu\" ] ] -   buildMatrixWithNARows (  mu ,    mcols (  object ) $ allZero )   return (  object ) } ",
    "filename": "core.txt"
  }
}

1.
{
  "old_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , modelMatrix = NULL , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) }  if (  !   is.null (    mcols (  object ) $ dispersion ) )  {  if (  !  quiet )   message (  \"found already estimated dispersions, removing these\" )   removeCols -   c (  \"dispersion\" ,  \"dispOutlier\" ,  \"dispMAP\" ,  \"dispIter\" ,  \"dispConv\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols , drop =  FALSE ] }  if (   is.null (  modelMatrix ) )  {   modelMatrix -   getModelMatrix (  object ) } # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  { # if no gene-wise estimates above minimum  if (    sum (     mcols (  object ) $ dispGeneEst =   minDisp *  100 , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   rep (   minDisp *  10 ,   sum (  !    mcols (  object ) $ allZero ) ) )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  0.25    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn   return (  object ) }   dispPriorVar -   estimateDispersionsPriorVar (  object , modelMatrix =  modelMatrix )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn } else  {   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn }   stopifnot (    length (  dispPriorVar ) ==  1 ) # use weights if they are present in assays(object)   wlist -   getAndCheckWeights (  object ,  modelMatrix )   object -   wlist $ object   weights -   wlist $ weights   useWeights -   wlist $ useWeights   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]   varLogDispEsts -   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one order of magnitude # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDispWrapper ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , usePriorSEXP =  TRUE , weightsSEXP =  weights , useWeightsSEXP =  useWeights ) # prepare dispersions for storage in mcols(object)   dispMAP -   exp (   dispResMAP $ log_alpha ) # when lacking convergence from fitDisp() (C++) # we use a function to maximize dispersion parameter # along an adaptive grid (also C++)   dispConv -    dispResMAP $ iter undefined  maxit   refitDisp -  !  dispConv  if (    sum (  refitDisp ) undefined  0 )  {   dispGrid -   fitDispGridWrapper ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =    log (    mcols (  objectNZ ) $ dispFit ) [  refitDisp ] , logAlphaPriorSigmaSq =  log_alpha_prior_sigmasq , usePrior =  TRUE , weightsSEXP =   weights [  refitDisp , , drop =  FALSE ] , useWeightsSEXP =  useWeights )    dispMAP [  refitDisp ] -  dispGrid } # bound the dispersion estimate between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   dispMAP -   pmin (   pmax (  dispMAP ,  minDisp ) ,  maxDisp )   dispersionFinal -  dispMAP # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEsts )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispOutlier =  dispOutlier , dispMAP =  dispMAP )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , useCR = TRUE , weightThreshold = 1e-2 , modelMatrix = NULL , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) }  if (  !   is.null (    mcols (  object ) $ dispersion ) )  {  if (  !  quiet )   message (  \"found already estimated dispersions, removing these\" )   removeCols -   c (  \"dispersion\" ,  \"dispOutlier\" ,  \"dispMAP\" ,  \"dispIter\" ,  \"dispConv\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols , drop =  FALSE ] }  if (   is.null (  modelMatrix ) )  {   modelMatrix -   getModelMatrix (  object ) } # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  { # if no gene-wise estimates above minimum  if (    sum (     mcols (  object ) $ dispGeneEst =   minDisp *  100 , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   rep (   minDisp *  10 ,   sum (  !    mcols (  object ) $ allZero ) ) )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  0.25    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn   return (  object ) }   dispPriorVar -   estimateDispersionsPriorVar (  object , modelMatrix =  modelMatrix )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn } else  {   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn }   stopifnot (    length (  dispPriorVar ) ==  1 ) # use weights if they are present in assays(object)   wlist -   getAndCheckWeights (  object ,  modelMatrix , weightThreshold =  weightThreshold )   object -   wlist $ object   weights -   wlist $ weights   useWeights -   wlist $ useWeights   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]   weights -   weights [  !    mcols (  object ) $ allZero , , drop =  FALSE ]   varLogDispEsts -   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one order of magnitude # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDispWrapper ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , usePriorSEXP =  TRUE , weightsSEXP =  weights , useWeightsSEXP =  useWeights , weightThresholdSEXP =  weightThreshold , useCRSEXP =  useCR ) # prepare dispersions for storage in mcols(object)   dispMAP -   exp (   dispResMAP $ log_alpha ) # when lacking convergence from fitDisp() (C++) # we use a function to maximize dispersion parameter # along an adaptive grid (also C++)   dispConv -    dispResMAP $ iter undefined  maxit   refitDisp -  !  dispConv  if (    sum (  refitDisp ) undefined  0 )  {   dispGrid -   fitDispGridWrapper ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =    log (    mcols (  objectNZ ) $ dispFit ) [  refitDisp ] , logAlphaPriorSigmaSq =  log_alpha_prior_sigmasq , usePrior =  TRUE , weightsSEXP =   weights [  refitDisp , , drop =  FALSE ] , useWeightsSEXP =  useWeights , weightThresholdSEXP =  weightThreshold , useCRSEXP =  TRUE )    dispMAP [  refitDisp ] -  dispGrid } # bound the dispersion estimate between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   dispMAP -   pmin (   pmax (  dispMAP ,  minDisp ) ,  maxDisp )   dispersionFinal -  dispMAP # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEsts )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispOutlier =  dispOutlier , dispMAP =  dispMAP )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  }
}

2.
{
  "old_function": {
    "name": "estimateDispersions",
    "representation": "estimateDispersions",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , maxit = 100 , quiet = FALSE , modelMatrix = NULL , minmu = 0.5 )",
    "body": "{ # Temporary hack for backward compatibility with \"old\" DESeqDataSet # objects. Remove once all serialized DESeqDataSet objects around have # been updated.  if (  !   .hasSlot (  object ,  \"rowRanges\" ) )   object -   updateObject (  object )  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   stop (  \"first call estimateSizeFactors or provide a normalizationFactor matrix before estimateDispersions\" ) } # size factors could have slipped in to colData from a previous run  if (  !   is.null (   sizeFactors (  object ) ) )  {  if (  !   is.numeric (   sizeFactors (  object ) ) )  {   stop (  \"the sizeFactor column in colData is not numeric.\r\nthis column could have come in during colData import and should be removed.\" ) }  if (   any (   is.na (   sizeFactors (  object ) ) ) )  {   stop (  \"the sizeFactor column in colData contains NA.\r\nthis column could have come in during colData import and should be removed.\" ) } }  if (   all (    rowSums (    counts (  object ) ==    counts (  object ) [ ,  1 ] ) ==   ncol (  object ) ) )  {   stop (  \"all genes have equal values for all samples. will not be able to perform differential analysis\" ) }  if (  !   is.null (   dispersions (  object ) ) )  {  if (  !  quiet )   message (  \"found already estimated dispersions, replacing these\" )    mcols (  object ) -    mcols (  object ) [ ,  !  (     mcols (   mcols (  object ) ) $ type %in%   c (  \"intermediate\" ,  \"results\" ) ) , drop =  FALSE ] }   stopifnot (    length (  maxit ) ==  1 )   fitType -   match.arg (  fitType , choices =   c (  \"parametric\" ,  \"local\" ,  \"mean\" ) )   checkForExperimentalReplicates (  object ,  modelMatrix )  if (  !  quiet )   message (  \"gene-wise dispersion estimates\" )   object -   estimateDispersionsGeneEst (  object , maxit =  maxit , quiet =  quiet , modelMatrix =  modelMatrix , minmu =  minmu )  if (  !  quiet )   message (  \"mean-dispersion relationship\" )   object -   estimateDispersionsFit (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"final dispersion estimates\" )   object -   estimateDispersionsMAP (  object , maxit =  maxit , quiet =  quiet , modelMatrix =  modelMatrix )   return (  object ) } ",
    "replacementFunction": "estimateDispersions.DESeqDataSet",
    "filename": "methods.txt"
  },
  "new_function": {
    "name": "estimateDispersions",
    "representation": "estimateDispersions",
    "signature": "signature ( object =  DESeqDataSet )",
    "parameters": "function ( object , fitType = c ( \"parametric\" , \"local\" , \"mean\" ) , maxit = 100 , useCR = TRUE , weightThreshold = 1e-2 , quiet = FALSE , modelMatrix = NULL , minmu = 0.5 )",
    "body": "{ # Temporary hack for backward compatibility with \"old\" DESeqDataSet # objects. Remove once all serialized DESeqDataSet objects around have # been updated.  if (  !   .hasSlot (  object ,  \"rowRanges\" ) )   object -   updateObject (  object )  if (    is.null (   sizeFactors (  object ) ) undefined   is.null (   normalizationFactors (  object ) ) )  {   stop (  \"first call estimateSizeFactors or provide a normalizationFactor matrix before estimateDispersions\" ) } # size factors could have slipped in to colData from a previous run  if (  !   is.null (   sizeFactors (  object ) ) )  {  if (  !   is.numeric (   sizeFactors (  object ) ) )  {   stop (  \"the sizeFactor column in colData is not numeric.\r\nthis column could have come in during colData import and should be removed.\" ) }  if (   any (   is.na (   sizeFactors (  object ) ) ) )  {   stop (  \"the sizeFactor column in colData contains NA.\r\nthis column could have come in during colData import and should be removed.\" ) } }  if (   all (    rowSums (    counts (  object ) ==    counts (  object ) [ ,  1 ] ) ==   ncol (  object ) ) )  {   stop (  \"all genes have equal values for all samples. will not be able to perform differential analysis\" ) }  if (  !   is.null (   dispersions (  object ) ) )  {  if (  !  quiet )   message (  \"found already estimated dispersions, replacing these\" )    mcols (  object ) -    mcols (  object ) [ ,  !  (     mcols (   mcols (  object ) ) $ type %in%   c (  \"intermediate\" ,  \"results\" ) ) , drop =  FALSE ] }   stopifnot (    length (  maxit ) ==  1 )   fitType -   match.arg (  fitType , choices =   c (  \"parametric\" ,  \"local\" ,  \"mean\" ) )   checkForExperimentalReplicates (  object ,  modelMatrix )  if (  !  quiet )   message (  \"gene-wise dispersion estimates\" )   object -   estimateDispersionsGeneEst (  object , maxit =  maxit , useCR =  useCR , weightThreshold =  weightThreshold , quiet =  quiet , modelMatrix =  modelMatrix , minmu =  minmu )  if (  !  quiet )   message (  \"mean-dispersion relationship\" )   object -   estimateDispersionsFit (  object , fitType =  fitType , quiet =  quiet )  if (  !  quiet )   message (  \"final dispersion estimates\" )   object -   estimateDispersionsMAP (  object , maxit =  maxit , useCR =  useCR , weightThreshold =  weightThreshold , quiet =  quiet , modelMatrix =  modelMatrix )   return (  object ) } ",
    "replacementFunction": "estimateDispersions.DESeqDataSet",
    "filename": "methods.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_11 deseq2_release_3_12

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_11 deseq2_release_3_12",
    "desc_release_old": "1.28.1",
    "desc_release_new": "1.30.1",
    "old_release_number": 12,
    "new_release_number": 13,
    "function_removals": 0,
    "function_additions": 1,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 1,
    "total_count": 1
}

##########
Functions Removed
##########



##########
Functions Added
##########

integrateWithSingleCell


##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , useCR = TRUE , weightThreshold = 1e-2 , modelMatrix = NULL , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) }  if (  !   is.null (    mcols (  object ) $ dispersion ) )  {  if (  !  quiet )   message (  \"found already estimated dispersions, removing these\" )   removeCols -   c (  \"dispersion\" ,  \"dispOutlier\" ,  \"dispMAP\" ,  \"dispIter\" ,  \"dispConv\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols , drop =  FALSE ] }  if (   is.null (  modelMatrix ) )  {   modelMatrix -   getModelMatrix (  object ) } # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  { # if no gene-wise estimates above minimum  if (    sum (     mcols (  object ) $ dispGeneEst =   minDisp *  100 , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   rep (   minDisp *  10 ,   sum (  !    mcols (  object ) $ allZero ) ) )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  0.25    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn   return (  object ) }   dispPriorVar -   estimateDispersionsPriorVar (  object , modelMatrix =  modelMatrix )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn } else  {   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn }   stopifnot (    length (  dispPriorVar ) ==  1 ) # use weights if they are present in assays(object)   wlist -   getAndCheckWeights (  object ,  modelMatrix , weightThreshold =  weightThreshold )   object -   wlist $ object   weights -   wlist $ weights   useWeights -   wlist $ useWeights   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]   weights -   weights [  !    mcols (  object ) $ allZero , , drop =  FALSE ]   varLogDispEsts -   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ] # start fitting at gene estimate unless the points are one order of magnitude # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDispWrapper ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , usePriorSEXP =  TRUE , weightsSEXP =  weights , useWeightsSEXP =  useWeights , weightThresholdSEXP =  weightThreshold , useCRSEXP =  useCR ) # prepare dispersions for storage in mcols(object)   dispMAP -   exp (   dispResMAP $ log_alpha ) # when lacking convergence from fitDisp() (C++) # we use a function to maximize dispersion parameter # along an adaptive grid (also C++)   dispConv -    dispResMAP $ iter undefined  maxit   refitDisp -  !  dispConv  if (    sum (  refitDisp ) undefined  0 )  {   dispGrid -   fitDispGridWrapper ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =    log (    mcols (  objectNZ ) $ dispFit ) [  refitDisp ] , logAlphaPriorSigmaSq =  log_alpha_prior_sigmasq , usePrior =  TRUE , weightsSEXP =   weights [  refitDisp , , drop =  FALSE ] , useWeightsSEXP =  useWeights , weightThresholdSEXP =  weightThreshold , useCRSEXP =  TRUE )    dispMAP [  refitDisp ] -  dispGrid } # bound the dispersion estimate between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   dispMAP -   pmin (   pmax (  dispMAP ,  minDisp ) ,  maxDisp )   dispersionFinal -  dispMAP # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEsts )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =   dispResMAP $ iter , dispOutlier =  dispOutlier , dispMAP =  dispMAP )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  },
  "new_function": {
    "name": "estimateDispersionsMAP",
    "representation": "estimateDispersionsMAP",
    "parameters": "function ( object , outlierSD = 2 , dispPriorVar , minDisp = 1e-8 , kappa_0 = 1 , dispTol = 1e-6 , maxit = 100 , useCR = TRUE , weightThreshold = 1e-2 , modelMatrix = NULL , type = c ( \"DESeq2\" , \"glmGamPoi\" ) , quiet = FALSE )",
    "body": "{   stopifnot (    length (  outlierSD ) ==  1 )   stopifnot (    length (  minDisp ) ==  1 )   stopifnot (    length (  kappa_0 ) ==  1 )   stopifnot (    length (  dispTol ) ==  1 )   stopifnot (    length (  maxit ) ==  1 )   type -   match.arg (  type ,   c (  \"DESeq2\" ,  \"glmGamPoi\" ) )  if (   is.null (    mcols (  object ) $ allZero ) )  {   object -   getBaseMeansAndVariances (  object ) }  if (  !   is.null (    mcols (  object ) $ dispersion ) )  {  if (  !  quiet )   message (  \"found already estimated dispersions, removing these\" )   removeCols -   c (  \"dispersion\" ,  \"dispOutlier\" ,  \"dispMAP\" ,  \"dispIter\" ,  \"dispConv\" )    mcols (  object ) -    mcols (  object ) [ ,  !    names (   mcols (  object ) ) %in%  removeCols , drop =  FALSE ] }  if (   is.null (  modelMatrix ) )  {   modelMatrix -   getModelMatrix (  object ) } # fill in the calculated dispersion prior variance  if (   missing (  dispPriorVar ) )  { # if no gene-wise estimates above minimum  if (    sum (     mcols (  object ) $ dispGeneEst =   minDisp *  100 , na.rm =  TRUE ) ==  0 )  {   warning (   paste0 (  \"all genes have dispersion estimates ,   minDisp *  10 ,  \", returning disp = \" ,   minDisp *  10 ) )   resultsList -   list ( dispersion =   rep (   minDisp *  10 ,   sum (  !    mcols (  object ) $ allZero ) ) )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =  \"intermediate\" , description =  \"final estimates of dispersion\" )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  0.25    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn   return (  object ) }   dispPriorVar -   estimateDispersionsPriorVar (  object , modelMatrix =  modelMatrix )   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn } else  {   dispFn -   dispersionFunction (  object )    attr (  dispFn ,  \"dispPriorVar\" ) -  dispPriorVar    dispersionFunction (  object , estimateVar =  FALSE ) -  dispFn }   stopifnot (    length (  dispPriorVar ) ==  1 ) # use weights if they are present in assays(object)   wlist -   getAndCheckWeights (  object ,  modelMatrix , weightThreshold =  weightThreshold )   object -   wlist $ object   weights -   wlist $ weights   useWeights -   wlist $ useWeights   objectNZ -   object [  !    mcols (  object ) $ allZero , , drop =  FALSE ]   weights -   weights [  !    mcols (  object ) $ allZero , , drop =  FALSE ]   varLogDispEsts -   attr (   dispersionFunction (  object ) ,  \"varLogDispEsts\" ) # set prior variance for fitting dispersion   log_alpha_prior_sigmasq -  dispPriorVar # get previously calculated mu   mu -    assays (  objectNZ ) [[  \"mu\" ] ]  if (   type ==  \"DESeq2\" )  { # start fitting at gene estimate unless the points are one order of magnitude # below the fitted line, then start at fitted line   dispInit -   ifelse (     mcols (  objectNZ ) $ dispGeneEst undefined   0.1 *    mcols (  objectNZ ) $ dispFit ,    mcols (  objectNZ ) $ dispGeneEst ,    mcols (  objectNZ ) $ dispFit ) # if any missing values, fill in the fitted value to initialize    dispInit [   is.na (  dispInit ) ] -     mcols (  objectNZ ) $ dispFit [   is.na (  dispInit ) ] # run with prior   dispResMAP -   fitDispWrapper ( ySEXP =   counts (  objectNZ ) , xSEXP =  modelMatrix , mu_hatSEXP =  mu , log_alphaSEXP =   log (  dispInit ) , log_alpha_prior_meanSEXP =   log (    mcols (  objectNZ ) $ dispFit ) , log_alpha_prior_sigmasqSEXP =  log_alpha_prior_sigmasq , min_log_alphaSEXP =   log (   minDisp /  10 ) , kappa_0SEXP =  kappa_0 , tolSEXP =  dispTol , maxitSEXP =  maxit , usePriorSEXP =  TRUE , weightsSEXP =  weights , useWeightsSEXP =  useWeights , weightThresholdSEXP =  weightThreshold , useCRSEXP =  useCR ) # prepare dispersions for storage in mcols(object)   dispMAP -   exp (   dispResMAP $ log_alpha )   dispIter -   dispResMAP $ iter # when lacking convergence from fitDisp() (C++) # we use a function to maximize dispersion parameter # along an adaptive grid (also C++)   dispConv -    dispResMAP $ iter undefined  maxit   refitDisp -  !  dispConv  if (    sum (  refitDisp ) undefined  0 )  {   dispGrid -   fitDispGridWrapper ( y =    counts (  objectNZ ) [  refitDisp , , drop =  FALSE ] , x =  modelMatrix , mu =   mu [  refitDisp , , drop =  FALSE ] , logAlphaPriorMean =    log (    mcols (  objectNZ ) $ dispFit ) [  refitDisp ] , logAlphaPriorSigmaSq =  log_alpha_prior_sigmasq , usePrior =  TRUE , weightsSEXP =   weights [  refitDisp , , drop =  FALSE ] , useWeightsSEXP =  useWeights , weightThresholdSEXP =  weightThreshold , useCRSEXP =  TRUE )    dispMAP [  refitDisp ] -  dispGrid } } else  if (   type ==  \"glmGamPoi\" )  {  if (  !   requireNamespace (  \"glmGamPoi\" , quietly =  TRUE ) )  {   stop (  \"type='glmGamPoi' requires installing the Bioconductor package 'glmGamPoi'\" ) }   stopifnot ( \"type = 'glmGamPoi' cannot handle weights\" =  !  useWeights )   gene_means -    mcols (  objectNZ ) $ baseMean   disp_est -    mcols (  objectNZ ) $ dispGeneEst   disp_trend -    mcols (  objectNZ ) $ dispFit   shrink_res -   glmGamPoi :: overdispersion_shrinkage (  disp_est , gene_means =  gene_means , df =    ncol (  objectNZ ) -   ncol (  modelMatrix ) , disp_trend =  disp_trend )   dispFitCorrected -   (     shrink_res $ ql_disp_trend *  (   gene_means +    gene_means ^  2 *  disp_trend ) -  gene_means ) /   gene_means ^  2   dispFitCorrected -   pmin (   pmax (  dispFitCorrected ,  minDisp ) ,   max (  10 ,   ncol (  object ) ) )   qlResultsList -   list ( qlDispMLE =   shrink_res $ ql_disp_estimate , qlDispFit =   shrink_res $ ql_disp_trend , qlDispMAP =   shrink_res $ ql_disp_shrunken , dispFitQLCorrected =  dispFitCorrected )   qlDispDataFrame -   buildDataFrameWithNARows (  qlResultsList ,    mcols (  object ) $ allZero )    mcols (  qlDispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  qlDispDataFrame ) ) , description =   c (  \"quasi likelihood dispersion MLE\" ,  \"quasi likelihood dispersion Trend\" ,  \"quasi likelihood dispersion MAP\" ,  \"dispersion trend corrected by quasi likelihood\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  qlDispDataFrame )    attr (  object ,  \"quasiLikelihood_df0\" ) -   shrink_res $ ql_df0 # Quick way to find alpha that would give same variance as shrunken quasi # likelihood dispersion with dispFit   dispMAP -   (     shrink_res $ ql_disp_shrunken *  (   gene_means +    gene_means ^  2 *  disp_trend ) -  gene_means ) /   gene_means ^  2   dispIter -   rep (  0 ,   length (  dispMAP ) ) } # bound the dispersion estimate between minDisp and maxDisp for numeric stability   maxDisp -   max (  10 ,   ncol (  object ) )   dispMAP -   pmin (   pmax (  dispMAP ,  minDisp ) ,  maxDisp )   dispersionFinal -  dispMAP # detect outliers which have gene-wise estimates # outlierSD * standard deviation of log gene-wise estimates # above the fitted mean (prior mean) # and keep the original gene-est value for these. # Note: we use the variance of log dispersions estimates # from all the genes, not only those from below   dispOutlier -    log (    mcols (  objectNZ ) $ dispGeneEst ) undefined    log (    mcols (  objectNZ ) $ dispFit ) +   outlierSD *   sqrt (  varLogDispEsts )    dispOutlier [   is.na (  dispOutlier ) ] -  FALSE    dispersionFinal [  dispOutlier ] -     mcols (  objectNZ ) $ dispGeneEst [  dispOutlier ]   resultsList -   list ( dispersion =  dispersionFinal , dispIter =  dispIter , dispOutlier =  dispOutlier , dispMAP =  dispMAP )   dispDataFrame -   buildDataFrameWithNARows (  resultsList ,    mcols (  object ) $ allZero )    mcols (  dispDataFrame ) -   DataFrame ( type =   rep (  \"intermediate\" ,   ncol (  dispDataFrame ) ) , description =   c (  \"final estimate of dispersion\" ,  \"number of iterations\" ,  \"dispersion flagged as outlier\" ,  \"maximum a posteriori estimate\" ) )    mcols (  object ) -   cbind (   mcols (  object ) ,  dispDataFrame )   return (  object ) } ",
    "filename": "core.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_12 deseq2_release_3_13

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_12 deseq2_release_3_13",
    "desc_release_old": "1.30.1",
    "desc_release_new": "1.32.0",
    "old_release_number": 13,
    "new_release_number": 14,
    "function_removals": 0,
    "function_additions": 0,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 1,
    "total_count": 1
}

##########
Functions Removed
##########



##########
Functions Added
##########



##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########

0.
{
  "old_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" , filterFun , format = c ( \"DataFrame\" , \"GRanges\" , \"GRangesList\" ) , test , addMLE = FALSE , tidy = FALSE , parallel = FALSE , BPPARAM = bpparam ( ) , minmu = 0.5 )",
    "body": "{   stopifnot (   is (  object ,  \"DESeqDataSet\" ) ) # match args   format -   match.arg (  format , choices =   c (  \"DataFrame\" ,  \"GRanges\" ,  \"GRangesList\" ) )   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) )  if (  !   missing (  test ) )  {   test -   match.arg (  test , choices =   c (  \"Wald\" ,  \"LRT\" ) ) } # initial argument testing   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    alpha undefined  0 undefined   alpha undefined  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"couldn't find results. you should first run DESeq()\" ) }  if (   missing (  test ) )  {   test -   attr (  object ,  \"test\" ) } else  if (    test ==  \"Wald\" undefined    attr (  object ,  \"test\" ) ==  \"LRT\" )  { # initially test was LRT, now need to add Wald statistics and p-values   object -   makeWaldTest (  object ) } else  if (    test ==  \"LRT\" undefined    attr (  object ,  \"test\" ) ==  \"Wald\" )  {   stop (  \"the LRT requires the user run nbinomLRT or DESeq(dds,test='LRT')\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) }  if (  addMLE )  {  if (  !   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"addMLE=TRUE is only for when a beta prior was used.\r\notherwise, the log2 fold changes are already MLE\" ) }  if (   !   missing (  name ) undefined   missing (  contrast ) )  {   stop (  \"addMLE=TRUE should be used by providing character vector\r\nof length 3 to 'contrast' instead of using 'name'\" ) } }  if (    format ==  \"GRanges\" undefined   is (   rowRanges (  object ) ,  \"GRangesList\" ) )  {  if (   any (    elementNROWS (   rowRanges (  object ) ) ==  0 ) )  {   stop (  \"rowRanges is GRangesList and one or more GRanges have length 0. Use format='DataFrame' or 'GRangesList'\" ) } }  if (  !   missing (  contrast ) )  {  if (     attr (  object ,  \"modelMatrixType\" ) ==  \"user-supplied\" undefined   is.character (  contrast ) )  {   stop (  \"only list- and numeric-type contrasts are supported for user-supplied model matrices\" ) } }  if (   is (   design (  object ) ,  \"formula\" ) )  {   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # if no intercept was used or an expanded model matrix was used, # and neither 'contrast' nor 'name' were specified, # and no interactions... # then we create the result table: last / first level for last variable  if (      (   test ==  \"Wald\" ) undefined  (   isExpanded |  !  hasIntercept ) undefined   missing (  contrast ) undefined   missing (  name ) undefined   all (   termsOrder undefined  2 ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) } else  {  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } }   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) ) # this will be used in cleanContrast, and in the lfcThreshold chunks below   useT -   \"tDegreesFreedom\" %in%   names (   mcols (  object ) ) # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {   resNames -   resultsNames (  object ) # do some arg checking/cleaning   contrast -   checkContrast (  contrast ,  resNames ) ### cleanContrast call ### # need to go back to C++ code in order to build the beta covariance matrix # then this is multiplied by the numeric contrast to get the Wald statistic. # with 100s of samples, this can get slow, so offer parallelization  if (  !  parallel )  {   res -   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test , useT =  useT , minmu =  minmu ) } else  if (  parallel )  { # parallel execution   nworkers -   getNworkers (  BPPARAM )   idx -   factor (   sort (   rep (   seq_len (  nworkers ) , length.out =   nrow (  object ) ) ) )   res -   do.call (  rbind ,   bplapply (   levels (  idx ) ,  function ( l )  {   cleanContrast (   object [   idx ==  l , , drop =  FALSE ] ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test , useT =  useT , minmu =  minmu ) } , BPPARAM =  BPPARAM ) ) } } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # add unshrunken MLE coefficients to the results table  if (  addMLE )  {  if (   is.numeric (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )  if (   is.list (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )   res -   cbind (  res ,   mleContrast (  object ,  contrast ) )   res -   res [ ,   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcMLE\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) ] # if an all zero contrast, also zero out the lfcMLE     res $ lfcMLE [   which (     res $ log2FoldChange ==  0 undefined    res $ stat ==  0 ) ] -  0 } # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   stop (  \"tests of log fold change above or below a theshold must be Wald tests.\" ) } # check requirement if betaPrior was set to FALSE  if (    altHypothesis ==  \"lessAbs\" undefined   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) } # easier to read   LFC -   res $ log2FoldChange   SE -   res $ lfcSE   T -  lfcThreshold  if (  useT )  {   df -    mcols (  object ) $ tDegreesFreedom   pfunc -  function ( q )   pt (  q , df =  df , lower.tail =  FALSE ) } else  {   pfunc -  function ( q )   pnorm (  q , lower.tail =  FALSE ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newStat -    sign (  LFC ) *   pmax (   (    abs (  LFC ) -  T ) /  SE ,  0 )   newPvalue -   pmin (  1 ,   2 *   pfunc (   (    abs (  LFC ) -  T ) /  SE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  {   newStatAbove -   pmax (   (   T -  LFC ) /  SE ,  0 )   pvalueAbove -   pfunc (   (   T -  LFC ) /  SE )   newStatBelow -   pmax (   (   LFC +  T ) /  SE ,  0 )   pvalueBelow -   pfunc (   (   LFC +  T ) /  SE )   newStat -   pmin (  newStatAbove ,  newStatBelow )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newStat -   pmax (   (   LFC -  T ) /  SE ,  0 )   newPvalue -   pfunc (   (   LFC -  T ) /  SE ) } else  if (   altHypothesis ==  \"less\" )  {   newStat -   pmin (   (   LFC +  T ) /  SE ,  0 )   newPvalue -   pfunc (   (   -  T -  LFC ) /  SE ) }    res $ stat -  newStat    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"dispModelMatrix\" ) )   p -   ncol (   attr (  object ,  \"dispModelMatrix\" ) )   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff ### BEGIN heuristic to avoid filtering genes with low count outliers # as according to Cook's cutoff. only for two group designs. # dont filter if three or more counts are larger  if (    any (  cooksOutlier , na.rm =  TRUE ) undefined   is (   design (  object ) ,  \"formula\" ) )  {   designVars -   all.vars (   design (  object ) )  if (    length (  designVars ) ==  1 )  {   var -    colData (  object ) [[  designVars ] ]  if (    is (  var ,  \"factor\" ) undefined    nlevels (  var ) ==  2 )  {   dontFilter -   logical (   sum (  cooksOutlier , na.rm =  TRUE ) )  for  ( i in   seq_along (  dontFilter ) )  { # index along rows of object   ii -    which (  cooksOutlier ) [  i ] # count for the outlier with max cooks   outCount -    counts (  object ) [  ii ,   which.max (     assays (  object ) [[  \"cooks\" ] ] [  ii , ] ) ] # if three or more counts larger than the outlier  if (    sum (     counts (  object ) [  ii , ] undefined  outCount ) =  3 )  { # don't filter out the p-value for that gene    dontFilter [  i ] -  TRUE } } # reset the outlier status for these genes     cooksOutlier [   which (  cooksOutlier ) ] [  dontFilter ] -  FALSE } } } ### END heuristic ###     res $ pvalue [   which (  cooksOutlier ) ] -  NA } # if original baseMean was positive, but now zero due to replaced counts, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0  if (  addMLE )  {     res $ lfcMLE [  nowZero ] -  0 }     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # add prior information   deseq2.version -   packageVersion (  \"DESeq2\" )  if (  !   attr (  object ,  \"betaPrior\" ) )  {   priorInfo -   list ( type =  \"none\" , package =  \"DESeq2\" , version =  deseq2.version ) } else  {   betaPriorVar -   attr (  object ,  \"betaPriorVar\" )   priorInfo -   list ( type =  \"normal\" , package =  \"DESeq2\" , version =  deseq2.version , betaPriorVar =  betaPriorVar ) } # make results object   deseqRes -   DESeqResults (  res , priorInfo =  priorInfo ) # p-value adjustment  if (   missing (  filterFun ) )  {   deseqRes -   pvalueAdjustment (  deseqRes ,  independentFiltering ,  filter ,  theta ,  alpha ,  pAdjustMethod ) } else  {   deseqRes -   filterFun (  deseqRes ,  filter ,  alpha ,  pAdjustMethod ) } # stash lfcThreshold     metadata (  deseqRes ) [[  \"lfcThreshold\" ] ] -  lfcThreshold # remove rownames and attach as a new column, 'row'  if (  tidy )  {   colnms -   colnames (  deseqRes )    deseqRes $ row -   rownames (  deseqRes )     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"type\" ] -  \"results\"     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"description\" ] -  \"row names\"   deseqRes -   deseqRes [ ,   c (  \"row\" ,  colnms ) ]    rownames (  deseqRes ) -  NULL   deseqRes -   as.data.frame (  deseqRes ) } # return DataFrame, GRanges or GRangesList   out -   resultsFormatSwitch ( object =  object , res =  deseqRes , format =  format )   return (  out ) } ",
    "filename": "results.txt"
  },
  "new_function": {
    "name": "results",
    "representation": "results",
    "parameters": "function ( object , contrast , name , lfcThreshold = 0 , altHypothesis = c ( \"greaterAbs\" , \"lessAbs\" , \"greater\" , \"less\" ) , listValues = c ( 1 , - 1 ) , cooksCutoff , independentFiltering = TRUE , alpha = 0.1 , filter , theta , pAdjustMethod = \"BH\" , filterFun , format = c ( \"DataFrame\" , \"GRanges\" , \"GRangesList\" ) , saveCols = NULL , test , addMLE = FALSE , tidy = FALSE , parallel = FALSE , BPPARAM = bpparam ( ) , minmu = 0.5 )",
    "body": "{   stopifnot (   is (  object ,  \"DESeqDataSet\" ) ) # match args   format -   match.arg (  format , choices =   c (  \"DataFrame\" ,  \"GRanges\" ,  \"GRangesList\" ) )   altHypothesis -   match.arg (  altHypothesis , choices =   c (  \"greaterAbs\" ,  \"lessAbs\" ,  \"greater\" ,  \"less\" ) )  if (  !   missing (  test ) )  {   test -   match.arg (  test , choices =   c (  \"Wald\" ,  \"LRT\" ) ) } ### initial argument testing ###   stopifnot (   lfcThreshold =  0 )   stopifnot (    length (  lfcThreshold ) ==  1 )   stopifnot (    length (  alpha ) ==  1 )   stopifnot (    alpha undefined  0 undefined   alpha undefined  1 )   stopifnot (    length (  pAdjustMethod ) ==  1 )   stopifnot (     length (  listValues ) ==  2 undefined   is.numeric (  listValues ) )   stopifnot (     listValues [  1 ] undefined  0 undefined    listValues [  2 ] undefined  0 )  if (  !   \"results\" %in%    mcols (   mcols (  object ) ) $ type )  {   stop (  \"couldn't find results. you should first run DESeq()\" ) }  if (   missing (  test ) )  {   test -   attr (  object ,  \"test\" ) } else  if (    test ==  \"Wald\" undefined    attr (  object ,  \"test\" ) ==  \"LRT\" )  { # initially test was LRT, now need to add Wald statistics and p-values   object -   makeWaldTest (  object ) } else  if (    test ==  \"LRT\" undefined    attr (  object ,  \"test\" ) ==  \"Wald\" )  {   stop (  \"the LRT requires the user run nbinomLRT or DESeq(dds,test='LRT')\" ) }  if (    lfcThreshold ==  0 undefined   altHypothesis ==  \"lessAbs\" )  {   stop (  \"when testing altHypothesis='lessAbs', set the argument lfcThreshold to a positive value\" ) }  if (  addMLE )  {  if (  !   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"addMLE=TRUE is only for when a beta prior was used.\r\notherwise, the log2 fold changes are already MLE\" ) }  if (   !   missing (  name ) undefined   missing (  contrast ) )  {   stop (  \"addMLE=TRUE should be used by providing character vector\r\nof length 3 to 'contrast' instead of using 'name'\" ) } }  if (    format ==  \"GRanges\" undefined   is (   rowRanges (  object ) ,  \"GRangesList\" ) )  {  if (   any (    elementNROWS (   rowRanges (  object ) ) ==  0 ) )  {   stop (  \"rowRanges is GRangesList and one or more GRanges have length 0. Use format='DataFrame' or 'GRangesList'\" ) } }  if (  !   is.null (  saveCols ) )  {  if (   is (  saveCols ,  \"character\" ) )   stopifnot (   all (   saveCols %in%   colnames (   mcols (  object ) ) ) )  if (   is (  saveCols ,  \"numeric\" ) )  {   stopifnot (   saveCols ==   round (  saveCols ) )   stopifnot (    min (  saveCols ) undefined  0 )   stopifnot (    max (  saveCols ) =   ncol (   mcols (  object ) ) ) } }  if (  !   missing (  contrast ) )  {  if (     attr (  object ,  \"modelMatrixType\" ) ==  \"user-supplied\" undefined   is.character (  contrast ) )  {   stop (  \"only list- and numeric-type contrasts are supported for user-supplied model matrices\" ) } }  if (   is (   design (  object ) ,  \"formula\" ) )  {   hasIntercept -    attr (   terms (   design (  object ) ) ,  \"intercept\" ) ==  1   isExpanded -    attr (  object ,  \"modelMatrixType\" ) ==  \"expanded\"   termsOrder -   attr (   terms.formula (   design (  object ) ) ,  \"order\" ) # if no intercept was used or an expanded model matrix was used, # and neither 'contrast' nor 'name' were specified, # and no interactions... # then we create the result table: last / first level for last variable  if (      (   test ==  \"Wald\" ) undefined  (   isExpanded |  !  hasIntercept ) undefined   missing (  contrast ) undefined   missing (  name ) undefined   all (   termsOrder undefined  2 ) )  {   designVars -   all.vars (   design (  object ) )   lastVarName -   designVars [   length (  designVars ) ]   lastVar -    colData (  object ) [[  lastVarName ] ]  if (   is.factor (  lastVar ) )  {   nlvls -   nlevels (  lastVar )   contrast -   c (  lastVarName ,    levels (  lastVar ) [  nlvls ] ,    levels (  lastVar ) [  1 ] ) } } }  if (   missing (  name ) )  {   name -   lastCoefName (  object ) } else  {  if (     length (  name ) !=  1 |  !   is.character (  name ) )  {   stop (  \"the argument 'name' should be a character vector of length 1\" ) } } ### done with input argument testing ###   WaldResults -    paste0 (  \"WaldPvalue_\" ,  name ) %in%   names (   mcols (  object ) )   LRTResults -   \"LRTPvalue\" %in%   names (   mcols (  object ) ) # this will be used in cleanContrast, and in the lfcThreshold chunks below   useT -   \"tDegreesFreedom\" %in%   names (   mcols (  object ) ) # if performing a contrast call the function cleanContrast()  if (  !   missing (  contrast ) )  {   resNames -   resultsNames (  object ) # do some arg checking/cleaning   contrast -   checkContrast (  contrast ,  resNames ) ### cleanContrast call ### # need to go back to C++ code in order to build the beta covariance matrix # then this is multiplied by the numeric contrast to get the Wald statistic. # with 100s of samples, this can get slow, so offer parallelization  if (  !  parallel )  {   res -   cleanContrast (  object ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test , useT =  useT , minmu =  minmu ) } else  if (  parallel )  { # parallel execution   nworkers -   getNworkers (  BPPARAM )   idx -   factor (   sort (   rep (   seq_len (  nworkers ) , length.out =   nrow (  object ) ) ) )   res -   do.call (  rbind ,   bplapply (   levels (  idx ) ,  function ( l )  {   cleanContrast (   object [   idx ==  l , , drop =  FALSE ] ,  contrast , expanded =  isExpanded , listValues =  listValues , test =  test , useT =  useT , minmu =  minmu ) } , BPPARAM =  BPPARAM ) ) } } else  { # if not performing a contrast # pull relevant columns from mcols(object)   log2FoldChange -   getCoef (  object ,  name )   lfcSE -   getCoefSE (  object ,  name )   stat -   getStat (  object ,  test ,  name )   pvalue -   getPvalue (  object ,  test ,  name )   res -   cbind (    mcols (  object ) [  \"baseMean\" ] ,  log2FoldChange ,  lfcSE ,  stat ,  pvalue )    names (  res ) -   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) }    rownames (  res ) -   rownames (  object ) # add unshrunken MLE coefficients to the results table  if (  addMLE )  {  if (   is.numeric (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )  if (   is.list (  contrast ) )   stop (  \"addMLE only implemented for: contrast=c('condition','B','A')\" )   res -   cbind (  res ,   mleContrast (  object ,  contrast ) )   res -   res [ ,   c (  \"baseMean\" ,  \"log2FoldChange\" ,  \"lfcMLE\" ,  \"lfcSE\" ,  \"stat\" ,  \"pvalue\" ) ] # if an all zero contrast, also zero out the lfcMLE     res $ lfcMLE [   which (     res $ log2FoldChange ==  0 undefined    res $ stat ==  0 ) ] -  0 } # only if we need to generate new p-values  if (  !  (    lfcThreshold ==  0 undefined   altHypothesis ==  \"greaterAbs\" ) )  {  if (   test ==  \"LRT\" )  {   stop (  \"tests of log fold change above or below a theshold must be Wald tests.\" ) } # check requirement if betaPrior was set to FALSE  if (    altHypothesis ==  \"lessAbs\" undefined   attr (  object ,  \"betaPrior\" ) )  {   stop (  \"testing altHypothesis='lessAbs' requires setting the DESeq() argument betaPrior=FALSE\" ) } # easier to read   LFC -   res $ log2FoldChange   SE -   res $ lfcSE   T -  lfcThreshold  if (  useT )  {   df -    mcols (  object ) $ tDegreesFreedom   pfunc -  function ( q )   pt (  q , df =  df , lower.tail =  FALSE ) } else  {   pfunc -  function ( q )   pnorm (  q , lower.tail =  FALSE ) }  if (   altHypothesis ==  \"greaterAbs\" )  {   newStat -    sign (  LFC ) *   pmax (   (    abs (  LFC ) -  T ) /  SE ,  0 )   newPvalue -   pmin (  1 ,   2 *   pfunc (   (    abs (  LFC ) -  T ) /  SE ) ) } else  if (   altHypothesis ==  \"lessAbs\" )  {   newStatAbove -   pmax (   (   T -  LFC ) /  SE ,  0 )   pvalueAbove -   pfunc (   (   T -  LFC ) /  SE )   newStatBelow -   pmax (   (   LFC +  T ) /  SE ,  0 )   pvalueBelow -   pfunc (   (   LFC +  T ) /  SE )   newStat -   pmin (  newStatAbove ,  newStatBelow )   newPvalue -   pmax (  pvalueAbove ,  pvalueBelow ) } else  if (   altHypothesis ==  \"greater\" )  {   newStat -   pmax (   (   LFC -  T ) /  SE ,  0 )   newPvalue -   pfunc (   (   LFC -  T ) /  SE ) } else  if (   altHypothesis ==  \"less\" )  {   newStat -   pmin (   (   LFC +  T ) /  SE ,  0 )   newPvalue -   pfunc (   (   -  T -  LFC ) /  SE ) }    res $ stat -  newStat    res $ pvalue -  newPvalue } # calculate Cook's cutoff   m -   nrow (   attr (  object ,  \"dispModelMatrix\" ) )   p -   ncol (   attr (  object ,  \"dispModelMatrix\" ) )   defaultCutoff -   qf (  .99 ,  p ,   m -  p )  if (   missing (  cooksCutoff ) )  {   cooksCutoff -  defaultCutoff }   stopifnot (    length (  cooksCutoff ) ==  1 )  if (    is.logical (  cooksCutoff ) undefined  cooksCutoff )  {   cooksCutoff -  defaultCutoff } # apply cutoff based on maximum Cook's distance   performCooksCutoff -  (    is.numeric (  cooksCutoff ) |  cooksCutoff )  if (  performCooksCutoff )  {   cooksOutlier -     mcols (  object ) $ maxCooks undefined  cooksCutoff ### BEGIN heuristic to avoid filtering genes with low count outliers # as according to Cook's cutoff. only for two group designs. # dont filter if three or more counts are larger  if (    any (  cooksOutlier , na.rm =  TRUE ) undefined   is (   design (  object ) ,  \"formula\" ) )  {   designVars -   all.vars (   design (  object ) )  if (    length (  designVars ) ==  1 )  {   var -    colData (  object ) [[  designVars ] ]  if (    is (  var ,  \"factor\" ) undefined    nlevels (  var ) ==  2 )  {   dontFilter -   logical (   sum (  cooksOutlier , na.rm =  TRUE ) )  for  ( i in   seq_along (  dontFilter ) )  { # index along rows of object   ii -    which (  cooksOutlier ) [  i ] # count for the outlier with max cooks   outCount -    counts (  object ) [  ii ,   which.max (     assays (  object ) [[  \"cooks\" ] ] [  ii , ] ) ] # if three or more counts larger than the outlier  if (    sum (     counts (  object ) [  ii , ] undefined  outCount ) =  3 )  { # don't filter out the p-value for that gene    dontFilter [  i ] -  TRUE } } # reset the outlier status for these genes     cooksOutlier [   which (  cooksOutlier ) ] [  dontFilter ] -  FALSE } } } ### END heuristic ###     res $ pvalue [   which (  cooksOutlier ) ] -  NA } # if original baseMean was positive, but now zero due to replaced counts, fill in results  if (    sum (    mcols (  object ) $ replace , na.rm =  TRUE ) undefined  0 )  {   nowZero -   which (     mcols (  object ) $ replace undefined     mcols (  object ) $ baseMean ==  0 )     res $ log2FoldChange [  nowZero ] -  0  if (  addMLE )  {     res $ lfcMLE [  nowZero ] -  0 }     res $ lfcSE [  nowZero ] -  0     res $ stat [  nowZero ] -  0     res $ pvalue [  nowZero ] -  1 } # add prior information   deseq2.version -   packageVersion (  \"DESeq2\" )  if (  !   attr (  object ,  \"betaPrior\" ) )  {   priorInfo -   list ( type =  \"none\" , package =  \"DESeq2\" , version =  deseq2.version ) } else  {   betaPriorVar -   attr (  object ,  \"betaPriorVar\" )   priorInfo -   list ( type =  \"normal\" , package =  \"DESeq2\" , version =  deseq2.version , betaPriorVar =  betaPriorVar ) } # make results object   deseqRes -   DESeqResults (  res , priorInfo =  priorInfo ) # p-value adjustment  if (   missing (  filterFun ) )  {   deseqRes -   pvalueAdjustment (  deseqRes ,  independentFiltering ,  filter ,  theta ,  alpha ,  pAdjustMethod ) } else  {   deseqRes -   filterFun (  deseqRes ,  filter ,  alpha ,  pAdjustMethod ) } # stash lfcThreshold     metadata (  deseqRes ) [[  \"lfcThreshold\" ] ] -  lfcThreshold # remove rownames and attach as a new column, 'row'  if (  tidy )  {   colnms -   colnames (  deseqRes )    deseqRes $ row -   rownames (  deseqRes )     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"type\" ] -  \"results\"     mcols (  deseqRes , use.names =  TRUE ) [  \"row\" ,  \"description\" ] -  \"row names\"   deseqRes -   deseqRes [ ,   c (  \"row\" ,  colnms ) ]    rownames (  deseqRes ) -  NULL   deseqRes -   as.data.frame (  deseqRes ) } # return DataFrame, GRanges or GRangesList   out -   resultsFormatSwitch ( object =  object , res =  deseqRes , format =  format , saveCols =  saveCols )   return (  out ) } ",
    "filename": "results.txt"
  }
}


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_13 deseq2_release_3_14

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_13 deseq2_release_3_14",
    "desc_release_old": "1.32.0",
    "desc_release_new": "1.34.0",
    "old_release_number": 14,
    "new_release_number": 15,
    "function_removals": 0,
    "function_additions": 0,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 0,
    "total_count": 0
}

##########
Functions Removed
##########



##########
Functions Added
##########



##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########


###############################
###############################
###############################
###############################
Checking Versions:  deseq2_release_3_14 deseq2_master

{
    "package": "DESeq2",
    "release_versions": "deseq2_release_3_14 deseq2_master",
    "desc_release_old": "1.34.0",
    "desc_release_new": "1.35.0",
    "old_release_number": 15,
    "new_release_number": 16,
    "function_removals": 0,
    "function_additions": 0,
    "parameter_removals": 0,
    "parameter_additions": 0,
    "parameter_renames": 0,
    "parameter_default_changes": 0,
    "parameter_overall_changes": 0,
    "total_count": 0
}

##########
Functions Removed
##########



##########
Functions Added
##########



##########
Removed Non Default Parameters
##########



##########
Added Non Default Parameters
##########



##########
All Parameter Breaking Changes
##########

